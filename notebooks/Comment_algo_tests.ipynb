{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import translators as ts\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment\n",
       "0  aLZ85hb4wjE                     Loved the calmness of Manilla.\n",
       "1  aLZ85hb4wjE  After this pandemic I think every country shou...\n",
       "2  aLZ85hb4wjE           manila looks beautifull with less people\n",
       "3  aLZ85hb4wjE  The lockdown makes the city look like a place ...\n",
       "4  aLZ85hb4wjE                                    India also same"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/covid_philippines/covid_philippines_comments.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_comments = {}\n",
    "translated_comments[\"video_id\"] = {}\n",
    "translated_comments[\"comment\"] = {}\n",
    "video_id_list = df[\"video_id\"].to_list()\n",
    "comments_list = df[\"comment\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating...:   0%|          | 0/1216 [00:00<?, ?it/s]Translating...: 100%|██████████| 1216/1216 [04:57<00:00,  4.09it/s]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(video_id_list))\n",
    "pbar.set_description(\"Translating...\")\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    if comments_list[i] != None:\n",
    "        new_comment = comments_list[i]\n",
    "        try:\n",
    "            lang = detect(comments_list[i]) #added langdetect since it errors if there are many entries to translate, so now it will ontly tranlate if comment not english\n",
    "            if lang != 'en':\n",
    "                new_comment = ts.translate_text(comments_list[i], 'google', to_language = 'en')\n",
    "                \n",
    "        except:\n",
    "            # No change; get same comment from list\n",
    "            pass\n",
    "            \n",
    "        finally:\n",
    "            translated_comments[\"video_id\"][i] = video_id_list[i]\n",
    "            translated_comments[\"comment\"][i] = new_comment\n",
    "            pbar.update(1)\n",
    "\n",
    "translated_df = pd.DataFrame.from_dict(translated_comments)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>This covid will be a never-ending fuckery as l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>A new variant is inevitable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>The man that should resign from his office is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>Is that the people who got been vaccinated.,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>The toxic of comments section 😄 \\r\\n During th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                            comment\n",
       "0     aLZ85hb4wjE                     Loved the calmness of Manilla.\n",
       "1     aLZ85hb4wjE  After this pandemic I think every country shou...\n",
       "2     aLZ85hb4wjE           manila looks beautifull with less people\n",
       "3     aLZ85hb4wjE  The lockdown makes the city look like a place ...\n",
       "4     aLZ85hb4wjE                                    India also same\n",
       "...           ...                                                ...\n",
       "1211  5DvMPgoKZmM  This covid will be a never-ending fuckery as l...\n",
       "1212  5DvMPgoKZmM                       A new variant is inevitable.\n",
       "1213  5DvMPgoKZmM  The man that should resign from his office is ...\n",
       "1214  5DvMPgoKZmM       Is that the people who got been vaccinated.,\n",
       "1215  5DvMPgoKZmM  The toxic of comments section 😄 \\r\\n During th...\n",
       "\n",
       "[1216 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(video_id_list, comments_list):\n",
    "    translated_comments = {}\n",
    "    translated_comments[\"video_id\"] = {}\n",
    "    translated_comments[\"comment\"] = {}\n",
    "    \n",
    "    pbar = tqdm(total=len(video_id_list))\n",
    "    pbar.set_description(\"Translating...\")\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        if comments_list[i] != None:\n",
    "            new_comment = comments_list[i]\n",
    "            try:\n",
    "                lang = detect(comments_list[i]) #added langdetect since it errors if there are many entries to translate, so now it will ontly tranlate if comment not english\n",
    "                if lang != 'en':\n",
    "                    new_comment = ts.translate_text(comments_list[i], 'google', to_language = 'en')\n",
    "\n",
    "            except:\n",
    "                # No change; get same comment from list\n",
    "                pass\n",
    "\n",
    "            finally:\n",
    "                translated_comments[\"video_id\"][i] = video_id_list[i]\n",
    "                translated_comments[\"comment\"][i] = new_comment\n",
    "                pbar.update(1)\n",
    "\n",
    "    translated_df = pd.DataFrame.from_dict(translated_comments)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETECT SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0:Not Spam\n",
    "- 1:Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    1508\n",
       "AUTHOR        1508\n",
       "DATE          1508\n",
       "CONTENT       1508\n",
       "CLASS         1508\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset source: https://archive.ics.uci.edu/dataset/380/youtube+spam+collection\n",
    "\n",
    "psy_model_df = pd.read_csv(\"../datasets/model_train/Youtube01-Psy.csv\")\n",
    "lmfao_model_df = pd.read_csv(\"../datasets/model_train/Youtube03-LMFAO.csv\")\n",
    "kp_model_df = pd.read_csv(\"../datasets/model_train/Youtube02-KatyPerry.csv\")\n",
    "shakira_df = pd.read_csv(\"../datasets/model_train/Youtube05-Shakira.csv\")\n",
    "model_df = pd.concat([psy_model_df,lmfao_model_df,kp_model_df,shakira_df])\n",
    "model_df.reset_index(inplace=True, drop=True) \n",
    "model_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>_2viQ_Qnc6_1Hq9MGlefkBIszt9rYD3S_CozADvMhQ4</td>\n",
       "      <td>Dinova Sharon</td>\n",
       "      <td>2013-07-13T14:44:00.700000</td>\n",
       "      <td>well done shakira</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>_2viQ_Qnc6-bMSjqyL1NKj57ROicCSJV5SwTrw-RFFA</td>\n",
       "      <td>Katie Mettam</td>\n",
       "      <td>2013-07-13T13:27:39.441000</td>\n",
       "      <td>I love this song because we sing it at Camp al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>_2viQ_Qnc6-pY-1yR6K2FhmC5i48-WuNx5CumlHLDAI</td>\n",
       "      <td>Sabina Pearson-Smith</td>\n",
       "      <td>2013-07-13T13:14:30.021000</td>\n",
       "      <td>I love this song for two reasons: 1.it is abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>_2viQ_Qnc6_yBt8UGMWyg3vh0PulTqcqyQtdE7d4Fl0</td>\n",
       "      <td>Aishlin Maciel</td>\n",
       "      <td>2013-07-13T11:17:52.308000</td>\n",
       "      <td>Shakira u are so wiredo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>_2viQ_Qnc685RPw1aSa1tfrIuHXRvAQ2rPT9R06KTqA</td>\n",
       "      <td>Latin Bosch</td>\n",
       "      <td>2013-07-12T22:33:27.916000</td>\n",
       "      <td>Shakira is the best dancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1362 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID                AUTHOR  \\\n",
       "0     LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU             Julius NM   \n",
       "1     LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A           adam riyati   \n",
       "2     LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8      Evgeny Murashkin   \n",
       "3             z13jhp0bxqncu512g22wvzkasxmvvzjaz04       ElNino Melendez   \n",
       "4             z13fwbwp1oujthgqj04chlngpvzmtt3r3dw                GsMega   \n",
       "...                                           ...                   ...   \n",
       "1502  _2viQ_Qnc6_1Hq9MGlefkBIszt9rYD3S_CozADvMhQ4         Dinova Sharon   \n",
       "1503  _2viQ_Qnc6-bMSjqyL1NKj57ROicCSJV5SwTrw-RFFA          Katie Mettam   \n",
       "1504  _2viQ_Qnc6-pY-1yR6K2FhmC5i48-WuNx5CumlHLDAI  Sabina Pearson-Smith   \n",
       "1506  _2viQ_Qnc6_yBt8UGMWyg3vh0PulTqcqyQtdE7d4Fl0        Aishlin Maciel   \n",
       "1507  _2viQ_Qnc685RPw1aSa1tfrIuHXRvAQ2rPT9R06KTqA           Latin Bosch   \n",
       "\n",
       "                            DATE  \\\n",
       "0            2013-11-07T06:20:48   \n",
       "1            2013-11-07T12:37:15   \n",
       "2            2013-11-08T17:34:21   \n",
       "3            2013-11-09T08:28:43   \n",
       "4            2013-11-10T16:05:38   \n",
       "...                          ...   \n",
       "1502  2013-07-13T14:44:00.700000   \n",
       "1503  2013-07-13T13:27:39.441000   \n",
       "1504  2013-07-13T13:14:30.021000   \n",
       "1506  2013-07-13T11:17:52.308000   \n",
       "1507  2013-07-12T22:33:27.916000   \n",
       "\n",
       "                                                CONTENT  CLASS  \n",
       "0     Huh, anyway check out this you[tube] channel: ...      1  \n",
       "1     Hey guys check out my new channel and our firs...      1  \n",
       "2                just for test I have to say murdev.com      1  \n",
       "3      me shaking my sexy ass on my channel enjoy ^_^ ﻿      1  \n",
       "4               watch?v=vtaRGgvGtWQ   Check this out .﻿      1  \n",
       "...                                                 ...    ...  \n",
       "1502                                  well done shakira      0  \n",
       "1503  I love this song because we sing it at Camp al...      0  \n",
       "1504  I love this song for two reasons: 1.it is abou...      0  \n",
       "1506                            Shakira u are so wiredo      0  \n",
       "1507                         Shakira is the best dancer      0  \n",
       "\n",
       "[1362 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.drop_duplicates(subset=\"CONTENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    1508\n",
       "AUTHOR        1508\n",
       "DATE          1508\n",
       "CONTENT       1508\n",
       "CLASS         1508\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Melanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "stop_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['CONTENT'] = model_df['CONTENT'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "\n",
    "ps = PorterStemmer() \n",
    "for w in model_df[\"CONTENT\"]: \n",
    "    #convert to lowercase\n",
    "    model_df['CONTENT'] = model_df[\"CONTENT\"].str.lower()\n",
    "    #remove punctuation\n",
    "    model_df['CONTENT'] = model_df['CONTENT'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "    #Stem\n",
    "    model_df['CONTENT'] = model_df[\"CONTENT\"].apply(ps.stem) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model_df[\"CONTENT\"]\n",
    "y  =model_df[\"CLASS\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test  = train_test_split(x,y,random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9708222811671088\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       544\n",
      "           1       0.97      0.97      0.97       587\n",
      "\n",
      "    accuracy                           0.97      1131\n",
      "   macro avg       0.97      0.97      0.97      1131\n",
      "weighted avg       0.97      0.97      0.97      1131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_nb = MultinomialNB()\n",
    "spam_nb.fit(x_train,y_train)\n",
    "\n",
    "predictions=spam_nb.predict(x_train)\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(f\"Train Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_train, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9230769230769231\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       204\n",
      "           1       0.93      0.90      0.91       173\n",
      "\n",
      "    accuracy                           0.92       377\n",
      "   macro avg       0.92      0.92      0.92       377\n",
      "weighted avg       0.92      0.92      0.92       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=spam_nb.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with another dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z12rwfnyyrbsefonb232i5ehdxzkjzjs2</td>\n",
       "      <td>Lisa Wellas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+447935454150 lovely girl talk to me xxx﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z130wpnwwnyuetxcn23xf5k5ynmkdpjrj04</td>\n",
       "      <td>jason graham</td>\n",
       "      <td>2015-05-29T02:26:10.652000</td>\n",
       "      <td>I always end up coming back to this song&lt;br /&gt;﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z13vsfqirtavjvu0t22ezrgzyorwxhpf3</td>\n",
       "      <td>Ajkal Khan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my sister just received over 6,500 new &lt;a rel=...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z12wjzc4eprnvja4304cgbbizuved35wxcs</td>\n",
       "      <td>Dakota Taylor</td>\n",
       "      <td>2015-05-29T02:13:07.810000</td>\n",
       "      <td>Cool﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13xjfr42z3uxdz2223gx5rrzs3dt5hna</td>\n",
       "      <td>Jihad Naser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello I&amp;#39;am from Palastine﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            COMMENT_ID         AUTHOR  \\\n",
       "0    z12rwfnyyrbsefonb232i5ehdxzkjzjs2    Lisa Wellas   \n",
       "1  z130wpnwwnyuetxcn23xf5k5ynmkdpjrj04   jason graham   \n",
       "2    z13vsfqirtavjvu0t22ezrgzyorwxhpf3     Ajkal Khan   \n",
       "3  z12wjzc4eprnvja4304cgbbizuved35wxcs  Dakota Taylor   \n",
       "4    z13xjfr42z3uxdz2223gx5rrzs3dt5hna    Jihad Naser   \n",
       "\n",
       "                         DATE  \\\n",
       "0                         NaN   \n",
       "1  2015-05-29T02:26:10.652000   \n",
       "2                         NaN   \n",
       "3  2015-05-29T02:13:07.810000   \n",
       "4                         NaN   \n",
       "\n",
       "                                             CONTENT  CLASS  \n",
       "0          +447935454150 lovely girl talk to me xxx﻿      1  \n",
       "1    I always end up coming back to this song<br />﻿      0  \n",
       "2  my sister just received over 6,500 new <a rel=...      1  \n",
       "3                                              Cool﻿      0  \n",
       "4                     Hello I&#39;am from Palastine﻿      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset source: https://archive.ics.uci.edu/dataset/380/youtube+spam+collection\n",
    "\n",
    "em_model_df = pd.read_csv(\"../datasets/model_train/Youtube04-Eminem.csv\")\n",
    "em_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_model_df['CONTENT'] = em_model_df['CONTENT'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "\n",
    "ps = PorterStemmer() \n",
    "for w in em_model_df[\"CONTENT\"]: \n",
    "    #convert to lowercase\n",
    "    em_model_df['CONTENT'] = em_model_df[\"CONTENT\"].str.lower()\n",
    "    #remove punctuation\n",
    "    em_model_df['CONTENT'] = em_model_df['CONTENT'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "    #Stem\n",
    "    em_model_df['CONTENT'] = em_model_df[\"CONTENT\"].apply(ps.stem) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_x=em_model_df[\"CONTENT\"]\n",
    "em_y=em_model_df[\"CLASS\"]\n",
    "\n",
    "em_x=vectorizer.transform(em_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.828125\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.69      0.78       203\n",
      "           1       0.79      0.94      0.86       245\n",
      "\n",
      "    accuracy                           0.83       448\n",
      "   macro avg       0.85      0.82      0.82       448\n",
      "weighted avg       0.84      0.83      0.82       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=spam_nb.predict(em_x)\n",
    "accuracy = accuracy_score(em_y, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(em_y, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypertuning MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0, 10.0,2,0.2,0.02 ],\n",
    "    'fit_prior': [True, False],\n",
    "    'class_prior': [None, [.1,.9],[.2, .8],[.3,.7],[.4,.6],[.9,.1],[.8,.2]]\n",
    "         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 112 is smaller than n_iter=500. Running 112 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#https://coderzcolumn.com/tutorials/machine-learning/scikit-learn-sklearn-naive-bayes#6\n",
    "multinomial_nb_random = RandomizedSearchCV(MultinomialNB(),param_distributions=hyperparameters,n_iter=500,cv=10,random_state=42).fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_prior': True, 'class_prior': [0.8, 0.2], 'alpha': 10.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_nb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9283819628647215\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       204\n",
      "           1       0.93      0.91      0.92       173\n",
      "\n",
      "    accuracy                           0.93       377\n",
      "   macro avg       0.93      0.93      0.93       377\n",
      "weighted avg       0.93      0.93      0.93       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = multinomial_nb_random.best_estimator_.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eminem Test Accuracy: 0.9397321428571429\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       203\n",
      "           1       0.95      0.94      0.94       245\n",
      "\n",
      "    accuracy                           0.94       448\n",
      "   macro avg       0.94      0.94      0.94       448\n",
      "weighted avg       0.94      0.94      0.94       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = multinomial_nb_random.best_estimator_.predict(em_x)\n",
    "accuracy = accuracy_score(em_y, predictions)\n",
    "print(f\"Eminem Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(em_y, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=model_df[\"CONTENT\"]\n",
    "y=model_df[\"CLASS\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x=vectorizer.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test  = train_test_split(x,y,test_size=0.30,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8511848341232228\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       504\n",
      "           1       0.87      0.84      0.86       551\n",
      "\n",
      "    accuracy                           0.85      1055\n",
      "   macro avg       0.85      0.85      0.85      1055\n",
      "weighted avg       0.85      0.85      0.85      1055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel = 'sigmoid', gamma = 1.0)\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "predictions = svm_model.predict(x_train)\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(f\"Train Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_train, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8785871964679912\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       244\n",
      "           1       0.86      0.88      0.87       209\n",
      "\n",
      "    accuracy                           0.88       453\n",
      "   macro avg       0.88      0.88      0.88       453\n",
      "weighted avg       0.88      0.88      0.88       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = svm_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8325892857142857\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       203\n",
      "           1       0.85      0.84      0.85       245\n",
      "\n",
      "    accuracy                           0.83       448\n",
      "   macro avg       0.83      0.83      0.83       448\n",
      "weighted avg       0.83      0.83      0.83       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "em_x=em_model_df[\"CONTENT\"]\n",
    "em_y=em_model_df[\"CLASS\"]\n",
    "\n",
    "em_x=vectorizer.transform(em_x)\n",
    "\n",
    "predictions = svm_model.predict(em_x)\n",
    "accuracy = accuracy_score(em_y, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(em_y, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters= [\n",
    "    {\n",
    "        \"C\":[0.0001, 0.001, 0.01 , 0.1, 1.0, 5, 30, 50],\n",
    "        \"kernel\": [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n",
    "        \"degree\" :[1, 3, 5, 10, 25, 50,100],\n",
    "        \"gamma\" :[\"scale\", \"auto\",1000, 10, 5, 2.5, 1.5, 1.0]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "178 fits failed out of a total of 3000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "178 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in fit\n",
      "    raise ValueError(\n",
      "ValueError: The dual coefficients or intercepts are not finite. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.86920934 0.52228212 0.49189578 0.52228212 0.95263252 0.86540881\n",
      " 0.5592363  0.93176999 0.84274034 0.95263252 0.79150045 0.70994609\n",
      " 0.95263252 0.95263252 0.95263252 0.59522911 0.52228212        nan\n",
      " 0.59522911 0.79339623 0.86636119 0.81520216 0.52228212 0.94787062\n",
      " 0.67867026 0.52228212        nan 0.52228212 0.5677628         nan\n",
      " 0.8531177  0.52228212 0.52228212 0.52228212 0.83885894 0.49572327\n",
      " 0.95263252 0.86920934 0.48436658 0.51942498 0.95263252 0.95359389\n",
      " 0.52228212 0.863531   0.86252471 0.52228212 0.95263252 0.52228212\n",
      " 0.87303684        nan 0.52228212 0.90427673 0.95263252 0.79150045\n",
      " 0.52228212 0.81710692 0.52228212 0.90427673 0.86920934 0.52228212\n",
      " 0.84745732 0.56302785 0.93176999 0.52228212 0.59522911 0.95263252\n",
      " 0.95359389 0.95263252 0.95263252 0.84745732 0.52228212 0.81615454\n",
      " 0.90237197 0.52228212 0.86920934 0.86350404 0.79150045 0.86920934\n",
      " 0.90237197 0.95263252 0.52228212 0.94787062 0.59522911 0.52228212\n",
      " 0.52228212 0.86920934 0.86350404 0.52228212 0.52228212        nan\n",
      " 0.52228212 0.52228212 0.95263252 0.52228212        nan 0.52228212\n",
      " 0.95263252 0.95359389 0.52228212 0.95263252 0.52228212        nan\n",
      " 0.52228212        nan 0.52228212        nan 0.84365678 0.93176999\n",
      " 0.52228212        nan 0.89763702 0.71280323 0.90237197 0.52228212\n",
      " 0.90237197 0.56302785 0.52228212 0.93176999 0.52132974 0.52228212\n",
      " 0.52228212 0.95263252 0.86920934 0.52228212 0.95263252 0.59522911\n",
      " 0.95263252 0.52228212 0.52228212 0.86540881        nan 0.67867026\n",
      " 0.85881402 0.90427673 0.93176999 0.52228212 0.52228212 0.52228212\n",
      " 0.93271339 0.88063792 0.82465409 0.95263252 0.71280323 0.95263252\n",
      " 0.52228212        nan 0.863531   0.79150045 0.93271339 0.52228212\n",
      " 0.52132974        nan 0.52228212 0.52228212 0.52228212 0.52228212\n",
      " 0.93176999 0.81615454 0.93176999 0.52228212 0.52228212 0.89763702\n",
      " 0.88253369 0.52228212 0.94787062 0.59522911 0.71280323 0.52228212\n",
      " 0.52228212 0.52228212 0.88253369 0.52228212 0.71280323 0.52228212\n",
      " 0.52228212 0.52228212 0.93176999 0.95359389 0.56302785 0.95263252\n",
      " 0.79150045 0.52228212 0.87020665 0.52228212 0.95263252 0.86255166\n",
      " 0.67867026        nan 0.52228212 0.86540881 0.95263252 0.88158131\n",
      " 0.52228212        nan 0.93176999 0.52228212 0.95263252 0.86920934\n",
      " 0.79150045 0.52228212 0.59522911 0.95263252 0.86920934 0.51656783\n",
      " 0.85598383 0.52228212 0.90237197 0.95359389 0.95263252 0.52228212\n",
      " 0.79810422 0.52228212 0.5592363  0.84365678 0.59522911 0.95074573\n",
      " 0.52228212        nan 0.95263252 0.59522911 0.52228212 0.52228212\n",
      " 0.52228212        nan 0.95263252 0.88726864 0.52228212 0.88158131\n",
      " 0.95359389        nan 0.52228212 0.79150045 0.52228212 0.85971249\n",
      " 0.95359389 0.95263252 0.81520216 0.6132345  0.52228212 0.84932615\n",
      " 0.52228212 0.95263252 0.74504043 0.52228212 0.95263252 0.52228212\n",
      " 0.52228212 0.52228212 0.95263252 0.91284816        nan 0.59522911\n",
      " 0.52228212 0.90237197 0.95359389 0.95359389 0.52228212 0.90140162\n",
      " 0.66920036 0.81615454 0.52228212 0.52228212 0.95359389 0.90237197\n",
      "        nan 0.86540881 0.88158131 0.88253369 0.81615454 0.52228212\n",
      " 0.87686433 0.85971249 0.88725966 0.81615454 0.6132345  0.86920934\n",
      " 0.90427673 0.95263252        nan 0.86920934 0.8663522  0.52228212\n",
      " 0.95263252 0.52228212        nan 0.94219227 0.88253369 0.59522911\n",
      "        nan 0.81615454 0.52228212 0.90237197 0.52228212 0.52228212\n",
      " 0.95359389 0.86255166 0.81520216 0.7649416  0.52228212 0.92702606]\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rssvc = RandomizedSearchCV(estimator = svc, param_distributions = hyperparameters, n_iter =300, cv=10, random_state=42).fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.001, degree=1, gamma=1000, kernel=&#x27;poly&#x27;, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.001, degree=1, gamma=1000, kernel=&#x27;poly&#x27;, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.001, degree=1, gamma=1000, kernel='poly', max_iter=1000)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rssvc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9514348785871964\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       244\n",
      "           1       0.96      0.93      0.95       209\n",
      "\n",
      "    accuracy                           0.95       453\n",
      "   macro avg       0.95      0.95      0.95       453\n",
      "weighted avg       0.95      0.95      0.95       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=rssvc.best_estimator_.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (EMINEM DF): 0.9732142857142857\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       203\n",
      "           1       1.00      0.95      0.97       245\n",
      "\n",
      "    accuracy                           0.97       448\n",
      "   macro avg       0.97      0.98      0.97       448\n",
      "weighted avg       0.97      0.97      0.97       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=rssvc.best_estimator_.predict(em_x)\n",
    "accuracy = accuracy_score(em_y, predictions)\n",
    "print(f\"Test Accuracy (EMINEM DF): {accuracy}\")\n",
    "\n",
    "class_report = classification_report(em_y, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "better performance with eminem dataset using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_svc=rssvc.best_estimator_\n",
    "spam_nb=multinomial_nb_random.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Models Wih Translated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try models on translated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_spam_filtered = translated_df.copy()\n",
    "#svm_spam_filtered = translated_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_spam_filtered[\"comment_cleaned\"] = nb_spam_filtered[\"comment\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "\n",
    "ps = PorterStemmer() \n",
    "for w in nb_spam_filtered[\"comment\"]: \n",
    "    #remove punctuation\n",
    "    nb_spam_filtered[\"comment_cleaned\"] = nb_spam_filtered[\"comment\"].str.replace('[^\\w\\s]','')\n",
    "    nb_spam_filtered[\"comment_cleaned\"] = nb_spam_filtered[\"comment\"].str.lower()\n",
    "    nb_spam_filtered[\"comment_cleaned\"] = nb_spam_filtered[\"comment\"].apply(ps.stem) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_spam_filtered = nb_spam_filtered.copy() #so no need to go through same cleaning/preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "      <td>loved the calmness of manilla.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "      <td>after this pandemic i think every country shou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>manila looks beautifull with less peopl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "      <td>the lockdown makes the city look like a place ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "      <td>india also sam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  aLZ85hb4wjE                     Loved the calmness of Manilla.   \n",
       "1  aLZ85hb4wjE  After this pandemic I think every country shou...   \n",
       "2  aLZ85hb4wjE           manila looks beautifull with less people   \n",
       "3  aLZ85hb4wjE  The lockdown makes the city look like a place ...   \n",
       "4  aLZ85hb4wjE                                    India also same   \n",
       "\n",
       "                                     comment_cleaned  spam  \n",
       "0                     loved the calmness of manilla.     0  \n",
       "1  after this pandemic i think every country shou...     0  \n",
       "2            manila looks beautifull with less peopl     0  \n",
       "3  the lockdown makes the city look like a place ...     1  \n",
       "4                                     india also sam     0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = vectorizer.transform(nb_spam_filtered[\"comment_cleaned\"])\n",
    "\n",
    "nb_spam_filtered[\"spam\"]=spam_nb.predict(transformed)\n",
    "nb_spam_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           383\n",
       "comment            383\n",
       "comment_cleaned    383\n",
       "spam               383\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_spam_filtered[nb_spam_filtered[\"spam\"]==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           833\n",
       "comment            833\n",
       "comment_cleaned    833\n",
       "spam               833\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_spam_filtered[nb_spam_filtered[\"spam\"]==0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "      <td>loved the calmness of manilla.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "      <td>after this pandemic i think every country shou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>manila looks beautifull with less peopl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "      <td>the lockdown makes the city look like a place ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "      <td>india also sam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  aLZ85hb4wjE                     Loved the calmness of Manilla.   \n",
       "1  aLZ85hb4wjE  After this pandemic I think every country shou...   \n",
       "2  aLZ85hb4wjE           manila looks beautifull with less people   \n",
       "3  aLZ85hb4wjE  The lockdown makes the city look like a place ...   \n",
       "4  aLZ85hb4wjE                                    India also same   \n",
       "\n",
       "                                     comment_cleaned  spam  \n",
       "0                     loved the calmness of manilla.     0  \n",
       "1  after this pandemic i think every country shou...     0  \n",
       "2            manila looks beautifull with less peopl     0  \n",
       "3  the lockdown makes the city look like a place ...     0  \n",
       "4                                     india also sam     0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = vectorizer.transform(svm_spam_filtered[\"comment_cleaned\"])\n",
    "\n",
    "svm_spam_filtered[\"spam\"]=spam_svc.predict(transformed)\n",
    "svm_spam_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           94\n",
       "comment            94\n",
       "comment_cleaned    94\n",
       "spam               94\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_spam_filtered[svm_spam_filtered[\"spam\"]==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           1122\n",
       "comment            1122\n",
       "comment_cleaned    1122\n",
       "spam               1122\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_spam_filtered[svm_spam_filtered[\"spam\"]==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dIsaz_XlmTw</td>\n",
       "      <td>Is the covid BS 1 variant still coming</td>\n",
       "      <td>is the covid bs 1 variant still com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>nTUWK8vufOk</td>\n",
       "      <td>I am so glad that they also tackled the mental...</td>\n",
       "      <td>i am so glad that they also tackled the mental...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>cPVE7QGS7As</td>\n",
       "      <td>Deaths have been low compared to other countri...</td>\n",
       "      <td>deaths have been low compared to other countri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>lw16DeB6zns</td>\n",
       "      <td>Tthis was really confusing, plss fix ur news w...</td>\n",
       "      <td>tthis was really confusing, plss fix ur news w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>lw16DeB6zns</td>\n",
       "      <td>its kinda cute to read angry Pinoy comments</td>\n",
       "      <td>its kinda cute to read angry pinoy com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>lw0rcwYyiwE</td>\n",
       "      <td>VARIANT XZY IS NEXT PLEASE LOCK UP THE POLITIC...</td>\n",
       "      <td>variant xzy is next please lock up the politician</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>lw0rcwYyiwE</td>\n",
       "      <td>Next variant would be Alpha/Omega \\r\\nNext is ...</td>\n",
       "      <td>next variant would be alpha/omega \\r\\nnext is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>Y-xQtgvNuvA</td>\n",
       "      <td>In the Philippines, mandatory faceshields and ...</td>\n",
       "      <td>in the philippines, mandatory faceshields and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>W7n2FoRinVk</td>\n",
       "      <td>I went to the vaccine center today for booster...</td>\n",
       "      <td>i went to the vaccine center today for booster...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>It's been almost 2 years of this, and how many...</td>\n",
       "      <td>it's been almost 2 years of this, and how many...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                            comment  \\\n",
       "25    dIsaz_XlmTw             Is the covid BS 1 variant still coming   \n",
       "47    nTUWK8vufOk  I am so glad that they also tackled the mental...   \n",
       "58    cPVE7QGS7As  Deaths have been low compared to other countri...   \n",
       "65    lw16DeB6zns  Tthis was really confusing, plss fix ur news w...   \n",
       "69    lw16DeB6zns        its kinda cute to read angry Pinoy comments   \n",
       "...           ...                                                ...   \n",
       "1163  lw0rcwYyiwE  VARIANT XZY IS NEXT PLEASE LOCK UP THE POLITIC...   \n",
       "1164  lw0rcwYyiwE  Next variant would be Alpha/Omega \\r\\nNext is ...   \n",
       "1187  Y-xQtgvNuvA  In the Philippines, mandatory faceshields and ...   \n",
       "1190  W7n2FoRinVk  I went to the vaccine center today for booster...   \n",
       "1207  5DvMPgoKZmM  It's been almost 2 years of this, and how many...   \n",
       "\n",
       "                                        comment_cleaned  spam  \n",
       "25                  is the covid bs 1 variant still com     1  \n",
       "47    i am so glad that they also tackled the mental...     1  \n",
       "58    deaths have been low compared to other countri...     1  \n",
       "65    tthis was really confusing, plss fix ur news w...     1  \n",
       "69               its kinda cute to read angry pinoy com     1  \n",
       "...                                                 ...   ...  \n",
       "1163  variant xzy is next please lock up the politician     1  \n",
       "1164  next variant would be alpha/omega \\r\\nnext is ...     1  \n",
       "1187  in the philippines, mandatory faceshields and ...     1  \n",
       "1190  i went to the vaccine center today for booster...     1  \n",
       "1207  it's been almost 2 years of this, and how many...     1  \n",
       "\n",
       "[94 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_spam_filtered[svm_spam_filtered[\"spam\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "      <td>loved the calmness of manilla.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "      <td>after this pandemic i think every country shou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>manila looks beautifull with less peopl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "      <td>the lockdown makes the city look like a place ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "      <td>india also sam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>This covid will be a never-ending fuckery as l...</td>\n",
       "      <td>this covid will be a never-ending fuckery as l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>A new variant is inevitable.</td>\n",
       "      <td>a new variant is inevitable.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>The man that should resign from his office is ...</td>\n",
       "      <td>the man that should resign from his office is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>Is that the people who got been vaccinated.,</td>\n",
       "      <td>is that the people who got been vaccinated.,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>The toxic of comments section 😄 \\r\\n During th...</td>\n",
       "      <td>the toxic of comments section 😄 \\r\\n during th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1122 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                            comment  \\\n",
       "0     aLZ85hb4wjE                     Loved the calmness of Manilla.   \n",
       "1     aLZ85hb4wjE  After this pandemic I think every country shou...   \n",
       "2     aLZ85hb4wjE           manila looks beautifull with less people   \n",
       "3     aLZ85hb4wjE  The lockdown makes the city look like a place ...   \n",
       "4     aLZ85hb4wjE                                    India also same   \n",
       "...           ...                                                ...   \n",
       "1211  5DvMPgoKZmM  This covid will be a never-ending fuckery as l...   \n",
       "1212  5DvMPgoKZmM                       A new variant is inevitable.   \n",
       "1213  5DvMPgoKZmM  The man that should resign from his office is ...   \n",
       "1214  5DvMPgoKZmM       Is that the people who got been vaccinated.,   \n",
       "1215  5DvMPgoKZmM  The toxic of comments section 😄 \\r\\n During th...   \n",
       "\n",
       "                                        comment_cleaned  spam  \n",
       "0                        loved the calmness of manilla.     0  \n",
       "1     after this pandemic i think every country shou...     0  \n",
       "2               manila looks beautifull with less peopl     0  \n",
       "3     the lockdown makes the city look like a place ...     0  \n",
       "4                                        india also sam     0  \n",
       "...                                                 ...   ...  \n",
       "1211  this covid will be a never-ending fuckery as l...     0  \n",
       "1212                       a new variant is inevitable.     0  \n",
       "1213  the man that should resign from his office is ...     0  \n",
       "1214       is that the people who got been vaccinated.,     0  \n",
       "1215  the toxic of comments section 😄 \\r\\n during th...     0  \n",
       "\n",
       "[1122 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_spam_filtered[svm_spam_filtered[\"spam\"]==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Israel-Palestine comments check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>No matter how many times these information get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>*To learn who RULES over you, simply find out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Say that part again: Jewish , Christian’s and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Let peace prevail.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Why start at 1946?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment\n",
       "0  R0ftmf_Uv9A  No matter how many times these information get...\n",
       "1  R0ftmf_Uv9A  *To learn who RULES over you, simply find out ...\n",
       "2  R0ftmf_Uv9A  Say that part again: Jewish , Christian’s and ...\n",
       "3  R0ftmf_Uv9A                                 Let peace prevail.\n",
       "4  R0ftmf_Uv9A                                 Why start at 1946?"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_df = pd.read_csv(\"../datasets/israeli-palestine_conflict_history/comments.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "is_pal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pal_nb= is_pal_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pal_nb[\"comment_cleaned\"] = is_pal_nb[\"comment\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "\n",
    "ps = PorterStemmer() \n",
    "for w in is_pal_df[\"comment\"]:     \n",
    "    is_pal_nb[\"comment_cleaned\"] = is_pal_nb[\"comment\"].str.lower()\n",
    "    is_pal_nb[\"comment_cleaned\"] = is_pal_nb[\"comment\"].str.replace('[^\\w\\s]','')\n",
    "    is_pal_nb[\"comment_cleaned\"] = is_pal_nb[\"comment\"].apply(ps.stem) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pal_svc = is_pal_nb.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>No matter how many times these information get...</td>\n",
       "      <td>no matter how many times these information get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>*To learn who RULES over you, simply find out ...</td>\n",
       "      <td>*to learn who rules over you, simply find out ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Say that part again: Jewish , Christian’s and ...</td>\n",
       "      <td>say that part again: jewish , christian’s and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Let peace prevail.</td>\n",
       "      <td>let peace prevail.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Why start at 1946?</td>\n",
       "      <td>why start at 1946?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  R0ftmf_Uv9A  No matter how many times these information get...   \n",
       "1  R0ftmf_Uv9A  *To learn who RULES over you, simply find out ...   \n",
       "2  R0ftmf_Uv9A  Say that part again: Jewish , Christian’s and ...   \n",
       "3  R0ftmf_Uv9A                                 Let peace prevail.   \n",
       "4  R0ftmf_Uv9A                                 Why start at 1946?   \n",
       "\n",
       "                                     comment_cleaned  spam  \n",
       "0  no matter how many times these information get...     0  \n",
       "1  *to learn who rules over you, simply find out ...     1  \n",
       "2  say that part again: jewish , christian’s and ...     1  \n",
       "3                                 let peace prevail.     0  \n",
       "4                                 why start at 1946?     0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = vectorizer.transform(is_pal_nb[\"comment_cleaned\"])\n",
    "\n",
    "is_pal_nb[\"spam\"]=spam_nb.predict(transformed)\n",
    "is_pal_nb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           694\n",
       "comment            694\n",
       "comment_cleaned    694\n",
       "spam               694\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_nb[is_pal_nb[\"spam\"]==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           1180\n",
       "comment            1180\n",
       "comment_cleaned    1180\n",
       "spam               1180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_nb[is_pal_nb[\"spam\"]==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>*To learn who RULES over you, simply find out ...</td>\n",
       "      <td>*to learn who rules over you, simply find out ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Say that part again: Jewish , Christian’s and ...</td>\n",
       "      <td>say that part again: jewish , christian’s and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Thank's Ireland, for being consistent n vocal ...</td>\n",
       "      <td>thank's ireland, for being consistent n vocal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bno1m1zhIWs</td>\n",
       "      <td>Insane how the HISTORY channel of all places a...</td>\n",
       "      <td>insane how the history channel of all places a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bno1m1zhIWs</td>\n",
       "      <td>Finally. An objective concise summary with no ...</td>\n",
       "      <td>finally. an objective concise summary with no ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>nUfWTHbCS78</td>\n",
       "      <td>Dear brother \\r\\nMy name is Alia Mohammed Jalu...</td>\n",
       "      <td>dear brother \\r\\nmy name is alia mohammed jalu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>nUfWTHbCS78</td>\n",
       "      <td>The truth is out there....  Why do people not ...</td>\n",
       "      <td>the truth is out there....  why do people not ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>nUfWTHbCS78</td>\n",
       "      <td>Norman is a true gem of a human being \\nI pray...</td>\n",
       "      <td>norman is a true gem of a human being \\ni pray...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>nUfWTHbCS78</td>\n",
       "      <td>An asset for this issue -explains the issue wi...</td>\n",
       "      <td>an asset for this issue -explains the issue wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>nUfWTHbCS78</td>\n",
       "      <td>Thank you Norman for dedicating your life to t...</td>\n",
       "      <td>thank you norman for dedicating your life to t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>694 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                            comment  \\\n",
       "1     R0ftmf_Uv9A  *To learn who RULES over you, simply find out ...   \n",
       "2     R0ftmf_Uv9A  Say that part again: Jewish , Christian’s and ...   \n",
       "5     R0ftmf_Uv9A  Thank's Ireland, for being consistent n vocal ...   \n",
       "11    Bno1m1zhIWs  Insane how the HISTORY channel of all places a...   \n",
       "12    Bno1m1zhIWs  Finally. An objective concise summary with no ...   \n",
       "...           ...                                                ...   \n",
       "1866  nUfWTHbCS78  Dear brother \\r\\nMy name is Alia Mohammed Jalu...   \n",
       "1868  nUfWTHbCS78  The truth is out there....  Why do people not ...   \n",
       "1869  nUfWTHbCS78  Norman is a true gem of a human being \\nI pray...   \n",
       "1870  nUfWTHbCS78  An asset for this issue -explains the issue wi...   \n",
       "1871  nUfWTHbCS78  Thank you Norman for dedicating your life to t...   \n",
       "\n",
       "                                        comment_cleaned  spam  \n",
       "1     *to learn who rules over you, simply find out ...     1  \n",
       "2     say that part again: jewish , christian’s and ...     1  \n",
       "5     thank's ireland, for being consistent n vocal ...     1  \n",
       "11    insane how the history channel of all places a...     1  \n",
       "12    finally. an objective concise summary with no ...     1  \n",
       "...                                                 ...   ...  \n",
       "1866  dear brother \\r\\nmy name is alia mohammed jalu...     1  \n",
       "1868  the truth is out there....  why do people not ...     1  \n",
       "1869  norman is a true gem of a human being \\ni pray...     1  \n",
       "1870  an asset for this issue -explains the issue wi...     1  \n",
       "1871  thank you norman for dedicating your life to t...     1  \n",
       "\n",
       "[694 rows x 4 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_nb[is_pal_nb[\"spam\"]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>No matter how many times these information get...</td>\n",
       "      <td>no matter how many times these information get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>*To learn who RULES over you, simply find out ...</td>\n",
       "      <td>*to learn who rules over you, simply find out ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Say that part again: Jewish , Christian’s and ...</td>\n",
       "      <td>say that part again: jewish , christian’s and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Let peace prevail.</td>\n",
       "      <td>let peace prevail.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Why start at 1946?</td>\n",
       "      <td>why start at 1946?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  R0ftmf_Uv9A  No matter how many times these information get...   \n",
       "1  R0ftmf_Uv9A  *To learn who RULES over you, simply find out ...   \n",
       "2  R0ftmf_Uv9A  Say that part again: Jewish , Christian’s and ...   \n",
       "3  R0ftmf_Uv9A                                 Let peace prevail.   \n",
       "4  R0ftmf_Uv9A                                 Why start at 1946?   \n",
       "\n",
       "                                     comment_cleaned  spam  \n",
       "0  no matter how many times these information get...     0  \n",
       "1  *to learn who rules over you, simply find out ...     0  \n",
       "2  say that part again: jewish , christian’s and ...     1  \n",
       "3                                 let peace prevail.     0  \n",
       "4                                 why start at 1946?     0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = vectorizer.transform(is_pal_svc[\"comment_cleaned\"])\n",
    "\n",
    "is_pal_svc[\"spam\"]=spam_svc.predict(transformed)\n",
    "is_pal_svc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           231\n",
       "comment            231\n",
       "comment_cleaned    231\n",
       "spam               231\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_df[is_pal_df[\"spam\"]==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           1643\n",
       "comment            1643\n",
       "comment_cleaned    1643\n",
       "spam               1643\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_df[is_pal_df[\"spam\"]==0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like SVM works better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "      <td>loved the calmness of manilla.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "      <td>after this pandemic i think every country shou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>manila looks beautifull with less peopl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "      <td>the lockdown makes the city look like a place ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "      <td>india also sam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  aLZ85hb4wjE                     Loved the calmness of Manilla.   \n",
       "1  aLZ85hb4wjE  After this pandemic I think every country shou...   \n",
       "2  aLZ85hb4wjE           manila looks beautifull with less people   \n",
       "3  aLZ85hb4wjE  The lockdown makes the city look like a place ...   \n",
       "4  aLZ85hb4wjE                                    India also same   \n",
       "\n",
       "                                     comment_cleaned  spam  \n",
       "0                     loved the calmness of manilla.     0  \n",
       "1  after this pandemic i think every country shou...     0  \n",
       "2            manila looks beautifull with less peopl     0  \n",
       "3  the lockdown makes the city look like a place ...     0  \n",
       "4                                     india also sam     0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_filtered_out_df = svm_spam_filtered[svm_spam_filtered[\"spam\"]==0]\n",
    "covid_filtered_out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>No matter how many times these information get...</td>\n",
       "      <td>no matter how many times these information get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>*To learn who RULES over you, simply find out ...</td>\n",
       "      <td>*to learn who rules over you, simply find out ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Let peace prevail.</td>\n",
       "      <td>let peace prevail.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Why start at 1946?</td>\n",
       "      <td>why start at 1946?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Thank's Ireland, for being consistent n vocal ...</td>\n",
       "      <td>thank's ireland, for being consistent n vocal ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  R0ftmf_Uv9A  No matter how many times these information get...   \n",
       "1  R0ftmf_Uv9A  *To learn who RULES over you, simply find out ...   \n",
       "3  R0ftmf_Uv9A                                 Let peace prevail.   \n",
       "4  R0ftmf_Uv9A                                 Why start at 1946?   \n",
       "5  R0ftmf_Uv9A  Thank's Ireland, for being consistent n vocal ...   \n",
       "\n",
       "                                     comment_cleaned  spam  \n",
       "0  no matter how many times these information get...     0  \n",
       "1  *to learn who rules over you, simply find out ...     0  \n",
       "3                                 let peace prevail.     0  \n",
       "4                                 why start at 1946?     0  \n",
       "5  thank's ireland, for being consistent n vocal ...     0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_filtered_df = is_pal_df[is_pal_df[\"spam\"]==0]\n",
    "is_pal_filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import re\n",
    "from scipy.special import softmax\n",
    "\n",
    "def roberta_sentiment_scores(list_comments):\n",
    "    roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "    labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "\n",
    "    for comments in list_comments:\n",
    "        comment_words = []\n",
    "        comments = comments.replace(\"\\n\", \" \")\n",
    "        comments = comments.replace(\"\\xa0\", \" \")\n",
    "        comments = comments.replace(\"?\", \" \")\n",
    "        comments = comments.replace(\":\", \" \")\n",
    "        comments = comments.replace(\";\", \" \")\n",
    "        comments = comments.replace(\";\", \" \")\n",
    "        comments = re.sub(r\"\\s+\", ' ', comments) \n",
    "        print(comments)\n",
    "        for word in comments.split(' '):\n",
    "            if word.startswith('@') and len(word) > 1:\n",
    "               word = '@user'\n",
    "        \n",
    "            elif word.startswith('http'):\n",
    "                word = \"http\"\n",
    "            comment_words.append(word)\n",
    "\n",
    "        comment_procs = \" \".join(comment_words)\n",
    "\n",
    "        encoded = tokenizer(comment_procs, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "        print(encoded)\n",
    "        output = model(**encoded)\n",
    "\n",
    "        scores = output[0][0].detach().numpy()\n",
    "\n",
    "        scores = softmax(scores)\n",
    "\n",
    "        for i in range(len(scores)):\n",
    "\n",
    "            l = labels[i]\n",
    "            s = scores[i]\n",
    "            print(l, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved the calmness of Manilla.\n",
      "{'input_ids': tensor([[    0,   574, 12677,     5,  6327,  1825,     9,  1554,  4699,     4,\n",
      "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.0026419058\n",
      "Neutral 0.031785045\n",
      "Positive 0.9655731\n",
      "After this pandemic I think every country should have a lockdown every month to give mother nature a time to heal, with all the pollution that the earth is experiencing.\n",
      "{'input_ids': tensor([[    0,  4993,    42, 23387, 14414,    38,   206,   358,   247,   197,\n",
      "            33,    10, 23076,   358,   353,     7,   492,   985,  2574,    10,\n",
      "            86,     7, 14384,     6,    19,    70,     5,  6631,    14,     5,\n",
      "          6872,    16,  7242,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.72357625\n",
      "Neutral 0.25514364\n",
      "Positive 0.021280115\n",
      "manila looks beautifull with less people\n",
      "{'input_ids': tensor([[    0,   397,  4882,  1326, 28651,  1594,  5023,    19,   540,    82,\n",
      "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.023302699\n",
      "Neutral 0.14321633\n",
      "Positive 0.83348095\n",
      "The lockdown makes the city look like a place I want to explore. Before the lockdown, it looked like a crowded mess filled with traffic and pollution.\n",
      "{'input_ids': tensor([[    0,   133, 23076,   817,     5,   343,   356,   101,    10,   317,\n",
      "            38,   236,     7,  5393,     4,  3224,     5, 23076,     6,    24,\n",
      "          1415,   101,    10, 11138,  7319,  3820,    19,  1703,     8,  6631,\n",
      "             4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.41387478\n",
      "Neutral 0.4223302\n",
      "Positive 0.1637951\n",
      "India also same\n",
      "{'input_ids': tensor([[    0, 11015,    67,   276,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
      "Negative 0.081384994\n",
      "Neutral 0.8471448\n",
      "Positive 0.0714702\n",
      "The president promised that he'll do his best to ease the traffic in the metro like 5mins of travel along EDSA. Fortunately it happened but unfortunately it wasn't in the ideal way. Nature's sense of humor tho.\n",
      "{'input_ids': tensor([[    0,   133,   394,  3604,    14,    37,   581,   109,    39,   275,\n",
      "             7,  5136,     5,  1703,    11,     5, 12716,   101,   195, 30658,\n",
      "             9,  1504,   552, 12714,  3603,     4, 14802,    24,  1102,    53,\n",
      "          9574,    24,   938,    75,    11,     5,  5631,   169,     4, 10053,\n",
      "            18,  1472,     9, 12073, 41090,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.20141368\n",
      "Neutral 0.49210703\n",
      "Positive 0.3064793\n",
      "I went up the viewing spot at antipolo, its a very beautiful, almost smog free view of the metro skyline\n",
      "{'input_ids': tensor([[    0,   100,   439,    62,     5,  7603,  1514,    23, 37554,  5675,\n",
      "             6,    63,    10,   182,  2721,     6,   818,  5278,  2154,   481,\n",
      "          1217,     9,     5, 12716, 30728,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Negative 0.0017040264\n",
      "Neutral 0.021389995\n",
      "Positive 0.976906\n",
      "The sad part is people around the world did not intend to heal earth but afraid of death.\n",
      "{'input_ids': tensor([[    0,   133,  5074,   233,    16,    82,   198,     5,   232,   222,\n",
      "            45, 10557,     7, 14384,  6872,    53,  6023,     9,   744,     4,\n",
      "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.9466527\n",
      "Neutral 0.05063883\n",
      "Positive 0.0027084134\n",
      "i hope it stays like this forever its beautiful with no messy people\n",
      "{'input_ids': tensor([[    0,   118,  1034,    24, 10117,   101,    42,  6000,    63,  2721,\n",
      "            19,   117, 18882,    82,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.012420255\n",
      "Neutral 0.09276514\n",
      "Positive 0.8948146\n",
      "2020 is the year when nature fight back and reduce human emission dramatically.\n",
      "{'input_ids': tensor([[    0, 24837,    16,     5,    76,    77,  2574,  1032,   124,     8,\n",
      "          1888,  1050, 22679,  8617,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.03548623\n",
      "Neutral 0.45920116\n",
      "Positive 0.5053126\n",
      "Cough and cold season now because the weather is cold .... now covid again amg impression\n",
      "{'input_ids': tensor([[    0,   347,  4894,     8,  2569,   191,   122,   142,     5,  1650,\n",
      "            16,  2569, 39574,   122, 47268,   808,   456,   524,   571,  8450,\n",
      "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.5715849\n",
      "Neutral 0.38286152\n",
      "Positive 0.0455536\n",
      "Ala n covid tngina\n",
      "{'input_ids': tensor([[    0,  7083,   102,   295, 47268,   808,   326,  2590,  1243,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.20740348\n",
      "Neutral 0.66628414\n",
      "Positive 0.12631242\n",
      "This is how cold it is to just make it worse for those who make money\n",
      "{'input_ids': tensor([[   0,  713,   16,  141, 2569,   24,   16,    7,   95,  146,   24, 3007,\n",
      "           13,  167,   54,  146,  418,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.9579097\n",
      "Neutral 0.039565\n",
      "Positive 0.0025252388\n",
      "Has it been in Bahrain so the diseases were the same time when it was so old that it was so painful when it came to winter\n",
      "{'input_ids': tensor([[    0, 35634,    24,    57,    11, 13800,    98,     5,  6357,    58,\n",
      "             5,   276,    86,    77,    24,    21,    98,   793,    14,    24,\n",
      "            21,    98,  8661,    77,    24,   376,     7,  2608,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Negative 0.7892667\n",
      "Neutral 0.20188612\n",
      "Positive 0.008847155\n",
      "Season of cough and cold today here in Pinas after our cold day in the morning when it comes to the morning until the night is hot there is no aircon at home after entering work aircon their body temperature has changed before it does not get sick of cough and cold. .atibp\n",
      "{'input_ids': tensor([[    0, 37052,     9, 21768,     8,  2569,   452,   259,    11, 12009,\n",
      "           281,    71,    84,  2569,   183,    11,     5,   662,    77,    24,\n",
      "           606,     7,     5,   662,   454,     5,   363,    16,  2131,    89,\n",
      "            16,   117,   935,  3865,    23,   184,    71,  4201,   173,   935,\n",
      "          3865,    49,   809,  5181,    34,  1714,   137,    24,   473,    45,\n",
      "           120,  4736,     9, 21768,     8,  2569,     4,   479,   415,  1452,\n",
      "           642,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.44137755\n",
      "Neutral 0.46308964\n",
      "Positive 0.09553273\n",
      "It is difficult to cure 2_3wks.This is here in Nueva Ecija.\n",
      "{'input_ids': tensor([[    0,   243,    16,  1202,     7, 13306,   132,  1215,   246,   605,\n",
      "          2258,     4,   713,    16,   259,    11,   234,  1780,  3952,   381,\n",
      "          2520,  1910,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.65835446\n",
      "Neutral 0.3044711\n",
      "Positive 0.037174404\n",
      "Take a ginger drink ..\n",
      "{'input_ids': tensor([[    0, 21031,    10, 19863,  4076, 29942,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.023496099\n",
      "Neutral 0.8185454\n",
      "Positive 0.15795857\n",
      "It's not a joke to say that it's just a cold cold because my brother is the symptom of two hospitals we carry the same covid the outdoors also hard to breathe\n",
      "{'input_ids': tensor([[    0,   243,    18,    45,    10,  8018,     7,   224,    14,    24,\n",
      "            18,    95,    10,  2569,  2569,   142,   127,  2138,    16,     5,\n",
      "         28667,     9,    80,  4815,    52,  2324,     5,   276, 47268,   808,\n",
      "             5, 13384,    67,   543,     7, 14575,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.5769885\n",
      "Neutral 0.36087403\n",
      "Positive 0.062137436\n",
      "😊😊 😊\n",
      "{'input_ids': tensor([[    0, 18636, 27969, 18636, 27969, 17841, 27969,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.0031313696\n",
      "Neutral 0.068584144\n",
      "Positive 0.92828447\n",
      "There are many feverish fever here in the Philippines not just in China.\n",
      "{'input_ids': tensor([[    0,   970,    32,   171, 11696,  1173, 11696,   259,    11,     5,\n",
      "          5639,    45,    95,    11,   436,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.6582311\n",
      "Neutral 0.31710607\n",
      "Positive 0.024662782\n",
      "PRAISE GOD THERE ARE ONLY 18 CASES OUT OF 114 MILLION PEOPLE !! THANK YOU LORD WE ARE ALL HEALTHY ! COVID IS OVER !!\n",
      "{'input_ids': tensor([[    0,   510,  4396, 18819, 41827, 28842, 10616, 35669,   504, 24775,\n",
      "          1723, 14662,  3243, 15900, 34299,  7744, 16789, 43912, 42787, 10540,\n",
      "         45660, 10284, 10616, 12389, 12925, 33086,   975, 27785,  6247, 43814,\n",
      "          3703, 25133, 43912,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.004931455\n",
      "Neutral 0.048431896\n",
      "Positive 0.9466366\n",
      "DOH you have the power to report the height of the cases .. But backlogs of covid allowances of frontliners teach you a teach !!!!!\n",
      "{'input_ids': tensor([[    0,   495, 11979,    47,    33,     5,   476,     7,   266,     5,\n",
      "          6958,     9,     5,  1200, 29942,   125, 14846,    29,     9, 47268,\n",
      "           808, 23885,     9,   760, 18444,  6396,    47,    10,  6396, 43912,\n",
      "         16506,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.5291133\n",
      "Neutral 0.42791548\n",
      "Positive 0.04297118\n",
      "wow ! GOOD NEWS ! glad we are all safe and there is near zero cases of covid ! 🤗\n",
      "{'input_ids': tensor([[    0, 34798, 27785, 31708,  7857, 27785,  7785,    52,    32,    70,\n",
      "          1522,     8,    89,    16,   583,  4276,  1200,     9, 47268,   808,\n",
      "         27785,  8103, 10470,  6800,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Negative 0.004520912\n",
      "Neutral 0.027586922\n",
      "Positive 0.96789217\n",
      "Thanks a Lot/ DOH- Keep all Our Health Well!!!❤😊\n",
      "{'input_ids': tensor([[    0, 22086,    10, 11973,    73, 14010,   725,    12,  7238,    70,\n",
      "          1541,  1309,  2647, 16506, 30151, 10470, 18636, 27969,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.0011429677\n",
      "Neutral 0.027316816\n",
      "Positive 0.9715403\n",
      "To those who say 18 cases are only detected. They say they detect 18 cases of JN.1. So in other variants we have no news. But good news padin. Hopefully it's just low cases.\n",
      "{'input_ids': tensor([[    0,  3972,   167,    54,   224,   504,  1200,    32,   129, 12333,\n",
      "             4,   252,   224,    51, 10933,   504,  1200,     9,   344,   487,\n",
      "             4,   134,     4,   407,    11,    97, 21740,    52,    33,   117,\n",
      "           340,     4,   125,   205,   340, 11212,   179,     4, 13088,    24,\n",
      "            18,    95,   614,  1200,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.09744214\n",
      "Neutral 0.54689276\n",
      "Positive 0.35566503\n",
      "here we go again\n",
      "{'input_ids': tensor([[    0, 10859,    52,   213,   456,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.57551485\n",
      "Neutral 0.3833746\n",
      "Positive 0.04111058\n",
      "Hmmm. this could be the triggering pin for the ....\n",
      "{'input_ids': tensor([[    0,   725, 41311,     4,    42,   115,    28,     5, 16902,  7756,\n",
      "            13,     5, 39574,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.35495794\n",
      "Neutral 0.6257598\n",
      "Positive 0.01928225\n",
      "Balik na naman ba tayo na ka hit tooth ache lang Covid na agad Or death due to a vehicular accident Galing Covid sa report \n",
      "{'input_ids': tensor([[    0, 35917,   967,  2750,   295,  7243, 17279,   326,   857,   139,\n",
      "          2750,  4661,   478, 13495,  4285,   700, 22682, 19150,   808,  2750,\n",
      "          5951,   625,  1793,   744,   528,     7,    10, 27102, 21953,  3213,\n",
      "           272,  8279, 19150,   808,  2241,   266,  1437,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.61488426\n",
      "Neutral 0.37239805\n",
      "Positive 0.012717769\n",
      "Others country in south east Asia, people are dying on the complication of the mutate virus COVID. As far as US several cases have been reported on ICU don't be so carefree extreme measures and social distancing is a must\n",
      "{'input_ids': tensor([[    0, 43813,   247,    11,  2077,  3017,  1817,     6,    82,    32,\n",
      "          8180,    15,     5, 36443,     9,     5, 16119,   877,  6793,  6247,\n",
      "         43814,     4,   287,   444,    25,   382,   484,  1200,    33,    57,\n",
      "           431,    15,  8242,   791,   218,    75,    28,    98,   575,  3743,\n",
      "          5004,  1797,     8,   592,  7018,  7710,    16,    10,   531,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Negative 0.86476046\n",
      "Neutral 0.1307641\n",
      "Positive 0.004475479\n",
      "200k excess death sa 💉💉💉💉, explain nyo pls lang.\n",
      "{'input_ids': tensor([[    0,  2619,   330,  7400,   744,  2241,  8103, 10659, 23171,  6569,\n",
      "         10659, 23171,  6569, 10659, 23171,  6569, 10659, 23171,     6,  3922,\n",
      "           295,  9839,  2968,    29, 22682,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "Negative 0.6907134\n",
      "Neutral 0.29440364\n",
      "Positive 0.014882902\n",
      "Take us back to work from home\n",
      "{'input_ids': tensor([[    0, 21031,   201,   124,     7,   173,    31,   184,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.11331079\n",
      "Neutral 0.8166681\n",
      "Positive 0.07002113\n",
      "can we use this po \n",
      "{'input_ids': tensor([[   0, 7424,   52,  304,   42, 4202, 1437,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.030302525\n",
      "Neutral 0.7931191\n",
      "Positive 0.1765784\n",
      "Permission to use this for my video presentation, thank you!\n",
      "{'input_ids': tensor([[    0, 20823, 12478,     7,   304,    42,    13,   127,   569,  5209,\n",
      "             6,  3392,    47,   328,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.0009896423\n",
      "Neutral 0.03443175\n",
      "Positive 0.96457857\n",
      "No comments odd\n",
      "{'input_ids': tensor([[   0, 3084, 1450, 8372,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
      "Negative 0.31256422\n",
      "Neutral 0.6460113\n",
      "Positive 0.041424446\n",
      "SANA MAY PART 2 NA LOCKDOWN THIS 2024\n",
      "{'input_ids': tensor([[    0,   104, 14629, 19105, 19713,   132,  8438,   226, 13181, 39200,\n",
      "         10652, 15294,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.034807835\n",
      "Neutral 0.8932153\n",
      "Positive 0.07197685\n",
      "Daddy Digs is frustrating\n",
      "{'input_ids': tensor([[    0, 36009, 16621,    29,    16, 10314,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.95266706\n",
      "Neutral 0.042314567\n",
      "Positive 0.005018393\n",
      "Let us remember that the reason why we had such high numbers or had COVID AT ALL was because this guy was afraid of hurting China's feelings by imposing a travel ban on them.\n",
      "{'input_ids': tensor([[    0,  7939,   201,  2145,    14,     5,  1219,   596,    52,    56,\n",
      "           215,   239,  1530,    50,    56,  6247, 43814,  3263, 12389,    21,\n",
      "           142,    42,  2173,    21,  6023,     9, 12780,   436,    18,  6453,\n",
      "            30, 13223,    10,  1504,  2020,    15,   106,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.65882885\n",
      "Neutral 0.3244862\n",
      "Positive 0.016684989\n",
      "Sweet un lock down, Daddy's voice is so sweet that people are looking forward to the lockdown. It means, everyone, Dad Digong's decision, is really salute to FPRRD because he is pressed during pandemic.\n",
      "{'input_ids': tensor([[    0, 35942,   542,  7014,   159,     6, 25455,    18,  2236,    16,\n",
      "            98,  4045,    14,    82,    32,   546,   556,     7,     5, 23076,\n",
      "             4,    85,   839,     6,   961,     6, 13404, 16621,  1657,    18,\n",
      "           568,     6,    16,   269, 23824,     7,   274,  4454, 34158,   142,\n",
      "            37,    16, 11224,   148, 23387, 14414,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.014324683\n",
      "Neutral 0.09721928\n",
      "Positive 0.888456\n",
      "Cure.\n",
      "{'input_ids': tensor([[   0,  347, 2407,    4,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
      "Negative 0.31450516\n",
      "Neutral 0.51580006\n",
      "Positive 0.16969474\n",
      "Just ask me so there is a booster avail on covid ngaun po.\n",
      "{'input_ids': tensor([[    0,  6785,  1394,   162,    98,    89,    16,    10, 27028, 22345,\n",
      "            15, 47268,   808,  6094,  7381,  4202,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.045634624\n",
      "Neutral 0.9055104\n",
      "Positive 0.048854902\n",
      "Slightly Rise! But hopefully the face mask is imandatory before it gets worse .. globally because it rises. But it would have taken action immediately rather than to be caught and pushed to the public to wear a face mask again\n",
      "{'input_ids': tensor([[    0,   104, 41720, 20644,   328,   125,  5952,     5,   652, 11445,\n",
      "            16,  4356,   463,  5257,   137,    24,  1516,  3007, 29942,  7197,\n",
      "           142,    24, 10185,     4,   125,    24,    74,    33,   551,   814,\n",
      "          1320,  1195,    87,     7,    28,  2037,     8,  3148,     7,     5,\n",
      "           285,     7,  3568,    10,   652, 11445,   456,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.5221928\n",
      "Neutral 0.40845758\n",
      "Positive 0.06934962\n",
      "As a Filipino student, online class is frustrating because our internet here sucks.\n",
      "{'input_ids': tensor([[    0,  1620,    10, 19890,  1294,     6,   804,  1380,    16, 10314,\n",
      "           142,    84,  2888,   259, 29384,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.9777641\n",
      "Neutral 0.01999423\n",
      "Positive 0.0022416082\n",
      "I hope the family was paid for being interviewed. They need support more than ever.\n",
      "{'input_ids': tensor([[   0,  100, 1034,    5,  284,   21, 1199,   13,  145, 7477,    4,  252,\n",
      "          240,  323,   55,   87,  655,    4,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.11213035\n",
      "Neutral 0.5301997\n",
      "Positive 0.3576699\n",
      "nothing is more heartbreaking than children forced to grow up before there time...\n",
      "{'input_ids': tensor([[    0, 23702,    16,    55, 17052,    87,   408,  1654,     7,  1733,\n",
      "            62,   137,    89,    86,   734,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.96249413\n",
      "Neutral 0.034035742\n",
      "Positive 0.003470091\n",
      "As a teacher in Malaysia I feel for these anak- anak . Be strong and be safe ,only education can change your life and your family , Praying for success from Malaysia .\n",
      "{'input_ids': tensor([[    0,  1620,    10,  3254,    11,  5697,    38,   619,    13,   209,\n",
      "            41,   677,    12,    41,   677,   479,  1456,   670,     8,    28,\n",
      "          1522,  2156,  8338,  1265,    64,   464,   110,   301,     8,   110,\n",
      "           284,  2156,  2869, 11918,    13,  1282,    31,  5697,   479,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.01727385\n",
      "Neutral 0.2490064\n",
      "Positive 0.73371977\n",
      "I was in the Philippines on a mission trip when Covid hit. After I was home in the US with my family, the worry I felt for the kids I'd met there was overwhelming. May God bless the Filipino people💙\n",
      "{'input_ids': tensor([[    0,   100,    21,    11,     5,  5639,    15,    10,  2511,  1805,\n",
      "            77, 19150,   808,   478,     4,   572,    38,    21,   184,    11,\n",
      "             5,   382,    19,   127,   284,     6,     5,  4022,    38,  1299,\n",
      "            13,     5,  1159,    38,  1017,  1145,    89,    21,  8642,     4,\n",
      "           392,  1840, 22212,     5, 19890,    82,  6569, 10659,    27,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Negative 0.13846323\n",
      "Neutral 0.41005006\n",
      "Positive 0.45148668\n",
      "The problem in the Philippines is that there are many less privileged, challenged people. The government officials and local government unit can be corrupt and don’t do their assigned jobs properly(not saying all of them but some or maybe most of them). The less privileged people and some teens just makes more babies and say having an accidental baby is a “blessing”. It is only a blessing if it was planned and both couple/parents are ready to have their own family. That is why many people are suffering from poverty because many people do not plan making their family. Then they blame everything to the government and if there are people doing better than them they want to pull others down. #crabmentality 🦀 I feel sorry for the challenged people but some of the people just make their own problems. Didn’t comment here to debate. Just giving my opinion ✌🏻\n",
      "{'input_ids': tensor([[    0,   133,   936,    11,     5,  5639,    16,    14,    89,    32,\n",
      "           171,   540, 18560,     6,  6835,    82,     4,    20,   168,   503,\n",
      "             8,   400,   168,  1933,    64,    28, 10334,     8,   218,    17,\n",
      "            27,    90,   109,    49,  5530,  1315,  5083,  1640,  3654,   584,\n",
      "            70,     9,   106,    53,   103,    50,  2085,   144,     9,   106,\n",
      "           322,    20,   540, 18560,    82,     8,   103,  7475,    95,   817,\n",
      "            55,  7272,     8,   224,   519,    41, 18305,  1928,    16,    10,\n",
      "            44,    48,   428,  1672,   154,    17,    46,     4,    85,    16,\n",
      "           129,    10, 14164,   114,    24,    21,  1904,     8,   258,   891,\n",
      "            73, 34846,    32,  1227,     7,    33,    49,   308,   284,     4,\n",
      "           280,    16,   596,   171,    82,    32,  3606,    31,  5263,   142,\n",
      "           171,    82,   109,    45,   563,   442,    49,   284,     4,  1892,\n",
      "            51,  4887,   960,     7,     5,   168,     8,   114,    89,    32,\n",
      "            82,   608,   357,    87,   106,    51,   236,     7,  2999,   643,\n",
      "           159,     4,   849,  8344,   873,  1757,  6948,  8103, 18164,  7471,\n",
      "            38,   619,  6661,    13,     5,  6835,    82,    53,   103,     9,\n",
      "             5,    82,    95,   146,    49,   308,  1272,     4, 31940,    17,\n",
      "            27,    90,  1129,   259,     7,  2625,     4,  1801,  1311,   127,\n",
      "          2979, 36174, 14285,  6569,  9357,  2023,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.8140413\n",
      "Neutral 0.16427885\n",
      "Positive 0.021679783\n",
      "I'm here out of curiosity if they include how there are so many errors/incomplete in the modules given to students for online study. It's like it never even went to proofreading before it was released. Even our senate wants an investigation on this matter. How can we have internationally competitive students if the materials provided to them has so many errors.\n",
      "{'input_ids': tensor([[    0,   100,   437,   259,    66,     9, 20610,   114,    51,   680,\n",
      "           141,    89,    32,    98,   171,  9126,    73,   179, 27527,    11,\n",
      "             5, 22744,   576,     7,   521,    13,   804,   892,     4,    85,\n",
      "            18,   101,    24,   393,   190,   439,     7,  6461, 30164,   137,\n",
      "            24,    21,   703,     4,  1648,    84, 22437,  1072,    41,   803,\n",
      "            15,    42,   948,     4,  1336,    64,    52,    33,  9275,  2695,\n",
      "           521,   114,     5,  3183,  1286,     7,   106,    34,    98,   171,\n",
      "          9126,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Negative 0.8120004\n",
      "Neutral 0.17527542\n",
      "Positive 0.0127241975\n",
      "Ah bless jonathan he is so determined while my niece in the philippines her parents send her to a private school provided everything and now she did not finish school what a spoilt brat. I wish jonathan finish a degree someday he deserve to be help\n",
      "{'input_ids': tensor([[    0, 17986, 22212,  1236,   261, 15322,    37,    16,    98,  3030,\n",
      "           150,   127, 21348,    11,     5,  7843, 33465,  3141,    69,  1041,\n",
      "          2142,    69,     7,    10,   940,   334,  1286,   960,     8,   122,\n",
      "            79,   222,    45,  2073,   334,    99,    10, 25222, 10325,  5378,\n",
      "           415,     4,    38,  2813,  1236,   261, 15322,  2073,    10,  3093,\n",
      "         23090,    37,  6565,     7,    28,   244,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.17547931\n",
      "Neutral 0.3221349\n",
      "Positive 0.50238574\n",
      "I want to sponsor Johnathan and help him finish school.\n",
      "{'input_ids': tensor([[    0,   100,   236,     7,  9242,   610, 15322,     8,   244,   123,\n",
      "          2073,   334,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.0048315045\n",
      "Neutral 0.19115195\n",
      "Positive 0.8040166\n"
     ]
    }
   ],
   "source": [
    "roberta_sentiment_scores(covid_filtered_out_df[\"comment\"][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST TEXTBLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def textblob_sentiment_scores(list_comments):\n",
    "    list_sentiment={}\n",
    "    for comment in list_comments:\n",
    "        testimonial = TextBlob(comment)\n",
    "        if (testimonial.sentiment.polarity > 0):\n",
    "            print(\"positive\", testimonial.sentiment.polarity)\n",
    "        elif (testimonial.sentiment.polarity < 0):\n",
    "            print(\"negative\", testimonial.sentiment.polarity)\n",
    "        else:\n",
    "            print(\"neutral\", testimonial.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive 0.7\n",
      "neutral 0.0\n",
      "negative -0.16666666666666666\n",
      "positive 0.11250000000000002\n",
      "neutral 0.0\n",
      "positive 0.44999999999999996\n",
      "positive 0.7\n",
      "negative -0.55\n",
      "positive 0.475\n",
      "neutral 0.0\n",
      "negative -0.6\n",
      "neutral 0.0\n",
      "negative -0.5\n",
      "negative -0.19999999999999998\n",
      "negative -0.45285714285714285\n",
      "negative -0.5\n",
      "neutral 0.0\n",
      "negative -0.3729166666666667\n",
      "neutral 0.0\n",
      "positive 0.2\n",
      "positive 0.48828125\n",
      "neutral 0.0\n",
      "positive 0.425\n",
      "positive 0.2\n",
      "positive 0.14375\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "negative -0.125\n",
      "positive 0.0020833333333333346\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "negative -0.16666666666666666\n",
      "neutral 0.0\n",
      "negative -0.4\n",
      "negative -0.14666666666666664\n",
      "positive 0.18611111111111112\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "negative -0.10166666666666668\n",
      "negative -0.35\n",
      "positive 0.5\n",
      "positive 0.09999999999999998\n",
      "positive 0.30833333333333335\n",
      "positive 0.5\n",
      "positive 0.18194444444444446\n",
      "positive 0.3\n",
      "neutral 0.0\n",
      "neutral 0.0\n"
     ]
    }
   ],
   "source": [
    "textblob_sentiment_scores(covid_filtered_out_df[\"comment\"][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST STANZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "def stanza_sentiment_scores(list_comments):\n",
    "    nlp = stanza.Pipeline('en', processors='tokenize,sentiment', tokenize_no_ssplit=True)\n",
    "\n",
    "    for comment in list_comments:\n",
    "        doc = nlp(comment.replace(\"\\n\", \" \"))\n",
    "        print(comment)\n",
    "    #doc.sentences[0].print_dependencies()\n",
    "        for i, sentence in enumerate(doc.sentences):\n",
    "            print(\"%d -> %d\" % (i, sentence.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 15:23:56 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ff4b3bc89549a9b48c77494402d36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 15:23:56 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-03-08 15:23:58 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2024-03-08 15:23:58 INFO: Using device: cpu\n",
      "2024-03-08 15:23:58 INFO: Loading: tokenize\n",
      "2024-03-08 15:23:59 INFO: Loading: mwt\n",
      "2024-03-08 15:23:59 INFO: Loading: sentiment\n",
      "2024-03-08 15:24:00 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved the calmness of Manilla.\n",
      "0 -> 2\n",
      "After this pandemic I think every country should have a lockdown every month to give mother nature a time to heal, with all the pollution that the earth is experiencing.\n",
      "0 -> 0\n",
      "manila looks beautifull with less people\n",
      "0 -> 2\n",
      "The lockdown makes the city look like a place I want to explore.\n",
      "\n",
      "Before the lockdown, it looked like a crowded mess filled with traffic and pollution.\n",
      "0 -> 0\n",
      "India also same\n",
      "0 -> 1\n",
      "The president promised that he'll do his best to ease the traffic in the metro like 5mins of travel along EDSA. Fortunately it happened but unfortunately it wasn't in the ideal way. Nature's sense of humor tho.\n",
      "0 -> 0\n",
      "I went up the viewing spot at antipolo, its a very beautiful, almost smog free view of the metro skyline\n",
      "0 -> 2\n",
      "The sad part is people around the world did not intend to heal earth but afraid of death.\n",
      "0 -> 1\n",
      "i hope it stays like this forever its beautiful with no messy people\n",
      "0 -> 2\n",
      "2020 is the year when nature fight back and reduce human emission dramatically.\n",
      "0 -> 1\n",
      "Cough and cold season now because the weather is cold .... now covid again amg impression\n",
      "0 -> 0\n",
      "Ala n covid tngina\n",
      "0 -> 1\n",
      "This is how cold it is to just make it worse for those who make money\n",
      "0 -> 0\n",
      "Has it been in Bahrain so the diseases were the same time when it was so old that it was so painful when it came to winter\n",
      "0 -> 0\n",
      "Season of cough and cold today here in Pinas after our cold day in the morning when it comes to the morning until the night is hot there is no aircon at home after entering work aircon their body temperature has changed before it does not get sick of cough and cold. .atibp\n",
      "0 -> 0\n",
      "It is difficult to cure 2_3wks.This is here in Nueva Ecija.\n",
      "0 -> 0\n",
      "Take a ginger drink ..\n",
      "0 -> 1\n",
      "It's not a joke to say that it's just a cold cold because my brother is the symptom of two hospitals we carry the same covid the outdoors also hard to breathe\n",
      "0 -> 0\n",
      "😊😊\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "😊\n",
      "0 -> 1\n",
      "There are many feverish fever here in the Philippines not just in China.\n",
      "0 -> 1\n",
      "PRAISE GOD THERE ARE ONLY 18 CASES OUT OF 114 MILLION PEOPLE !!\n",
      " THANK YOU LORD WE ARE ALL HEALTHY !\n",
      " COVID IS OVER !!\n",
      "0 -> 2\n",
      "DOH you have the power to report the height of the cases .. But backlogs of covid allowances of frontliners teach you a teach !!!!!\n",
      "0 -> 1\n",
      "wow ! GOOD NEWS ! glad we are all safe and there is near zero cases of covid ! 🤗\n",
      "0 -> 2\n",
      "Thanks a Lot/ DOH- Keep all Our Health Well!!!❤😊\n",
      "0 -> 2\n",
      "To those who say 18 cases are only detected. They say they detect 18 cases of JN.1. So in other variants we have no news. But good news padin. Hopefully it's just low cases.\n",
      "0 -> 0\n",
      "here we go again\n",
      "0 -> 1\n",
      "Hmmm. this could be the triggering pin for the ....\n",
      "0 -> 1\n",
      "Balik na naman ba tayo na ka hit tooth ache lang Covid na agad? Or death due to a vehicular accident  Galing Covid sa report?\n",
      "0 -> 1\n",
      "Others country in south east Asia, people are dying on the complication of the mutate virus COVID. As far as US several cases have been reported on ICU don't be so carefree extreme measures and social distancing is a must\n",
      "0 -> 0\n",
      "200k excess death sa 💉💉💉💉, explain nyo pls lang.\n",
      "0 -> 1\n",
      "Take us back to work from home\n",
      "0 -> 1\n",
      "can we use this po?\n",
      "0 -> 1\n",
      "Permission to use this for my video presentation, thank you!\n",
      "0 -> 2\n",
      "No comments odd\n",
      "0 -> 1\n",
      "SANA MAY PART 2 NA LOCKDOWN THIS 2024\n",
      "0 -> 1\n",
      "Daddy Digs is frustrating\n",
      "0 -> 0\n",
      "Let us remember that the reason why we had such high numbers or had COVID AT ALL was because this guy was afraid of hurting China's feelings by imposing a travel ban on them.\n",
      "0 -> 0\n",
      "Sweet un lock down, Daddy's voice is so sweet that people are looking forward to the lockdown. It means, everyone, Dad Digong's decision, is really salute to FPRRD because he is pressed during pandemic.\n",
      "0 -> 2\n",
      "Cure.\n",
      "0 -> 1\n",
      "Just ask me so there is a booster avail on covid ngaun po.\n",
      "0 -> 1\n",
      "Slightly Rise! But hopefully the face mask is imandatory before it gets worse .. globally because it rises. But it would have taken action immediately rather than to be caught and pushed to the public to wear a face mask again\n",
      "0 -> 0\n",
      "As a Filipino student, online class is frustrating because our internet here sucks.\n",
      "0 -> 0\n",
      "I hope the family was paid for being interviewed. They need support more than ever.\n",
      "0 -> 0\n",
      "nothing is more heartbreaking than children forced to grow up before there time...\n",
      "0 -> 2\n",
      "As a teacher in Malaysia I feel for these anak- anak . Be strong and be safe ,only education can change your life and your family , Praying for success from Malaysia .\n",
      "0 -> 1\n",
      "I was in the Philippines on a mission trip when Covid hit. After I was home in the US with my family, the worry I felt for the kids I'd met there was overwhelming. May God bless the Filipino people💙\n",
      "0 -> 1\n",
      "The problem in the Philippines is that there are many less privileged, challenged people. The government officials and local government unit can be corrupt and don’t do their assigned jobs properly(not saying all of them but some or maybe most of them). The less privileged people and some teens just makes more babies and say having an accidental baby is a “blessing”. It is only a blessing if it was planned and both couple/parents are ready to have their own family. That is why many people are suffering from poverty because many people do not plan making their family. Then they blame everything to the government and if there are people doing better than them they want to pull others down. #crabmentality 🦀 I feel sorry for the challenged people but some of the people just make their own problems.\n",
      "\n",
      "Didn’t comment here to debate. Just giving my opinion ✌🏻\n",
      "0 -> 0\n",
      "I'm here out of curiosity if they include how there are so many errors/incomplete in the modules given to students for online study. It's like it never even went to proofreading before it was released. Even our senate wants an investigation on this matter. How can we have internationally competitive students if the materials provided to them has so many errors.\n",
      "0 -> 0\n",
      "Ah bless jonathan he is so determined while my niece in the philippines her parents send her to a private school provided everything and now she did not finish school what a spoilt brat. I wish jonathan finish a degree someday he deserve to be help\n",
      "0 -> 0\n",
      "I want to sponsor Johnathan and help him finish school.\n",
      "0 -> 1\n"
     ]
    }
   ],
   "source": [
    "stanza_sentiment_scores(covid_filtered_out_df[\"comment\"][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def vader_sentiment_scores (list_comments):\n",
    "    for sentence in list_comments:\n",
    "        sid_obj = SentimentIntensityAnalyzer()\n",
    "        sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "        print(sentence)\n",
    "        print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
    "        print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
    "        print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
    "        print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
    " \n",
    "        print(\"Sentence Overall Rated As\", end = \" \")\n",
    " \n",
    "        # decide sentiment as positive, negative and neutral\n",
    "        if sentiment_dict['compound'] >= 0.05 :\n",
    "            print(\"Positive\")\n",
    " \n",
    "        elif sentiment_dict['compound'] <= - 0.05 :\n",
    "            print(\"Negative\")\n",
    " \n",
    "        else :\n",
    "            print(\"Neutral\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved the calmness of Manilla.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.312, 'pos': 0.688, 'compound': 0.765}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  31.2 % Neutral\n",
      "sentence was rated as  68.8 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "After this pandemic I think every country should have a lockdown every month to give mother nature a time to heal, with all the pollution that the earth is experiencing.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "manila looks beautifull with less people\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "The lockdown makes the city look like a place I want to explore.\n",
      "\n",
      "Before the lockdown, it looked like a crowded mess filled with traffic and pollution.\n",
      "Overall sentiment dictionary is :  {'neg': 0.079, 'neu': 0.723, 'pos': 0.198, 'compound': 0.4215}\n",
      "sentence was rated as  7.9 % Negative\n",
      "sentence was rated as  72.3 % Neutral\n",
      "sentence was rated as  19.8 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "India also same\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "The president promised that he'll do his best to ease the traffic in the metro like 5mins of travel along EDSA. Fortunately it happened but unfortunately it wasn't in the ideal way. Nature's sense of humor tho.\n",
      "Overall sentiment dictionary is :  {'neg': 0.143, 'neu': 0.635, 'pos': 0.222, 'compound': 0.1867}\n",
      "sentence was rated as  14.299999999999999 % Negative\n",
      "sentence was rated as  63.5 % Neutral\n",
      "sentence was rated as  22.2 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "I went up the viewing spot at antipolo, its a very beautiful, almost smog free view of the metro skyline\n",
      "Overall sentiment dictionary is :  {'neg': 0.082, 'neu': 0.644, 'pos': 0.273, 'compound': 0.7222}\n",
      "sentence was rated as  8.200000000000001 % Negative\n",
      "sentence was rated as  64.4 % Neutral\n",
      "sentence was rated as  27.3 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "The sad part is people around the world did not intend to heal earth but afraid of death.\n",
      "Overall sentiment dictionary is :  {'neg': 0.316, 'neu': 0.684, 'pos': 0.0, 'compound': -0.8126}\n",
      "sentence was rated as  31.6 % Negative\n",
      "sentence was rated as  68.4 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "i hope it stays like this forever its beautiful with no messy people\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.441, 'pos': 0.559, 'compound': 0.8862}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  44.1 % Neutral\n",
      "sentence was rated as  55.900000000000006 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "2020 is the year when nature fight back and reduce human emission dramatically.\n",
      "Overall sentiment dictionary is :  {'neg': 0.178, 'neu': 0.822, 'pos': 0.0, 'compound': -0.3818}\n",
      "sentence was rated as  17.8 % Negative\n",
      "sentence was rated as  82.19999999999999 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Cough and cold season now because the weather is cold .... now covid again amg impression\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.888, 'pos': 0.112, 'compound': 0.2263}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  88.8 % Neutral\n",
      "sentence was rated as  11.200000000000001 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Ala n covid tngina\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "This is how cold it is to just make it worse for those who make money\n",
      "Overall sentiment dictionary is :  {'neg': 0.171, 'neu': 0.829, 'pos': 0.0, 'compound': -0.4767}\n",
      "sentence was rated as  17.1 % Negative\n",
      "sentence was rated as  82.89999999999999 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Has it been in Bahrain so the diseases were the same time when it was so old that it was so painful when it came to winter\n",
      "Overall sentiment dictionary is :  {'neg': 0.126, 'neu': 0.874, 'pos': 0.0, 'compound': -0.5777}\n",
      "sentence was rated as  12.6 % Negative\n",
      "sentence was rated as  87.4 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Season of cough and cold today here in Pinas after our cold day in the morning when it comes to the morning until the night is hot there is no aircon at home after entering work aircon their body temperature has changed before it does not get sick of cough and cold. .atibp\n",
      "Overall sentiment dictionary is :  {'neg': 0.039, 'neu': 0.912, 'pos': 0.048, 'compound': 0.1285}\n",
      "sentence was rated as  3.9 % Negative\n",
      "sentence was rated as  91.2 % Neutral\n",
      "sentence was rated as  4.8 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "It is difficult to cure 2_3wks.This is here in Nueva Ecija.\n",
      "Overall sentiment dictionary is :  {'neg': 0.2, 'neu': 0.8, 'pos': 0.0, 'compound': -0.3612}\n",
      "sentence was rated as  20.0 % Negative\n",
      "sentence was rated as  80.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Take a ginger drink ..\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "It's not a joke to say that it's just a cold cold because my brother is the symptom of two hospitals we carry the same covid the outdoors also hard to breathe\n",
      "Overall sentiment dictionary is :  {'neg': 0.099, 'neu': 0.901, 'pos': 0.0, 'compound': -0.3156}\n",
      "sentence was rated as  9.9 % Negative\n",
      "sentence was rated as  90.10000000000001 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "😊😊\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "😊\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.333, 'pos': 0.667, 'compound': 0.9517}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  33.300000000000004 % Neutral\n",
      "sentence was rated as  66.7 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "There are many feverish fever here in the Philippines not just in China.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "PRAISE GOD THERE ARE ONLY 18 CASES OUT OF 114 MILLION PEOPLE !!\n",
      " THANK YOU LORD WE ARE ALL HEALTHY !\n",
      " COVID IS OVER !!\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.583, 'pos': 0.417, 'compound': 0.9432}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  58.3 % Neutral\n",
      "sentence was rated as  41.699999999999996 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "DOH you have the power to report the height of the cases .. But backlogs of covid allowances of frontliners teach you a teach !!!!!\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "wow ! GOOD NEWS ! glad we are all safe and there is near zero cases of covid ! 🤗\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.485, 'pos': 0.515, 'compound': 0.9517}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  48.5 % Neutral\n",
      "sentence was rated as  51.5 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Thanks a Lot/ DOH- Keep all Our Health Well!!!❤😊\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'compound': 0.944}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  40.6 % Neutral\n",
      "sentence was rated as  59.4 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "To those who say 18 cases are only detected. They say they detect 18 cases of JN.1. So in other variants we have no news. But good news padin. Hopefully it's just low cases.\n",
      "Overall sentiment dictionary is :  {'neg': 0.102, 'neu': 0.72, 'pos': 0.178, 'compound': 0.631}\n",
      "sentence was rated as  10.2 % Negative\n",
      "sentence was rated as  72.0 % Neutral\n",
      "sentence was rated as  17.8 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "here we go again\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Hmmm. this could be the triggering pin for the ....\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Balik na naman ba tayo na ka hit tooth ache lang Covid na agad? Or death due to a vehicular accident  Galing Covid sa report?\n",
      "Overall sentiment dictionary is :  {'neg': 0.312, 'neu': 0.688, 'pos': 0.0, 'compound': -0.8738}\n",
      "sentence was rated as  31.2 % Negative\n",
      "sentence was rated as  68.8 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Others country in south east Asia, people are dying on the complication of the mutate virus COVID. As far as US several cases have been reported on ICU don't be so carefree extreme measures and social distancing is a must\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.918, 'pos': 0.082, 'compound': 0.541}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  91.8 % Neutral\n",
      "sentence was rated as  8.200000000000001 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "200k excess death sa 💉💉💉💉, explain nyo pls lang.\n",
      "Overall sentiment dictionary is :  {'neg': 0.257, 'neu': 0.658, 'pos': 0.086, 'compound': -0.5574}\n",
      "sentence was rated as  25.7 % Negative\n",
      "sentence was rated as  65.8 % Neutral\n",
      "sentence was rated as  8.6 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Take us back to work from home\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "can we use this po?\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Permission to use this for my video presentation, thank you!\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'compound': 0.4199}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  76.3 % Neutral\n",
      "sentence was rated as  23.7 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "No comments odd\n",
      "Overall sentiment dictionary is :  {'neg': 0.426, 'neu': 0.194, 'pos': 0.38, 'compound': -0.0613}\n",
      "sentence was rated as  42.6 % Negative\n",
      "sentence was rated as  19.400000000000002 % Neutral\n",
      "sentence was rated as  38.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "SANA MAY PART 2 NA LOCKDOWN THIS 2024\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Daddy Digs is frustrating\n",
      "Overall sentiment dictionary is :  {'neg': 0.492, 'neu': 0.508, 'pos': 0.0, 'compound': -0.4404}\n",
      "sentence was rated as  49.2 % Negative\n",
      "sentence was rated as  50.8 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Let us remember that the reason why we had such high numbers or had COVID AT ALL was because this guy was afraid of hurting China's feelings by imposing a travel ban on them.\n",
      "Overall sentiment dictionary is :  {'neg': 0.199, 'neu': 0.801, 'pos': 0.0, 'compound': -0.7717}\n",
      "sentence was rated as  19.900000000000002 % Negative\n",
      "sentence was rated as  80.10000000000001 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Sweet un lock down, Daddy's voice is so sweet that people are looking forward to the lockdown. It means, everyone, Dad Digong's decision, is really salute to FPRRD because he is pressed during pandemic.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.823, 'pos': 0.177, 'compound': 0.7824}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  82.3 % Neutral\n",
      "sentence was rated as  17.7 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Cure.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Just ask me so there is a booster avail on covid ngaun po.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Slightly Rise! But hopefully the face mask is imandatory before it gets worse .. globally because it rises. But it would have taken action immediately rather than to be caught and pushed to the public to wear a face mask again\n",
      "Overall sentiment dictionary is :  {'neg': 0.095, 'neu': 0.837, 'pos': 0.068, 'compound': -0.3155}\n",
      "sentence was rated as  9.5 % Negative\n",
      "sentence was rated as  83.7 % Neutral\n",
      "sentence was rated as  6.800000000000001 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "As a Filipino student, online class is frustrating because our internet here sucks.\n",
      "Overall sentiment dictionary is :  {'neg': 0.329, 'neu': 0.671, 'pos': 0.0, 'compound': -0.6597}\n",
      "sentence was rated as  32.9 % Negative\n",
      "sentence was rated as  67.10000000000001 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "I hope the family was paid for being interviewed. They need support more than ever.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.699, 'pos': 0.301, 'compound': 0.6808}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  69.89999999999999 % Neutral\n",
      "sentence was rated as  30.099999999999998 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "nothing is more heartbreaking than children forced to grow up before there time...\n",
      "Overall sentiment dictionary is :  {'neg': 0.18, 'neu': 0.659, 'pos': 0.162, 'compound': -0.078}\n",
      "sentence was rated as  18.0 % Negative\n",
      "sentence was rated as  65.9 % Neutral\n",
      "sentence was rated as  16.2 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "As a teacher in Malaysia I feel for these anak- anak . Be strong and be safe ,only education can change your life and your family , Praying for success from Malaysia .\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.7, 'pos': 0.3, 'compound': 0.9081}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  70.0 % Neutral\n",
      "sentence was rated as  30.0 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "I was in the Philippines on a mission trip when Covid hit. After I was home in the US with my family, the worry I felt for the kids I'd met there was overwhelming. May God bless the Filipino people💙\n",
      "Overall sentiment dictionary is :  {'neg': 0.058, 'neu': 0.76, 'pos': 0.182, 'compound': 0.7351}\n",
      "sentence was rated as  5.800000000000001 % Negative\n",
      "sentence was rated as  76.0 % Neutral\n",
      "sentence was rated as  18.2 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "The problem in the Philippines is that there are many less privileged, challenged people. The government officials and local government unit can be corrupt and don’t do their assigned jobs properly(not saying all of them but some or maybe most of them). The less privileged people and some teens just makes more babies and say having an accidental baby is a “blessing”. It is only a blessing if it was planned and both couple/parents are ready to have their own family. That is why many people are suffering from poverty because many people do not plan making their family. Then they blame everything to the government and if there are people doing better than them they want to pull others down. #crabmentality 🦀 I feel sorry for the challenged people but some of the people just make their own problems.\n",
      "\n",
      "Didn’t comment here to debate. Just giving my opinion ✌🏻\n",
      "Overall sentiment dictionary is :  {'neg': 0.122, 'neu': 0.74, 'pos': 0.138, 'compound': 0.7006}\n",
      "sentence was rated as  12.2 % Negative\n",
      "sentence was rated as  74.0 % Neutral\n",
      "sentence was rated as  13.8 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "I'm here out of curiosity if they include how there are so many errors/incomplete in the modules given to students for online study. It's like it never even went to proofreading before it was released. Even our senate wants an investigation on this matter. How can we have internationally competitive students if the materials provided to them has so many errors.\n",
      "Overall sentiment dictionary is :  {'neg': 0.041, 'neu': 0.877, 'pos': 0.082, 'compound': 0.1647}\n",
      "sentence was rated as  4.1000000000000005 % Negative\n",
      "sentence was rated as  87.7 % Neutral\n",
      "sentence was rated as  8.200000000000001 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Ah bless jonathan he is so determined while my niece in the philippines her parents send her to a private school provided everything and now she did not finish school what a spoilt brat. I wish jonathan finish a degree someday he deserve to be help\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.788, 'pos': 0.212, 'compound': 0.8838}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  78.8 % Neutral\n",
      "sentence was rated as  21.2 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "I want to sponsor Johnathan and help him finish school.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.4588}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  66.7 % Neutral\n",
      "sentence was rated as  33.300000000000004 % Positive\n",
      "Sentence Overall Rated As Positive\n"
     ]
    }
   ],
   "source": [
    "vader_sentiment_scores (covid_filtered_out_df[\"comment\"][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sentiment sentiment for each video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEXTBLOB APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob_sentiment_scores(list_comments):\n",
    "    list_sentiment={}\n",
    "    for comment in list_comments:\n",
    "        testimonial = TextBlob(comment)\n",
    "        if (testimonial.sentiment.polarity > 0):\n",
    "            print(\"positive\", testimonial.sentiment.polarity)\n",
    "        elif (testimonial.sentiment.polarity < 0):\n",
    "            print(\"negative\", testimonial.sentiment.polarity)\n",
    "        else:\n",
    "            print(\"neutral\", testimonial.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aLZ85hb4wjE', 'sYI97jv-pZg', '3YFpjgIQqEo', 'dIsaz_XlmTw',\n",
       "       'DWxIvQlpJK8', 'pMUumjHY3tw', 'nTUWK8vufOk', 'cPVE7QGS7As',\n",
       "       'CEIrzjA8euQ', 'lw16DeB6zns', '8dTelszbObM', 'Mxf8uGFcqSE',\n",
       "       'MQ5aYS4YFlQ', 'iOE6rAY8l-k', '_a-rQYfsCck', 'jEINZXA_ujo',\n",
       "       '587N9bJ5J5k', 'E5F3xA_zkFc', '05JLyd58R-w', '2fRQ8OsqOLs',\n",
       "       'E56W-5xVOss', 'c1oU8U05puY', 'SEHcakm-fAc', '1psSvU1km0I',\n",
       "       'PP3Yu-ro1tA', 'NQeI1CRCqeo', 'RhDHGgo4yZg', 'sdsz-t540WI',\n",
       "       '7SKGXkZKjV8', 'oy0wHScCPds', 'o1kPskxFkQ8', 'aoNQUUQno00',\n",
       "       'liEUC1_l8e8', '-b0EuuMvvy8', 'MmyIvf7bEGc', 'Fd3HcncV6Zk',\n",
       "       '-n9Ks3VTub4', 'LzymJ2xZhho', '-qFcO_onBdA', 'fp9uRsmTWqg',\n",
       "       '3ZXR2eARmuQ', '57wz3HuIVLA', 'lbK7UjoLr8o', 'xV1oR-RbOGU',\n",
       "       'kn6DKdInYXk', '2T3yZ6lNRDg', 'HLYSlKY6Ww4', 'sH_YoV-NA6s',\n",
       "       'ZLT6L3PHz78', 'lczwrm68u6I', 'zhBdbLj5y6A', 'ibWFsmcnefk',\n",
       "       'e0fN7HxkIUc', 'Ji47WRv2tQE', 'dj5ov38ihZI', 'j3E3NF9nk44',\n",
       "       'BomdsEJjb0E', 'T7c6GvrF82k', '6DBFwIlT4fg', '2FgFNBIJTIA',\n",
       "       '254GdlKEz5I', 'y4qaoHc2ezk', '2VRGUm_wQ0w', 'HK5rfm4X2G0',\n",
       "       '_DM5L8uu1Do', 'pK6y1h0YgSU', 'a3-AiHSyTIU', 'SLrKdYsNbSo',\n",
       "       '8w61tigk0ag', 'Mwpqgw9gMfo', 'FJEMcVK0MWI', 'gRKL_FUQUpY',\n",
       "       'LLFcBFAuauk', 'EsW0ye2wjUQ', 'R0i7i80ToUM', '6zkba0hNiE8',\n",
       "       'T48EuGS36Zk', 'KzCjAetb3_I', 'N9OQbW0YOLU', 'I4WXmX_6Zds',\n",
       "       'WTD3l2xovQI', 'LtW0cTMWdbY', 'iVM-azf1Akk', 'xWV_GI9hq5U',\n",
       "       '-LFGaCkPzzY', 'rFDK10oplxA', '6p_8T_xmnLQ', 'D9-CHldoZ74',\n",
       "       'xqz1KueuzAM', 'T2JkwAZ8KY8', 'TQ0QJ4Si7A4', '81Fj00CFmJM',\n",
       "       'C-iuGrZR2pQ', 'JT1R95tG9jg', 'O06AlL8nONo', 'HabzHfgdMNs',\n",
       "       'o96VMbz4Zpk', 'XylXJJp4HpE', 'ZaTPlJ8nd9Q', 'R3E3RlBEIl8',\n",
       "       '5jCZ42fV6sw', 'tq7FyWSGaD4', 'jQusLZgOYac', 'iOnxb9jrY40',\n",
       "       'UWMmesK08TU', '4bub6WOlT-I', 'jIsXjk3TgkU', 'W8WAKyR5pGA',\n",
       "       'ZBO3c3ko0eg', 'FIiz8hqXm24', 'I3mkImSqHA0', 'DTUckJz0RGo',\n",
       "       'JWA5mUrrr_A', 'XqzQanN4Xx8', 'QjJwrWxwLJU', 'D7zMgv16cik',\n",
       "       'bJYGvO6V67A', 'sJ0xpruFAwQ', 'ENk_QRA2XsY', 'OB0qJwk5yA8',\n",
       "       '29LXKUT0eMY', 'Bo24jIb7GA8', '19hkLN7KEqc', '_quGokF8G0o',\n",
       "       'M7qPgEDk2JY', '-PqXVcMtygc', 'GUVKWAEO_hY', '_S_9JRwFmcA',\n",
       "       'LWIgEf_TMVU', 'aw59h2FNMIQ', 'lw0rcwYyiwE', 'sEjN7muHOLc',\n",
       "       'Y-xQtgvNuvA', 'W7n2FoRinVk', 'Wjj__vIdew0', '5DvMPgoKZmM'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_filtered_out_df[\"video_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_vid_textblob_polarity (df):\n",
    "    video_polarity={}\n",
    "    for video in df[\"video_id\"].unique():\n",
    "        sum_polarity=0\n",
    "        for comment in df.loc[df[\"video_id\"]==video][\"comment\"]:\n",
    "            sum_polarity+=(TextBlob(comment)).sentiment.polarity\n",
    "        video_polarity[video] = sum_polarity/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "    ''' if (testimonial.sentiment.polarity > 0):\n",
    "            print(\"positive\", testimonial.sentiment.subjectivity)\n",
    "        elif (testimonial.sentiment.polarity < 0):\n",
    "            print(\"negative\", testimonial.sentiment.subjectivity)\n",
    "        else:\n",
    "            print(\"neutral\", testimonial.sentiment.subjectivity)'''\n",
    "    return video_polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aLZ85hb4wjE': 0.1720833333333333,\n",
       " 'sYI97jv-pZg': -0.3,\n",
       " '3YFpjgIQqEo': -0.13374925595238094,\n",
       " 'dIsaz_XlmTw': 0.07175925925925926,\n",
       " 'DWxIvQlpJK8': -0.06590277777777777,\n",
       " 'pMUumjHY3tw': -0.05083333333333334,\n",
       " 'nTUWK8vufOk': 0.17114197530864197,\n",
       " 'cPVE7QGS7As': 0.38312003968253966,\n",
       " 'CEIrzjA8euQ': -0.25,\n",
       " 'lw16DeB6zns': 0.13262471655328797,\n",
       " '8dTelszbObM': 0.20164552024308124,\n",
       " 'Mxf8uGFcqSE': 0.16666666666666666,\n",
       " 'MQ5aYS4YFlQ': 0.23005483405483407,\n",
       " 'iOE6rAY8l-k': 0.03368055555555556,\n",
       " '_a-rQYfsCck': 0.05265151515151515,\n",
       " 'jEINZXA_ujo': 0.37429292929292923,\n",
       " '587N9bJ5J5k': 0.10679012345679012,\n",
       " 'E5F3xA_zkFc': 0.0866078884078884,\n",
       " '05JLyd58R-w': 0.0,\n",
       " '2fRQ8OsqOLs': 0.0919047619047619,\n",
       " 'E56W-5xVOss': 0.10351587301587302,\n",
       " 'c1oU8U05puY': 0.13055555555555556,\n",
       " 'SEHcakm-fAc': 0.06823292448292448,\n",
       " '1psSvU1km0I': 0.16116931216931216,\n",
       " 'PP3Yu-ro1tA': 0.12972727272727275,\n",
       " 'NQeI1CRCqeo': 0.020672348484848484,\n",
       " 'RhDHGgo4yZg': -0.04010416666666668,\n",
       " 'sdsz-t540WI': 0.08361678004535146,\n",
       " '7SKGXkZKjV8': -0.14477777777777776,\n",
       " 'oy0wHScCPds': -0.009515993265993247,\n",
       " 'o1kPskxFkQ8': 0.15447924540186445,\n",
       " 'aoNQUUQno00': 0.08114583333333332,\n",
       " 'liEUC1_l8e8': 0.13087987012987015,\n",
       " '-b0EuuMvvy8': 0.03419312169312169,\n",
       " 'MmyIvf7bEGc': 0.11958333333333335,\n",
       " 'Fd3HcncV6Zk': 0.1980952380952381,\n",
       " '-n9Ks3VTub4': 0.04938271604938271,\n",
       " 'LzymJ2xZhho': 0.07933942600609267,\n",
       " '-qFcO_onBdA': 0.028180803571428565,\n",
       " 'fp9uRsmTWqg': 0.0009259259259259381,\n",
       " '3ZXR2eARmuQ': 0.5315178571428572,\n",
       " '57wz3HuIVLA': 0.23699999999999996,\n",
       " 'lbK7UjoLr8o': 0.33333333333333337,\n",
       " 'xV1oR-RbOGU': 0.13866108171663727,\n",
       " 'kn6DKdInYXk': -0.14583333333333331,\n",
       " '2T3yZ6lNRDg': 0.1330625,\n",
       " 'HLYSlKY6Ww4': 0.28011188271604937,\n",
       " 'sH_YoV-NA6s': 0.3226953125,\n",
       " 'ZLT6L3PHz78': 0.0,\n",
       " 'lczwrm68u6I': 0.4138888888888889,\n",
       " 'zhBdbLj5y6A': -0.02916161616161616,\n",
       " 'ibWFsmcnefk': 0.22694816849816854,\n",
       " 'e0fN7HxkIUc': -0.06194047619047619,\n",
       " 'Ji47WRv2tQE': -0.016174242424242424,\n",
       " 'dj5ov38ihZI': 0.29276161193847655,\n",
       " 'j3E3NF9nk44': 0.22315909090909095,\n",
       " 'BomdsEJjb0E': 0.14701278659611994,\n",
       " 'T7c6GvrF82k': -0.20705555555555555,\n",
       " '6DBFwIlT4fg': 0.022234848484848496,\n",
       " '2FgFNBIJTIA': 0.14244047619047617,\n",
       " '254GdlKEz5I': 0.0,\n",
       " 'y4qaoHc2ezk': 0.276984126984127,\n",
       " '2VRGUm_wQ0w': 0.2549693772136954,\n",
       " 'HK5rfm4X2G0': -0.0375,\n",
       " '_DM5L8uu1Do': 0.061919191919191915,\n",
       " 'pK6y1h0YgSU': 0.27027011183261185,\n",
       " 'a3-AiHSyTIU': 0.1648983766233766,\n",
       " 'SLrKdYsNbSo': -0.04575887075887075,\n",
       " '8w61tigk0ag': -0.0013392857142857095,\n",
       " 'Mwpqgw9gMfo': 0.2375,\n",
       " 'FJEMcVK0MWI': 0.36442176870748305,\n",
       " 'gRKL_FUQUpY': 0.30357142857142855,\n",
       " 'LLFcBFAuauk': 0.10376602564102563,\n",
       " 'EsW0ye2wjUQ': 0.0,\n",
       " 'R0i7i80ToUM': 0.34358333333333335,\n",
       " '6zkba0hNiE8': 0.029166666666666664,\n",
       " 'T48EuGS36Zk': 0.18903559403559403,\n",
       " 'KzCjAetb3_I': 0.31357142857142856,\n",
       " 'N9OQbW0YOLU': 0.05421768707482994,\n",
       " 'I4WXmX_6Zds': 0.038000000000000006,\n",
       " 'WTD3l2xovQI': 0.3459848484848485,\n",
       " 'LtW0cTMWdbY': 0.20272727272727273,\n",
       " 'iVM-azf1Akk': -0.06458333333333333,\n",
       " 'xWV_GI9hq5U': 0.21869999999999998,\n",
       " '-LFGaCkPzzY': -0.19999999999999998,\n",
       " 'rFDK10oplxA': 0.10458754208754208,\n",
       " '6p_8T_xmnLQ': 0.11319642857142857,\n",
       " 'D9-CHldoZ74': 0.2138888888888889,\n",
       " 'xqz1KueuzAM': 0.06625,\n",
       " 'T2JkwAZ8KY8': 0.04006734006734005,\n",
       " 'TQ0QJ4Si7A4': 0.14166666666666666,\n",
       " '81Fj00CFmJM': 0.03666666666666665,\n",
       " 'C-iuGrZR2pQ': -0.01369318181818181,\n",
       " 'JT1R95tG9jg': 0.015624999999999993,\n",
       " 'O06AlL8nONo': 0.07473214285714286,\n",
       " 'HabzHfgdMNs': 0.215,\n",
       " 'o96VMbz4Zpk': -0.05,\n",
       " 'XylXJJp4HpE': 0.22633101851851853,\n",
       " 'ZaTPlJ8nd9Q': 0.2991784511784512,\n",
       " 'R3E3RlBEIl8': 0.20535714285714285,\n",
       " '5jCZ42fV6sw': 0.215625,\n",
       " 'tq7FyWSGaD4': 0.10674319727891156,\n",
       " 'jQusLZgOYac': 0.46296296296296297,\n",
       " 'iOnxb9jrY40': 0.025000000000000005,\n",
       " 'UWMmesK08TU': 0.22527777777777777,\n",
       " '4bub6WOlT-I': 0.1066547168109668,\n",
       " 'jIsXjk3TgkU': 0.10416666666666666,\n",
       " 'W8WAKyR5pGA': 0.0,\n",
       " 'ZBO3c3ko0eg': -0.024747474747474744,\n",
       " 'FIiz8hqXm24': 0.10555555555555556,\n",
       " 'I3mkImSqHA0': 0.045959595959595964,\n",
       " 'DTUckJz0RGo': 0.05185185185185185,\n",
       " 'JWA5mUrrr_A': -0.04791666666666666,\n",
       " 'XqzQanN4Xx8': 0.265,\n",
       " 'QjJwrWxwLJU': 0.10758928571428569,\n",
       " 'D7zMgv16cik': 0.16857142857142857,\n",
       " 'bJYGvO6V67A': 0.0,\n",
       " 'sJ0xpruFAwQ': 0.15030864197530863,\n",
       " 'ENk_QRA2XsY': 0.167020202020202,\n",
       " 'OB0qJwk5yA8': 0.058186958874458884,\n",
       " '29LXKUT0eMY': 0.010858585858585854,\n",
       " 'Bo24jIb7GA8': 0.050600248516915185,\n",
       " '19hkLN7KEqc': 0.002312008978675648,\n",
       " '_quGokF8G0o': 0.07071428571428572,\n",
       " 'M7qPgEDk2JY': 0.034393939393939386,\n",
       " '-PqXVcMtygc': 0.26666666666666666,\n",
       " 'GUVKWAEO_hY': 0.09912720959595958,\n",
       " '_S_9JRwFmcA': 0.875,\n",
       " 'LWIgEf_TMVU': 0.07415945165945168,\n",
       " 'aw59h2FNMIQ': 0.09791666666666668,\n",
       " 'lw0rcwYyiwE': 0.11293290043290043,\n",
       " 'sEjN7muHOLc': -0.006504329004329035,\n",
       " 'Y-xQtgvNuvA': 0.25647306397306396,\n",
       " 'W7n2FoRinVk': 0.1860739087301587,\n",
       " 'Wjj__vIdew0': 0.06395833333333334,\n",
       " '5DvMPgoKZmM': -0.0022853535353535414}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_vid_textblob_polarity(covid_filtered_out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VADER APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_vid_vader_polarity (df):\n",
    "    polarity_scores={}\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for video in df[\"video_id\"].unique():\n",
    "        sum_neg =0\n",
    "        sum_pos = 0\n",
    "        sum_neu =0\n",
    "        sum_compound= 0\n",
    "        scores={}\n",
    "        for sentence in df.loc[df[\"video_id\"]==video][\"comment\"]:\n",
    "\n",
    "            sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "            sum_neg += sentiment_dict['neg']\n",
    "            sum_pos += sentiment_dict['pos']\n",
    "            sum_neu += sentiment_dict['neu']\n",
    "            sum_compound += sentiment_dict['compound']\n",
    "            \n",
    "        scores[\"Neg\"] = sum_neg/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        scores[\"Pos\"] = sum_pos/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        scores[\"Neu\"] = sum_neu/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        scores[\"Overall\"] = sum_compound/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        \n",
    "        polarity_scores[video]=scores\n",
    "        '''# decide sentiment as positive, negative and neutral\n",
    "        if sentiment_dict['compound'] >= 0.05 :\n",
    "            print(\"Positive\")\n",
    " \n",
    "        elif sentiment_dict['compound'] <= - 0.05 :\n",
    "            print(\"Negative\")\n",
    " \n",
    "        else :\n",
    "            print(\"Neutral\")'''\n",
    "    return polarity_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aLZ85hb4wjE': {'Neg': 0.07980000000000001,\n",
       "  'Pos': 0.194,\n",
       "  'Neu': 0.7261,\n",
       "  'Overall': 0.17872000000000002},\n",
       " 'sYI97jv-pZg': {'Neg': 0.0, 'Pos': 0.056, 'Neu': 0.944, 'Overall': 0.11315},\n",
       " '3YFpjgIQqEo': {'Neg': 0.0635,\n",
       "  'Pos': 0.11320000000000001,\n",
       "  'Neu': 0.8231999999999999,\n",
       "  'Overall': 0.029220000000000003},\n",
       " 'dIsaz_XlmTw': {'Neg': 0.07455555555555556,\n",
       "  'Pos': 0.16166666666666668,\n",
       "  'Neu': 0.7638888888888888,\n",
       "  'Overall': 0.18183333333333332},\n",
       " 'DWxIvQlpJK8': {'Neg': 0.139625,\n",
       "  'Pos': 0.09925,\n",
       "  'Neu': 0.761125,\n",
       "  'Overall': -0.00888750000000002},\n",
       " 'pMUumjHY3tw': {'Neg': 0.0475,\n",
       "  'Pos': 0.034,\n",
       "  'Neu': 0.9185,\n",
       "  'Overall': -0.15775},\n",
       " 'nTUWK8vufOk': {'Neg': 0.08111111111111112,\n",
       "  'Pos': 0.18999999999999997,\n",
       "  'Neu': 0.729,\n",
       "  'Overall': 0.4215777777777778},\n",
       " 'cPVE7QGS7As': {'Neg': 0.0758888888888889,\n",
       "  'Pos': 0.262,\n",
       "  'Neu': 0.6621111111111111,\n",
       "  'Overall': 0.3731222222222222},\n",
       " 'CEIrzjA8euQ': {'Neg': 0.196, 'Pos': 0.0, 'Neu': 0.804, 'Overall': -0.296},\n",
       " 'lw16DeB6zns': {'Neg': 0.008428571428571428,\n",
       "  'Pos': 0.13799999999999998,\n",
       "  'Neu': 0.8535714285714285,\n",
       "  'Overall': 0.3301857142857143},\n",
       " '8dTelszbObM': {'Neg': 0.12455555555555556,\n",
       "  'Pos': 0.19866666666666666,\n",
       "  'Neu': 0.6766666666666667,\n",
       "  'Overall': 0.0400111111111111},\n",
       " 'Mxf8uGFcqSE': {'Neg': 0.049999999999999996,\n",
       "  'Pos': 0.14933333333333332,\n",
       "  'Neu': 0.8006666666666667,\n",
       "  'Overall': 0.23786666666666667},\n",
       " 'MQ5aYS4YFlQ': {'Neg': 0.10528571428571429,\n",
       "  'Pos': 0.13228571428571428,\n",
       "  'Neu': 0.7622857142857143,\n",
       "  'Overall': 0.18435714285714286},\n",
       " 'iOE6rAY8l-k': {'Neg': 0.028249999999999997,\n",
       "  'Pos': 0.16475,\n",
       "  'Neu': 0.8069999999999999,\n",
       "  'Overall': 0.196525},\n",
       " '_a-rQYfsCck': {'Neg': 0.064,\n",
       "  'Pos': 0.14344444444444443,\n",
       "  'Neu': 0.7925555555555556,\n",
       "  'Overall': 0.15585555555555555},\n",
       " 'jEINZXA_ujo': {'Neg': 0.05070000000000001,\n",
       "  'Pos': 0.3118,\n",
       "  'Neu': 0.6374000000000001,\n",
       "  'Overall': 0.43363000000000007},\n",
       " '587N9bJ5J5k': {'Neg': 0.04033333333333333,\n",
       "  'Pos': 0.3967777777777777,\n",
       "  'Neu': 0.5630000000000001,\n",
       "  'Overall': 0.43336666666666673},\n",
       " 'E5F3xA_zkFc': {'Neg': 0.12620000000000003,\n",
       "  'Pos': 0.1485,\n",
       "  'Neu': 0.7254,\n",
       "  'Overall': -0.03336000000000003},\n",
       " '05JLyd58R-w': {'Neg': 0.0, 'Pos': 0.0, 'Neu': 1.0, 'Overall': 0.0},\n",
       " '2fRQ8OsqOLs': {'Neg': 0.05700000000000001,\n",
       "  'Pos': 0.11209999999999998,\n",
       "  'Neu': 0.8309000000000001,\n",
       "  'Overall': 0.12241000000000002},\n",
       " 'E56W-5xVOss': {'Neg': 0.044700000000000004,\n",
       "  'Pos': 0.3266,\n",
       "  'Neu': 0.6288,\n",
       "  'Overall': 0.5922000000000001},\n",
       " 'c1oU8U05puY': {'Neg': 0.20299999999999999,\n",
       "  'Pos': 0.028777777777777777,\n",
       "  'Neu': 0.7682222222222221,\n",
       "  'Overall': -0.2014888888888889},\n",
       " 'SEHcakm-fAc': {'Neg': 0.033,\n",
       "  'Pos': 0.19622222222222221,\n",
       "  'Neu': 0.7705555555555555,\n",
       "  'Overall': 0.3718},\n",
       " '1psSvU1km0I': {'Neg': 0.16419999999999996,\n",
       "  'Pos': 0.08979999999999999,\n",
       "  'Neu': 0.7461,\n",
       "  'Overall': -0.23913},\n",
       " 'PP3Yu-ro1tA': {'Neg': 0.1284,\n",
       "  'Pos': 0.11000000000000001,\n",
       "  'Neu': 0.7616,\n",
       "  'Overall': -0.038069999999999986},\n",
       " 'NQeI1CRCqeo': {'Neg': 0.1836,\n",
       "  'Pos': 0.1698,\n",
       "  'Neu': 0.6467,\n",
       "  'Overall': 0.12021000000000001},\n",
       " 'RhDHGgo4yZg': {'Neg': 0.13130000000000003,\n",
       "  'Pos': 0.221,\n",
       "  'Neu': 0.6476999999999999,\n",
       "  'Overall': 0.13882999999999998},\n",
       " 'sdsz-t540WI': {'Neg': 0.033999999999999996,\n",
       "  'Pos': 0.16285714285714287,\n",
       "  'Neu': 0.8032857142857143,\n",
       "  'Overall': 0.4286571428571429},\n",
       " '7SKGXkZKjV8': {'Neg': 0.24240000000000003,\n",
       "  'Pos': 0.20220000000000002,\n",
       "  'Neu': 0.5554,\n",
       "  'Overall': 0.10447999999999999},\n",
       " 'oy0wHScCPds': {'Neg': 0.03833333333333334,\n",
       "  'Pos': 0.1101111111111111,\n",
       "  'Neu': 0.8515555555555555,\n",
       "  'Overall': 0.21537777777777778},\n",
       " 'o1kPskxFkQ8': {'Neg': 0.06477777777777777,\n",
       "  'Pos': 0.18455555555555556,\n",
       "  'Neu': 0.7507777777777779,\n",
       "  'Overall': -0.009800000000000007},\n",
       " 'aoNQUUQno00': {'Neg': 0.05644444444444444,\n",
       "  'Pos': 0.18588888888888888,\n",
       "  'Neu': 0.757888888888889,\n",
       "  'Overall': 0.3900555555555556},\n",
       " 'liEUC1_l8e8': {'Neg': 0.1125,\n",
       "  'Pos': 0.1014,\n",
       "  'Neu': 0.7862,\n",
       "  'Overall': -0.037189999999999994},\n",
       " '-b0EuuMvvy8': {'Neg': 0.07577777777777778,\n",
       "  'Pos': 0.16977777777777778,\n",
       "  'Neu': 0.7545555555555556,\n",
       "  'Overall': 0.1167},\n",
       " 'MmyIvf7bEGc': {'Neg': 0.05569999999999999,\n",
       "  'Pos': 0.1724,\n",
       "  'Neu': 0.7719,\n",
       "  'Overall': 0.11624000000000004},\n",
       " 'Fd3HcncV6Zk': {'Neg': 0.0945,\n",
       "  'Pos': 0.1855,\n",
       "  'Neu': 0.7199,\n",
       "  'Overall': 0.060639999999999986},\n",
       " '-n9Ks3VTub4': {'Neg': 0.052,\n",
       "  'Pos': 0.08633333333333333,\n",
       "  'Neu': 0.862,\n",
       "  'Overall': 0.33569999999999994},\n",
       " 'LzymJ2xZhho': {'Neg': 0.050888888888888886,\n",
       "  'Pos': 0.10133333333333333,\n",
       "  'Neu': 0.8476666666666666,\n",
       "  'Overall': 0.22284444444444448},\n",
       " '-qFcO_onBdA': {'Neg': 0.1711,\n",
       "  'Pos': 0.0771,\n",
       "  'Neu': 0.7518999999999999,\n",
       "  'Overall': 0.014460000000000006},\n",
       " 'fp9uRsmTWqg': {'Neg': 0.1521111111111111,\n",
       "  'Pos': 0.07911111111111112,\n",
       "  'Neu': 0.7687777777777778,\n",
       "  'Overall': -0.08923333333333333},\n",
       " '3ZXR2eARmuQ': {'Neg': 0.0504,\n",
       "  'Pos': 0.23729999999999998,\n",
       "  'Neu': 0.7123,\n",
       "  'Overall': 0.49859},\n",
       " '57wz3HuIVLA': {'Neg': 0.0268,\n",
       "  'Pos': 0.2791,\n",
       "  'Neu': 0.6940999999999999,\n",
       "  'Overall': 0.6058800000000001},\n",
       " 'lbK7UjoLr8o': {'Neg': 0.0,\n",
       "  'Pos': 0.26849999999999996,\n",
       "  'Neu': 0.7315,\n",
       "  'Overall': 0.29390000000000005},\n",
       " 'xV1oR-RbOGU': {'Neg': 0.03311111111111111,\n",
       "  'Pos': 0.20211111111111113,\n",
       "  'Neu': 0.7646666666666666,\n",
       "  'Overall': 0.5251222222222222},\n",
       " 'kn6DKdInYXk': {'Neg': 0.11987499999999998,\n",
       "  'Pos': 0.20687499999999998,\n",
       "  'Neu': 0.67325,\n",
       "  'Overall': -0.04357499999999999},\n",
       " '2T3yZ6lNRDg': {'Neg': 0.0188,\n",
       "  'Pos': 0.19290000000000002,\n",
       "  'Neu': 0.7884,\n",
       "  'Overall': 0.20521000000000003},\n",
       " 'HLYSlKY6Ww4': {'Neg': 0.09022222222222222,\n",
       "  'Pos': 0.3501111111111111,\n",
       "  'Neu': 0.5595555555555554,\n",
       "  'Overall': 0.6197000000000001},\n",
       " 'sH_YoV-NA6s': {'Neg': 0.0,\n",
       "  'Pos': 0.25712500000000005,\n",
       "  'Neu': 0.742875,\n",
       "  'Overall': 0.5731625},\n",
       " 'ZLT6L3PHz78': {'Neg': 0.11699999999999999,\n",
       "  'Pos': 0.2714,\n",
       "  'Neu': 0.6116,\n",
       "  'Overall': 0.053079999999999995},\n",
       " 'lczwrm68u6I': {'Neg': 0.023600000000000003,\n",
       "  'Pos': 0.3898,\n",
       "  'Neu': 0.5865,\n",
       "  'Overall': 0.6887199999999999},\n",
       " 'zhBdbLj5y6A': {'Neg': 0.1592,\n",
       "  'Pos': 0.14909999999999998,\n",
       "  'Neu': 0.6917,\n",
       "  'Overall': 0.06791},\n",
       " 'ibWFsmcnefk': {'Neg': 0.0392,\n",
       "  'Pos': 0.2173,\n",
       "  'Neu': 0.7434000000000001,\n",
       "  'Overall': 0.31825000000000003},\n",
       " 'e0fN7HxkIUc': {'Neg': 0.131,\n",
       "  'Pos': 0.21750000000000003,\n",
       "  'Neu': 0.6515,\n",
       "  'Overall': 0.07122999999999999},\n",
       " 'Ji47WRv2tQE': {'Neg': 0.1625,\n",
       "  'Pos': 0.146,\n",
       "  'Neu': 0.6915,\n",
       "  'Overall': -0.16921},\n",
       " 'dj5ov38ihZI': {'Neg': 0.3215,\n",
       "  'Pos': 0.2365,\n",
       "  'Neu': 0.44200000000000006,\n",
       "  'Overall': 0.22475},\n",
       " 'j3E3NF9nk44': {'Neg': 0.027600000000000003,\n",
       "  'Pos': 0.19849999999999998,\n",
       "  'Neu': 0.7739,\n",
       "  'Overall': 0.25595},\n",
       " 'BomdsEJjb0E': {'Neg': 0.13622222222222222,\n",
       "  'Pos': 0.119,\n",
       "  'Neu': 0.7447777777777778,\n",
       "  'Overall': -0.1807777777777778},\n",
       " 'T7c6GvrF82k': {'Neg': 0.27020000000000005,\n",
       "  'Pos': 0.1839,\n",
       "  'Neu': 0.5458999999999999,\n",
       "  'Overall': -0.06135},\n",
       " '6DBFwIlT4fg': {'Neg': 0.0638,\n",
       "  'Pos': 0.0927,\n",
       "  'Neu': 0.8435,\n",
       "  'Overall': 0.05889000000000001},\n",
       " '2FgFNBIJTIA': {'Neg': 0.12837500000000002,\n",
       "  'Pos': 0.0325,\n",
       "  'Neu': 0.8391249999999999,\n",
       "  'Overall': -0.2631375},\n",
       " '254GdlKEz5I': {'Neg': 0.0,\n",
       "  'Pos': 0.08233333333333333,\n",
       "  'Neu': 0.9176666666666667,\n",
       "  'Overall': 0.10606666666666666},\n",
       " 'y4qaoHc2ezk': {'Neg': 0.0921111111111111,\n",
       "  'Pos': 0.211,\n",
       "  'Neu': 0.6966666666666667,\n",
       "  'Overall': 0.13024444444444444},\n",
       " '2VRGUm_wQ0w': {'Neg': 0.09269999999999999,\n",
       "  'Pos': 0.24710000000000004,\n",
       "  'Neu': 0.6601999999999999,\n",
       "  'Overall': 0.18145000000000003},\n",
       " 'HK5rfm4X2G0': {'Neg': 0.0691,\n",
       "  'Pos': 0.1046,\n",
       "  'Neu': 0.8261,\n",
       "  'Overall': 0.06345},\n",
       " '_DM5L8uu1Do': {'Neg': 0.1355,\n",
       "  'Pos': 0.19829999999999998,\n",
       "  'Neu': 0.6662,\n",
       "  'Overall': 0.20348000000000002},\n",
       " 'pK6y1h0YgSU': {'Neg': 0.042124999999999996,\n",
       "  'Pos': 0.26887500000000003,\n",
       "  'Neu': 0.6889999999999998,\n",
       "  'Overall': 0.47506250000000005},\n",
       " 'a3-AiHSyTIU': {'Neg': 0.10290000000000002,\n",
       "  'Pos': 0.18439999999999998,\n",
       "  'Neu': 0.7127999999999999,\n",
       "  'Overall': 0.35263999999999995},\n",
       " 'SLrKdYsNbSo': {'Neg': 0.12833333333333333,\n",
       "  'Pos': 0.10983333333333332,\n",
       "  'Neu': 0.7619999999999999,\n",
       "  'Overall': 0.1722},\n",
       " '8w61tigk0ag': {'Neg': 0.1733,\n",
       "  'Pos': 0.0759,\n",
       "  'Neu': 0.7508999999999999,\n",
       "  'Overall': -0.22881999999999988},\n",
       " 'Mwpqgw9gMfo': {'Neg': 0.1465,\n",
       "  'Pos': 0.6910000000000001,\n",
       "  'Neu': 0.1625,\n",
       "  'Overall': 0.22995},\n",
       " 'FJEMcVK0MWI': {'Neg': 0.020428571428571428,\n",
       "  'Pos': 0.3085714285714286,\n",
       "  'Neu': 0.671,\n",
       "  'Overall': 0.5174428571428571},\n",
       " 'gRKL_FUQUpY': {'Neg': 0.06739999999999999,\n",
       "  'Pos': 0.1666,\n",
       "  'Neu': 0.766,\n",
       "  'Overall': 0.15442},\n",
       " 'LLFcBFAuauk': {'Neg': 0.11037499999999999,\n",
       "  'Pos': 0.20949999999999996,\n",
       "  'Neu': 0.68,\n",
       "  'Overall': 0.24870000000000003},\n",
       " 'EsW0ye2wjUQ': {'Neg': 0.0, 'Pos': 0.75, 'Neu': 0.25, 'Overall': 0.4588},\n",
       " 'R0i7i80ToUM': {'Neg': 0.02725,\n",
       "  'Pos': 0.31275,\n",
       "  'Neu': 0.66,\n",
       "  'Overall': 0.4477375},\n",
       " '6zkba0hNiE8': {'Neg': 0.016125,\n",
       "  'Pos': 0.04125,\n",
       "  'Neu': 0.942625,\n",
       "  'Overall': 0.0692875},\n",
       " 'T48EuGS36Zk': {'Neg': 0.04044444444444444,\n",
       "  'Pos': 0.35133333333333333,\n",
       "  'Neu': 0.6082222222222222,\n",
       "  'Overall': 0.6077666666666667},\n",
       " 'KzCjAetb3_I': {'Neg': 0.0813,\n",
       "  'Pos': 0.2623,\n",
       "  'Neu': 0.6564,\n",
       "  'Overall': 0.22349999999999998},\n",
       " 'N9OQbW0YOLU': {'Neg': 0.07628571428571429,\n",
       "  'Pos': 0.17471428571428574,\n",
       "  'Neu': 0.749,\n",
       "  'Overall': 0.1461285714285714},\n",
       " 'I4WXmX_6Zds': {'Neg': 0.06509999999999999,\n",
       "  'Pos': 0.0955,\n",
       "  'Neu': 0.8394,\n",
       "  'Overall': 0.15177999999999997},\n",
       " 'WTD3l2xovQI': {'Neg': 0.025625000000000002,\n",
       "  'Pos': 0.24774999999999997,\n",
       "  'Neu': 0.726875,\n",
       "  'Overall': 0.5155875000000001},\n",
       " 'LtW0cTMWdbY': {'Neg': 0.0455,\n",
       "  'Pos': 0.0607,\n",
       "  'Neu': 0.8936999999999999,\n",
       "  'Overall': 0.009170000000000001},\n",
       " 'iVM-azf1Akk': {'Neg': 0.15111111111111108,\n",
       "  'Pos': 0.02222222222222222,\n",
       "  'Neu': 0.8266666666666667,\n",
       "  'Overall': -0.2001222222222222},\n",
       " 'xWV_GI9hq5U': {'Neg': 0.1142,\n",
       "  'Pos': 0.2499,\n",
       "  'Neu': 0.6359,\n",
       "  'Overall': 0.18432000000000004},\n",
       " '-LFGaCkPzzY': {'Neg': 0.06799999999999999,\n",
       "  'Pos': 0.19833333333333333,\n",
       "  'Neu': 0.7336666666666667,\n",
       "  'Overall': 0.16363333333333335},\n",
       " 'rFDK10oplxA': {'Neg': 0.02688888888888889,\n",
       "  'Pos': 0.19677777777777777,\n",
       "  'Neu': 0.7762222222222221,\n",
       "  'Overall': 0.2789},\n",
       " '6p_8T_xmnLQ': {'Neg': 0.11040000000000001,\n",
       "  'Pos': 0.17470000000000002,\n",
       "  'Neu': 0.7150000000000001,\n",
       "  'Overall': 0.14632},\n",
       " 'D9-CHldoZ74': {'Neg': 0.13533333333333333,\n",
       "  'Pos': 0.2448888888888889,\n",
       "  'Neu': 0.6197777777777778,\n",
       "  'Overall': 0.029266666666666663},\n",
       " 'xqz1KueuzAM': {'Neg': 0.2451,\n",
       "  'Pos': 0.10705,\n",
       "  'Neu': 0.64785,\n",
       "  'Overall': -0.25944999999999996},\n",
       " 'T2JkwAZ8KY8': {'Neg': 0.24066666666666667,\n",
       "  'Pos': 0.11299999999999999,\n",
       "  'Neu': 0.6462222222222223,\n",
       "  'Overall': -0.24464444444444444},\n",
       " 'TQ0QJ4Si7A4': {'Neg': 0.07875,\n",
       "  'Pos': 0.1325,\n",
       "  'Neu': 0.7887500000000001,\n",
       "  'Overall': 0.19025},\n",
       " '81Fj00CFmJM': {'Neg': 0.02211111111111111,\n",
       "  'Pos': 0.021777777777777778,\n",
       "  'Neu': 0.9561111111111111,\n",
       "  'Overall': 0.10965555555555555},\n",
       " 'C-iuGrZR2pQ': {'Neg': 0.0805,\n",
       "  'Pos': 0.1266,\n",
       "  'Neu': 0.7928000000000001,\n",
       "  'Overall': 0.01286},\n",
       " 'JT1R95tG9jg': {'Neg': 0.12525,\n",
       "  'Pos': 0.132,\n",
       "  'Neu': 0.7427500000000001,\n",
       "  'Overall': -0.0342875},\n",
       " 'O06AlL8nONo': {'Neg': 0.084625,\n",
       "  'Pos': 0.035250000000000004,\n",
       "  'Neu': 0.8802500000000001,\n",
       "  'Overall': -0.16674999999999998},\n",
       " 'HabzHfgdMNs': {'Neg': 0.023799999999999998,\n",
       "  'Pos': 0.30979999999999996,\n",
       "  'Neu': 0.6664,\n",
       "  'Overall': 0.40113000000000004},\n",
       " 'o96VMbz4Zpk': {'Neg': 0.1665, 'Pos': 0.0, 'Neu': 0.8335, 'Overall': -0.125},\n",
       " 'XylXJJp4HpE': {'Neg': 0.03166666666666666,\n",
       "  'Pos': 0.22966666666666663,\n",
       "  'Neu': 0.7384444444444445,\n",
       "  'Overall': 0.4071777777777778},\n",
       " 'ZaTPlJ8nd9Q': {'Neg': 0.04544444444444444,\n",
       "  'Pos': 0.2541111111111111,\n",
       "  'Neu': 0.7004444444444444,\n",
       "  'Overall': 0.27423333333333333},\n",
       " 'R3E3RlBEIl8': {'Neg': 0.0, 'Pos': 0.4085, 'Neu': 0.5915, 'Overall': 0.61815},\n",
       " '5jCZ42fV6sw': {'Neg': 0.20099999999999998,\n",
       "  'Pos': 0.12975,\n",
       "  'Neu': 0.6689999999999999,\n",
       "  'Overall': -0.06670000000000004},\n",
       " 'tq7FyWSGaD4': {'Neg': 0.05442857142857143,\n",
       "  'Pos': 0.14242857142857143,\n",
       "  'Neu': 0.8032857142857143,\n",
       "  'Overall': 0.14994285714285716},\n",
       " 'jQusLZgOYac': {'Neg': 0.015,\n",
       "  'Pos': 0.306,\n",
       "  'Neu': 0.6789999999999999,\n",
       "  'Overall': 0.6242166666666666},\n",
       " 'iOnxb9jrY40': {'Neg': 0.0841,\n",
       "  'Pos': 0.1149,\n",
       "  'Neu': 0.8009999999999999,\n",
       "  'Overall': 0.11026999999999998},\n",
       " 'UWMmesK08TU': {'Neg': 0.0915,\n",
       "  'Pos': 0.14450000000000002,\n",
       "  'Neu': 0.764,\n",
       "  'Overall': 0.17307},\n",
       " '4bub6WOlT-I': {'Neg': 0.072375,\n",
       "  'Pos': 0.20350000000000001,\n",
       "  'Neu': 0.724125,\n",
       "  'Overall': 0.22838749999999997},\n",
       " 'jIsXjk3TgkU': {'Neg': 0.054200000000000005,\n",
       "  'Pos': 0.1776,\n",
       "  'Neu': 0.7682,\n",
       "  'Overall': 0.31197},\n",
       " 'W8WAKyR5pGA': {'Neg': 0.0, 'Pos': 0.315, 'Neu': 0.685, 'Overall': 0.3182},\n",
       " 'ZBO3c3ko0eg': {'Neg': 0.23511111111111113,\n",
       "  'Pos': 0.14788888888888888,\n",
       "  'Neu': 0.6172222222222222,\n",
       "  'Overall': -0.20312222222222223},\n",
       " 'FIiz8hqXm24': {'Neg': 0.0,\n",
       "  'Pos': 0.07522222222222223,\n",
       "  'Neu': 0.9247777777777778,\n",
       "  'Overall': 0.14596666666666666},\n",
       " 'I3mkImSqHA0': {'Neg': 0.12733333333333333,\n",
       "  'Pos': 0.09433333333333332,\n",
       "  'Neu': 0.7782222222222224,\n",
       "  'Overall': -0.1276},\n",
       " 'DTUckJz0RGo': {'Neg': 0.17722222222222225,\n",
       "  'Pos': 0.03966666666666666,\n",
       "  'Neu': 0.7831111111111111,\n",
       "  'Overall': -0.1674888888888889},\n",
       " 'JWA5mUrrr_A': {'Neg': 0.20090000000000002,\n",
       "  'Pos': 0.0772,\n",
       "  'Neu': 0.7218,\n",
       "  'Overall': -0.03163999999999999},\n",
       " 'XqzQanN4Xx8': {'Neg': 0.0114,\n",
       "  'Pos': 0.5027,\n",
       "  'Neu': 0.4859,\n",
       "  'Overall': 0.37498},\n",
       " 'QjJwrWxwLJU': {'Neg': 0.028375,\n",
       "  'Pos': 0.11462499999999999,\n",
       "  'Neu': 0.856875,\n",
       "  'Overall': 0.1935375},\n",
       " 'D7zMgv16cik': {'Neg': 0.05442857142857143,\n",
       "  'Pos': 0.20542857142857143,\n",
       "  'Neu': 0.7401428571428571,\n",
       "  'Overall': 0.12715714285714289},\n",
       " 'bJYGvO6V67A': {'Neg': 0.0, 'Pos': 0.659, 'Neu': 0.341, 'Overall': 0.7003},\n",
       " 'sJ0xpruFAwQ': {'Neg': 0.046,\n",
       "  'Pos': 0.2241111111111111,\n",
       "  'Neu': 0.73,\n",
       "  'Overall': 0.37444444444444447},\n",
       " 'ENk_QRA2XsY': {'Neg': 0.0228,\n",
       "  'Pos': 0.1139,\n",
       "  'Neu': 0.8633,\n",
       "  'Overall': 0.21849000000000002},\n",
       " 'OB0qJwk5yA8': {'Neg': 0.056100000000000004,\n",
       "  'Pos': 0.06860000000000001,\n",
       "  'Neu': 0.8754,\n",
       "  'Overall': -0.056600000000000004},\n",
       " '29LXKUT0eMY': {'Neg': 0.06833333333333333,\n",
       "  'Pos': 0.06933333333333333,\n",
       "  'Neu': 0.8623333333333333,\n",
       "  'Overall': -0.01906666666666666},\n",
       " 'Bo24jIb7GA8': {'Neg': 0.054,\n",
       "  'Pos': 0.09355555555555556,\n",
       "  'Neu': 0.8523333333333334,\n",
       "  'Overall': 0.22667777777777776},\n",
       " '19hkLN7KEqc': {'Neg': 0.1376666666666667,\n",
       "  'Pos': 0.15344444444444444,\n",
       "  'Neu': 0.7088888888888889,\n",
       "  'Overall': -0.06033333333333335},\n",
       " '_quGokF8G0o': {'Neg': 0.10099999999999999,\n",
       "  'Pos': 0.15114285714285716,\n",
       "  'Neu': 0.7477142857142856,\n",
       "  'Overall': 0.2424},\n",
       " 'M7qPgEDk2JY': {'Neg': 0.091,\n",
       "  'Pos': 0.22999999999999998,\n",
       "  'Neu': 0.679,\n",
       "  'Overall': 0.11255},\n",
       " '-PqXVcMtygc': {'Neg': 0.222,\n",
       "  'Pos': 0.17433333333333334,\n",
       "  'Neu': 0.6036666666666667,\n",
       "  'Overall': -0.14193333333333333},\n",
       " 'GUVKWAEO_hY': {'Neg': 0.032,\n",
       "  'Pos': 0.094875,\n",
       "  'Neu': 0.873,\n",
       "  'Overall': 0.13621250000000001},\n",
       " '_S_9JRwFmcA': {'Neg': 0.0, 'Pos': 0.761, 'Neu': 0.239, 'Overall': 0.4926},\n",
       " 'LWIgEf_TMVU': {'Neg': 0.0727,\n",
       "  'Pos': 0.23259999999999997,\n",
       "  'Neu': 0.6947,\n",
       "  'Overall': 0.12046000000000001},\n",
       " 'aw59h2FNMIQ': {'Neg': 0.06179999999999999,\n",
       "  'Pos': 0.19890000000000002,\n",
       "  'Neu': 0.7392,\n",
       "  'Overall': 0.05933999999999999},\n",
       " 'lw0rcwYyiwE': {'Neg': 0.14585714285714285,\n",
       "  'Pos': 0.08642857142857142,\n",
       "  'Neu': 0.7675714285714285,\n",
       "  'Overall': -0.05255714285714286},\n",
       " 'sEjN7muHOLc': {'Neg': 0.1343,\n",
       "  'Pos': 0.16570000000000001,\n",
       "  'Neu': 0.6999,\n",
       "  'Overall': -0.0253},\n",
       " 'Y-xQtgvNuvA': {'Neg': 0.10144444444444445,\n",
       "  'Pos': 0.17622222222222222,\n",
       "  'Neu': 0.7225555555555556,\n",
       "  'Overall': 0.1534333333333334},\n",
       " 'W7n2FoRinVk': {'Neg': 0.042,\n",
       "  'Pos': 0.07725,\n",
       "  'Neu': 0.8807499999999999,\n",
       "  'Overall': 0.0599625},\n",
       " 'Wjj__vIdew0': {'Neg': 0.03825,\n",
       "  'Pos': 0.09237500000000001,\n",
       "  'Neu': 0.869375,\n",
       "  'Overall': -0.014812500000000004},\n",
       " '5DvMPgoKZmM': {'Neg': 0.03833333333333333,\n",
       "  'Pos': 0.1,\n",
       "  'Neu': 0.8616666666666667,\n",
       "  'Overall': 0.16822222222222222}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_vid_vader_polarity(covid_filtered_out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "#import re\n",
    "#from scipy.special import softmax\n",
    "\n",
    "def roberta_per_vid_scores(df):\n",
    "    polarity_scores={}\n",
    "\n",
    "    roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "    labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "    for video in df[\"video_id\"].unique():\n",
    "        sum_neg =0\n",
    "        sum_pos = 0\n",
    "        sum_neu =0 \n",
    "        scores={}\n",
    "        for comments in df.loc[df[\"video_id\"]==video][\"comment\"]:\n",
    "            comment_words = []\n",
    "            comments = comments.replace(\"\\n\", \" \")\n",
    "            comments = comments.replace(\"\\xa0\", \" \")\n",
    "            comments = comments.replace(\"?\", \" \")\n",
    "            comments = comments.replace(\":\", \" \")\n",
    "            comments = comments.replace(\";\", \" \")\n",
    "            comments = comments.replace(\";\", \" \")\n",
    "            comments = re.sub(r\"\\s+\", ' ', comments) \n",
    "     #   print(comments)\n",
    "            for word in comments.split(' '):\n",
    "                if word.startswith('@') and len(word) > 1:\n",
    "                    word = '@user'\n",
    "        \n",
    "                elif word.startswith('http'):\n",
    "                    word = \"http\"\n",
    "                comment_words.append(word)\n",
    "\n",
    "            comment_procs = \" \".join(comment_words)\n",
    "\n",
    "            encoded = tokenizer(comment_procs, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "           # print(encoded)\n",
    "            output = model(**encoded)\n",
    "\n",
    "            scores = output[0][0].detach().numpy()\n",
    "\n",
    "            scores = softmax(scores)\n",
    "\n",
    "            for i in range(len(scores)):\n",
    "\n",
    "                l = labels[i]\n",
    "                s = scores[i]\n",
    "                #    labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "                if l==\"Negative\":\n",
    "                    sum_neg+= s\n",
    "                elif l == \"Neutral\":\n",
    "                    sum_neu+=s\n",
    "                else : \n",
    "                    sum_pos+=s\n",
    "       # scores[\"Neg\"] = sum_neg/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        scores =dict([(\"Neg\", sum_neg/df.loc[df[\"video_id\"]==video][\"comment\"].count()),(\"Pos\",sum_pos/df.loc[df[\"video_id\"]==video][\"comment\"].count()),(\"Neu\",sum_neu/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    ")])\n",
    "        #scores[\"Pos\"] = sum_pos/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        #scores[\"Neu\"] = sum_neu/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "\n",
    "        polarity_scores[video] = scores\n",
    "    return polarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aLZ85hb4wjE': {'Neg': 0.24424575177254154,\n",
       "  'Pos': 0.4741820393828675,\n",
       "  'Neu': 0.28157221488654616},\n",
       " 'sYI97jv-pZg': {'Neg': 0.3894941806793213,\n",
       "  'Pos': 0.0859330091625452,\n",
       "  'Neu': 0.5245728343725204},\n",
       " '3YFpjgIQqEo': {'Neg': 0.4642800234258175,\n",
       "  'Pos': 0.23067305744625627,\n",
       "  'Neu': 0.30504688881337644},\n",
       " 'dIsaz_XlmTw': {'Neg': 0.36858308074685436,\n",
       "  'Pos': 0.27306528648154604,\n",
       "  'Neu': 0.3583516404032707},\n",
       " 'DWxIvQlpJK8': {'Neg': 0.289873747547972,\n",
       "  'Pos': 0.29180154629284516,\n",
       "  'Neu': 0.41832468984648585},\n",
       " 'pMUumjHY3tw': {'Neg': 0.28391369991004467,\n",
       "  'Pos': 0.05910225957632065,\n",
       "  'Neu': 0.6569840013980865},\n",
       " 'nTUWK8vufOk': {'Neg': 0.446053135364006,\n",
       "  'Pos': 0.32104381538617116,\n",
       "  'Neu': 0.2329030301835802},\n",
       " 'cPVE7QGS7As': {'Neg': 0.16431427941036722,\n",
       "  'Pos': 0.5078818136826158,\n",
       "  'Neu': 0.32780391226212185},\n",
       " 'CEIrzjA8euQ': {'Neg': 0.15780450403690338,\n",
       "  'Pos': 0.1664552390575409,\n",
       "  'Neu': 0.6757402420043945},\n",
       " 'lw16DeB6zns': {'Neg': 0.20506471338947968,\n",
       "  'Pos': 0.27181072533130646,\n",
       "  'Neu': 0.5231245553919247},\n",
       " '8dTelszbObM': {'Neg': 0.3829619338115056,\n",
       "  'Pos': 0.23020292735762066,\n",
       "  'Neu': 0.38683512227402794},\n",
       " 'Mxf8uGFcqSE': {'Neg': 0.3286059144884348,\n",
       "  'Pos': 0.23150264006108046,\n",
       "  'Neu': 0.43989147742589313},\n",
       " 'MQ5aYS4YFlQ': {'Neg': 0.3885195241974933,\n",
       "  'Pos': 0.3550896951928735,\n",
       "  'Neu': 0.25639078127486364},\n",
       " 'iOE6rAY8l-k': {'Neg': 0.2396912667172728,\n",
       "  'Pos': 0.42479335458483547,\n",
       "  'Neu': 0.33551538176834583},\n",
       " '_a-rQYfsCck': {'Neg': 0.2134859820879582,\n",
       "  'Pos': 0.32815349960906637,\n",
       "  'Neu': 0.458360498978032},\n",
       " 'jEINZXA_ujo': {'Neg': 0.13006612944882362,\n",
       "  'Pos': 0.5712564446032047,\n",
       "  'Neu': 0.29867742620408533},\n",
       " '587N9bJ5J5k': {'Neg': 0.17312934953305456,\n",
       "  'Pos': 0.5903791793518596,\n",
       "  'Neu': 0.23649148808585274},\n",
       " 'E5F3xA_zkFc': {'Neg': 0.5447165288962423,\n",
       "  'Pos': 0.20625192711595447,\n",
       "  'Neu': 0.2490315232425928},\n",
       " '05JLyd58R-w': {'Neg': 0.4840949047356844,\n",
       "  'Pos': 0.06720608472824097,\n",
       "  'Neu': 0.4486990049481392},\n",
       " '2fRQ8OsqOLs': {'Neg': 0.21918998224427924,\n",
       "  'Pos': 0.2967803567647934,\n",
       "  'Neu': 0.484029658511281},\n",
       " 'E56W-5xVOss': {'Neg': 0.06499409828102216,\n",
       "  'Pos': 0.6393684446811676,\n",
       "  'Neu': 0.29563745576888323},\n",
       " 'c1oU8U05puY': {'Neg': 0.29776944364938474,\n",
       "  'Pos': 0.11613088954860966,\n",
       "  'Neu': 0.5860996453298463},\n",
       " 'SEHcakm-fAc': {'Neg': 0.19373247793151271,\n",
       "  'Pos': 0.4848881298676133,\n",
       "  'Neu': 0.32137942645284867},\n",
       " '1psSvU1km0I': {'Neg': 0.5697165600489825,\n",
       "  'Pos': 0.24753818698227406,\n",
       "  'Neu': 0.18274526074528694},\n",
       " 'PP3Yu-ro1tA': {'Neg': 0.43407171128783373,\n",
       "  'Pos': 0.19316874239593745,\n",
       "  'Neu': 0.37275953553617003},\n",
       " 'NQeI1CRCqeo': {'Neg': 0.26817576005123556,\n",
       "  'Pos': 0.3413007685914636,\n",
       "  'Neu': 0.3905234567821026},\n",
       " 'RhDHGgo4yZg': {'Neg': 0.3205419564503245,\n",
       "  'Pos': 0.4272730555385351,\n",
       "  'Neu': 0.2521850075572729},\n",
       " 'sdsz-t540WI': {'Neg': 0.11056576695825372,\n",
       "  'Pos': 0.5061521354530539,\n",
       "  'Neu': 0.3832820802927017},\n",
       " '7SKGXkZKjV8': {'Neg': 0.4182384212152101,\n",
       "  'Pos': 0.27301260456442833,\n",
       "  'Neu': 0.30874898955225943},\n",
       " 'oy0wHScCPds': {'Neg': 0.18616034168129167,\n",
       "  'Pos': 0.32002748052279156,\n",
       "  'Neu': 0.4938121711214383},\n",
       " 'o1kPskxFkQ8': {'Neg': 0.418451406656661,\n",
       "  'Pos': 0.32145232272644836,\n",
       "  'Neu': 0.26009630577431786},\n",
       " 'aoNQUUQno00': {'Neg': 0.36504708473674125,\n",
       "  'Pos': 0.2571868115208215,\n",
       "  'Neu': 0.3777661220067077},\n",
       " 'liEUC1_l8e8': {'Neg': 0.6834809392690658,\n",
       "  'Pos': 0.05279332213103771,\n",
       "  'Neu': 0.2637257404625416},\n",
       " '-b0EuuMvvy8': {'Neg': 0.24769592212720049,\n",
       "  'Pos': 0.10662825840214889,\n",
       "  'Neu': 0.6456758379936218},\n",
       " 'MmyIvf7bEGc': {'Neg': 0.08810573244700208,\n",
       "  'Pos': 0.3842112744227052,\n",
       "  'Neu': 0.52768300101161},\n",
       " 'Fd3HcncV6Zk': {'Neg': 0.28265681746415794,\n",
       "  'Pos': 0.3828651793766767,\n",
       "  'Neu': 0.3344780135899782},\n",
       " '-n9Ks3VTub4': {'Neg': 0.0663933443526427,\n",
       "  'Pos': 0.16013591488202414,\n",
       "  'Neu': 0.7734707196553549},\n",
       " 'LzymJ2xZhho': {'Neg': 0.22969941787111262,\n",
       "  'Pos': 0.38178115063864326,\n",
       "  'Neu': 0.3885194348792235},\n",
       " '-qFcO_onBdA': {'Neg': 0.3970037639141083,\n",
       "  'Pos': 0.07284530559554696,\n",
       "  'Neu': 0.5301509484648704},\n",
       " 'fp9uRsmTWqg': {'Neg': 0.5250400540729364,\n",
       "  'Pos': 0.14036676422175434,\n",
       "  'Neu': 0.33459319919347763},\n",
       " '3ZXR2eARmuQ': {'Neg': 0.10027769352309406,\n",
       "  'Pos': 0.5406160272657872,\n",
       "  'Neu': 0.3591062597930431},\n",
       " '57wz3HuIVLA': {'Neg': 0.06737328693270683,\n",
       "  'Pos': 0.6991583496332169,\n",
       "  'Neu': 0.23346834648400544},\n",
       " 'lbK7UjoLr8o': {'Neg': 0.26297249644994736,\n",
       "  'Pos': 0.32898617163300514,\n",
       "  'Neu': 0.4080413281917572},\n",
       " 'xV1oR-RbOGU': {'Neg': 0.32404468099897105,\n",
       "  'Pos': 0.2810820376293527,\n",
       "  'Neu': 0.394873258140352},\n",
       " 'kn6DKdInYXk': {'Neg': 0.3859320578048937,\n",
       "  'Pos': 0.3098619767697528,\n",
       "  'Neu': 0.304205977357924},\n",
       " '2T3yZ6lNRDg': {'Neg': 0.19512141330633312,\n",
       "  'Pos': 0.3508006255142391,\n",
       "  'Neu': 0.4540779642760754},\n",
       " 'HLYSlKY6Ww4': {'Neg': 0.007169049711794489,\n",
       "  'Pos': 0.9201088746388754,\n",
       "  'Neu': 0.07272207602444622},\n",
       " 'sH_YoV-NA6s': {'Neg': 0.014411926706088707,\n",
       "  'Pos': 0.7213083794340491,\n",
       "  'Neu': 0.2642796989530325},\n",
       " 'ZLT6L3PHz78': {'Neg': 0.18452267441898584,\n",
       "  'Pos': 0.33050221428275106,\n",
       "  'Neu': 0.48497511744499205},\n",
       " 'lczwrm68u6I': {'Neg': 0.012433728890027852,\n",
       "  'Pos': 0.8680140405893326,\n",
       "  'Neu': 0.11955223185941577},\n",
       " 'zhBdbLj5y6A': {'Neg': 0.3512038664892316,\n",
       "  'Pos': 0.24891177341341972,\n",
       "  'Neu': 0.3998843662440777},\n",
       " 'ibWFsmcnefk': {'Neg': 0.35898849315708503,\n",
       "  'Pos': 0.3185772662051022,\n",
       "  'Neu': 0.32243423629552126},\n",
       " 'e0fN7HxkIUc': {'Neg': 0.5900237200781703,\n",
       "  'Pos': 0.12562738405540586,\n",
       "  'Neu': 0.28434889763593674},\n",
       " 'Ji47WRv2tQE': {'Neg': 0.48088988242670894,\n",
       "  'Pos': 0.2609048563055694,\n",
       "  'Neu': 0.25820527598261833},\n",
       " 'dj5ov38ihZI': {'Neg': 0.33171851307270117,\n",
       "  'Pos': 0.44357716385275126,\n",
       "  'Neu': 0.22470431122928858},\n",
       " 'j3E3NF9nk44': {'Neg': 0.283336016186513,\n",
       "  'Pos': 0.30184469763189553,\n",
       "  'Neu': 0.41481929272413254},\n",
       " 'BomdsEJjb0E': {'Neg': 0.5487090044447945,\n",
       "  'Pos': 0.1453861485545834,\n",
       "  'Neu': 0.3059048487080468},\n",
       " 'T7c6GvrF82k': {'Neg': 0.6308264874736779,\n",
       "  'Pos': 0.1568138910923153,\n",
       "  'Neu': 0.212359619140625},\n",
       " '6DBFwIlT4fg': {'Neg': 0.3545808039023541,\n",
       "  'Pos': 0.3060166474664584,\n",
       "  'Neu': 0.3394025292247534},\n",
       " '2FgFNBIJTIA': {'Neg': 0.6461022719740868,\n",
       "  'Pos': 0.017911696282681078,\n",
       "  'Neu': 0.3359860135242343},\n",
       " '254GdlKEz5I': {'Neg': 0.5694599201281866,\n",
       "  'Pos': 0.022785108846922714,\n",
       "  'Neu': 0.40775499244530994},\n",
       " 'y4qaoHc2ezk': {'Neg': 0.18913336993298596,\n",
       "  'Pos': 0.37199236928588814,\n",
       "  'Neu': 0.4388742782175541},\n",
       " '2VRGUm_wQ0w': {'Neg': 0.38828980412799863,\n",
       "  'Pos': 0.36005087837111205,\n",
       "  'Neu': 0.25165930576622486},\n",
       " 'HK5rfm4X2G0': {'Neg': 0.21503179722931237,\n",
       "  'Pos': 0.32239614622667434,\n",
       "  'Neu': 0.4625720638781786},\n",
       " '_DM5L8uu1Do': {'Neg': 0.14113119307439775,\n",
       "  'Pos': 0.4922996868379414,\n",
       "  'Neu': 0.36656914576888083},\n",
       " 'pK6y1h0YgSU': {'Neg': 0.11696977718384005,\n",
       "  'Pos': 0.757594421505928,\n",
       "  'Neu': 0.1254357792204246},\n",
       " 'a3-AiHSyTIU': {'Neg': 0.5161955257877707,\n",
       "  'Pos': 0.13858293732628227,\n",
       "  'Neu': 0.3452215358614922},\n",
       " 'SLrKdYsNbSo': {'Neg': 0.3231428869379063,\n",
       "  'Pos': 0.21953286645778766,\n",
       "  'Neu': 0.4573242838184039},\n",
       " '8w61tigk0ag': {'Neg': 0.7055422127246856,\n",
       "  'Pos': 0.03963112242054194,\n",
       "  'Neu': 0.25482666939496995},\n",
       " 'Mwpqgw9gMfo': {'Neg': 0.01277605228824541,\n",
       "  'Pos': 0.8125654757022858,\n",
       "  'Neu': 0.1746584251523018},\n",
       " 'FJEMcVK0MWI': {'Neg': 0.0034766150887922515,\n",
       "  'Pos': 0.9128914134843009,\n",
       "  'Neu': 0.08363198768347502},\n",
       " 'gRKL_FUQUpY': {'Neg': 0.24368394557386636,\n",
       "  'Pos': 0.2982940323650837,\n",
       "  'Neu': 0.45802199468016624},\n",
       " 'LLFcBFAuauk': {'Neg': 0.32109121009125374,\n",
       "  'Pos': 0.4738640346331522,\n",
       "  'Neu': 0.20504474034532905},\n",
       " 'EsW0ye2wjUQ': {'Neg': 0.4900619387626648,\n",
       "  'Pos': 0.0339045524597168,\n",
       "  'Neu': 0.4760335087776184},\n",
       " 'R0i7i80ToUM': {'Neg': 0.08631485649675597,\n",
       "  'Pos': 0.7394320608582348,\n",
       "  'Neu': 0.17425306583754718},\n",
       " '6zkba0hNiE8': {'Neg': 0.13019369752146304,\n",
       "  'Pos': 0.2849810738116503,\n",
       "  'Neu': 0.5848252233117819},\n",
       " 'T48EuGS36Zk': {'Neg': 0.12247256049886346,\n",
       "  'Pos': 0.7139445941170884,\n",
       "  'Neu': 0.16358284341792265},\n",
       " 'KzCjAetb3_I': {'Neg': 0.0829349166015163,\n",
       "  'Pos': 0.5904765650629997,\n",
       "  'Neu': 0.3265885107219219},\n",
       " 'N9OQbW0YOLU': {'Neg': 0.4184330953617713,\n",
       "  'Pos': 0.23125017753669194,\n",
       "  'Neu': 0.35031672487301485},\n",
       " 'I4WXmX_6Zds': {'Neg': 0.3545514851342887,\n",
       "  'Pos': 0.2620341627858579,\n",
       "  'Neu': 0.3834143545478582},\n",
       " 'WTD3l2xovQI': {'Neg': 0.14517382263147738,\n",
       "  'Pos': 0.6795096568530425,\n",
       "  'Neu': 0.1753165521658957},\n",
       " 'LtW0cTMWdbY': {'Neg': 0.3060472868382931,\n",
       "  'Pos': 0.12382551711052656,\n",
       "  'Neu': 0.5701272189617157},\n",
       " 'iVM-azf1Akk': {'Neg': 0.7796124054325951,\n",
       "  'Pos': 0.026476849775968328,\n",
       "  'Neu': 0.1939107734296057},\n",
       " 'xWV_GI9hq5U': {'Neg': 0.18995033079991117,\n",
       "  'Pos': 0.48950322102755306,\n",
       "  'Neu': 0.3205464689526707},\n",
       " '-LFGaCkPzzY': {'Neg': 0.2800370619321863,\n",
       "  'Pos': 0.15166502942641577,\n",
       "  'Neu': 0.5682978928089142},\n",
       " 'rFDK10oplxA': {'Neg': 0.24117284515199977,\n",
       "  'Pos': 0.4010806452586419,\n",
       "  'Neu': 0.3577464930713177},\n",
       " '6p_8T_xmnLQ': {'Neg': 0.2893649827921763,\n",
       "  'Pos': 0.5290655262768269,\n",
       "  'Neu': 0.1815694997087121},\n",
       " 'D9-CHldoZ74': {'Neg': 0.48348832523657215,\n",
       "  'Pos': 0.2032786733729558,\n",
       "  'Neu': 0.31323300881518257},\n",
       " 'xqz1KueuzAM': {'Neg': 0.3269189974293113,\n",
       "  'Pos': 0.19688038467429578,\n",
       "  'Neu': 0.4762006364762783},\n",
       " 'T2JkwAZ8KY8': {'Neg': 0.5645740833133459,\n",
       "  'Pos': 0.1731405962879459,\n",
       "  'Neu': 0.26228532360659707},\n",
       " 'TQ0QJ4Si7A4': {'Neg': 0.29102530144155025,\n",
       "  'Pos': 0.09057668270543218,\n",
       "  'Neu': 0.6183980032801628},\n",
       " '81Fj00CFmJM': {'Neg': 0.24897830229666498,\n",
       "  'Pos': 0.12424740919636355,\n",
       "  'Neu': 0.6267742878860898},\n",
       " 'C-iuGrZR2pQ': {'Neg': 0.325102233979851,\n",
       "  'Pos': 0.24287764057517053,\n",
       "  'Neu': 0.4320201318711042},\n",
       " 'JT1R95tG9jg': {'Neg': 0.30956499150488526,\n",
       "  'Pos': 0.24831762025132775,\n",
       "  'Neu': 0.44211739487946033},\n",
       " 'O06AlL8nONo': {'Neg': 0.28957968892063946,\n",
       "  'Pos': 0.06958389980718493,\n",
       "  'Neu': 0.6408364027738571},\n",
       " 'HabzHfgdMNs': {'Neg': 0.22908939953194932,\n",
       "  'Pos': 0.5894168902188539,\n",
       "  'Neu': 0.18149370718747376},\n",
       " 'o96VMbz4Zpk': {'Neg': 0.6827418506145477,\n",
       "  'Pos': 0.01484176586382091,\n",
       "  'Neu': 0.3024163469672203},\n",
       " 'XylXJJp4HpE': {'Neg': 0.14342491639157137,\n",
       "  'Pos': 0.4279274278216892,\n",
       "  'Neu': 0.4286476737923092},\n",
       " 'ZaTPlJ8nd9Q': {'Neg': 0.13120037869602028,\n",
       "  'Pos': 0.6347056235083275,\n",
       "  'Neu': 0.2340939815880524},\n",
       " 'R3E3RlBEIl8': {'Neg': 0.03488782932981849,\n",
       "  'Pos': 0.41126159206032753,\n",
       "  'Neu': 0.5538505762815475},\n",
       " '5jCZ42fV6sw': {'Neg': 0.2389572646934539,\n",
       "  'Pos': 0.34653391502797604,\n",
       "  'Neu': 0.4145087953656912},\n",
       " 'tq7FyWSGaD4': {'Neg': 0.34068963889564785,\n",
       "  'Pos': 0.2580589501054159,\n",
       "  'Neu': 0.40125142144305365},\n",
       " 'jQusLZgOYac': {'Neg': 0.1076863578055054,\n",
       "  'Pos': 0.6641305622955164,\n",
       "  'Neu': 0.22818305172647038},\n",
       " 'iOnxb9jrY40': {'Neg': 0.3014579782262444,\n",
       "  'Pos': 0.19125144663266838,\n",
       "  'Neu': 0.5072905749082566},\n",
       " 'UWMmesK08TU': {'Neg': 0.3651632502675056,\n",
       "  'Pos': 0.12370195873081684,\n",
       "  'Neu': 0.5111347794532776},\n",
       " '4bub6WOlT-I': {'Neg': 0.24461411625088658,\n",
       "  'Pos': 0.424896051408723,\n",
       "  'Neu': 0.3304898105561733},\n",
       " 'jIsXjk3TgkU': {'Neg': 0.10518657099455594,\n",
       "  'Pos': 0.46090862452983855,\n",
       "  'Neu': 0.4339048116467893},\n",
       " 'W8WAKyR5pGA': {'Neg': 0.02103787288069725,\n",
       "  'Pos': 0.25927117466926575,\n",
       "  'Neu': 0.7196909785270691},\n",
       " 'ZBO3c3ko0eg': {'Neg': 0.3899563193424708,\n",
       "  'Pos': 0.1898460901963214,\n",
       "  'Neu': 0.4201975895298852},\n",
       " 'FIiz8hqXm24': {'Neg': 0.31086225735230577,\n",
       "  'Pos': 0.138207846838567,\n",
       "  'Neu': 0.5509298791488012},\n",
       " 'I3mkImSqHA0': {'Neg': 0.48593970470958286,\n",
       "  'Pos': 0.09399411061571704,\n",
       "  'Neu': 0.42006618943479324},\n",
       " 'DTUckJz0RGo': {'Neg': 0.5936250320325295,\n",
       "  'Pos': 0.053688747989427715,\n",
       "  'Neu': 0.3526861895289686},\n",
       " 'JWA5mUrrr_A': {'Neg': 0.4476510102977045,\n",
       "  'Pos': 0.1566269438713789,\n",
       "  'Neu': 0.39572202335111795},\n",
       " 'XqzQanN4Xx8': {'Neg': 0.15934443611185997,\n",
       "  'Pos': 0.5685877189040184,\n",
       "  'Neu': 0.27206783536821605},\n",
       " 'QjJwrWxwLJU': {'Neg': 0.1579431314021349,\n",
       "  'Pos': 0.29010852752253413,\n",
       "  'Neu': 0.5519483331590891},\n",
       " 'D7zMgv16cik': {'Neg': 0.38652886769601275,\n",
       "  'Pos': 0.2077847719192505,\n",
       "  'Neu': 0.40568635186978746},\n",
       " 'bJYGvO6V67A': {'Neg': 0.002704152837395668,\n",
       "  'Pos': 0.9547702670097351,\n",
       "  'Neu': 0.042525514960289},\n",
       " 'sJ0xpruFAwQ': {'Neg': 0.26731621702331015,\n",
       "  'Pos': 0.49249360700034434,\n",
       "  'Neu': 0.2401901731888453},\n",
       " 'ENk_QRA2XsY': {'Neg': 0.17662172483978794,\n",
       "  'Pos': 0.3967017057351768,\n",
       "  'Neu': 0.42667658925056456},\n",
       " 'OB0qJwk5yA8': {'Neg': 0.16235541123896838,\n",
       "  'Pos': 0.437119210511446,\n",
       "  'Neu': 0.40052539184689523},\n",
       " '29LXKUT0eMY': {'Neg': 0.563924511273702,\n",
       "  'Pos': 0.037749984146406255,\n",
       "  'Neu': 0.39832553019126254},\n",
       " 'Bo24jIb7GA8': {'Neg': 0.27485242630872464,\n",
       "  'Pos': 0.21806760049528545,\n",
       "  'Neu': 0.5070799589157104},\n",
       " '19hkLN7KEqc': {'Neg': 0.4250611807737086,\n",
       "  'Pos': 0.15854038437828422,\n",
       "  'Neu': 0.41639845073223114},\n",
       " '_quGokF8G0o': {'Neg': 0.31950254725026234,\n",
       "  'Pos': 0.25070636267108576,\n",
       "  'Neu': 0.42979112161057337},\n",
       " 'M7qPgEDk2JY': {'Neg': 0.33231044868007303,\n",
       "  'Pos': 0.20843206187710167,\n",
       "  'Neu': 0.4592574782669544},\n",
       " '-PqXVcMtygc': {'Neg': 0.5558043579415729,\n",
       "  'Pos': 0.3324661096557975,\n",
       "  'Neu': 0.11172952720274527},\n",
       " 'GUVKWAEO_hY': {'Neg': 0.1972051908960566,\n",
       "  'Pos': 0.3771052295342088,\n",
       "  'Neu': 0.42568958760239184},\n",
       " '_S_9JRwFmcA': {'Neg': 0.004872555378824472,\n",
       "  'Pos': 0.9520999789237976,\n",
       "  'Neu': 0.04302745312452316},\n",
       " 'LWIgEf_TMVU': {'Neg': 0.3389627614989877,\n",
       "  'Pos': 0.28782967692241074,\n",
       "  'Neu': 0.37320754677057266},\n",
       " 'aw59h2FNMIQ': {'Neg': 0.3863627668470144,\n",
       "  'Pos': 0.14319069050252436,\n",
       "  'Neu': 0.4704465545713902},\n",
       " 'lw0rcwYyiwE': {'Neg': 0.3034736591258219,\n",
       "  'Pos': 0.20126029423304967,\n",
       "  'Neu': 0.49526605010032654},\n",
       " 'sEjN7muHOLc': {'Neg': 0.5234656795975752,\n",
       "  'Pos': 0.2333638820797205,\n",
       "  'Neu': 0.24317042995244265},\n",
       " 'Y-xQtgvNuvA': {'Neg': 0.2755630847791003,\n",
       "  'Pos': 0.3815554017201066,\n",
       "  'Neu': 0.3428815371460385},\n",
       " 'W7n2FoRinVk': {'Neg': 0.4335947883082554,\n",
       "  'Pos': 0.17331847012974322,\n",
       "  'Neu': 0.393086732365191},\n",
       " 'Wjj__vIdew0': {'Neg': 0.3920016430929536,\n",
       "  'Pos': 0.2223463038681075,\n",
       "  'Neu': 0.38565206760540605},\n",
       " '5DvMPgoKZmM': {'Neg': 0.44655279628932476,\n",
       "  'Pos': 0.2427801410926299,\n",
       "  'Neu': 0.3106670396195518}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_per_vid_scores(covid_filtered_out_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
