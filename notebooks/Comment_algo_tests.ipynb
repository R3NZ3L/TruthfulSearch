{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import translators as ts\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment\n",
       "0  aLZ85hb4wjE                     Loved the calmness of Manilla.\n",
       "1  aLZ85hb4wjE  After this pandemic I think every country shou...\n",
       "2  aLZ85hb4wjE           manila looks beautifull with less people\n",
       "3  aLZ85hb4wjE  The lockdown makes the city look like a place ...\n",
       "4  aLZ85hb4wjE                                    India also same"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/covid_philippines/covid_philippines_comments.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_comments = {}\n",
    "translated_comments[\"video_id\"] = {}\n",
    "translated_comments[\"comment\"] = {}\n",
    "video_id_list = df[\"video_id\"].to_list()\n",
    "comments_list = df[\"comment\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating...: 100%|██████████| 1216/1216 [02:59<00:00,  6.77it/s]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(video_id_list))\n",
    "pbar.set_description(\"Translating...\")\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    if comments_list[i] != None:\n",
    "        new_comment = comments_list[i]\n",
    "        try:\n",
    "            lang = detect(comments_list[i]) #added langdetect since it errors if there are many entries to translate, so now it will ontly tranlate if comment not english\n",
    "            if lang != 'en':\n",
    "                new_comment = ts.translate_text(comments_list[i], 'google', to_language = 'en')\n",
    "                \n",
    "        except:\n",
    "            # No change; get same comment from list\n",
    "            pass\n",
    "            \n",
    "        finally:\n",
    "            translated_comments[\"video_id\"][i] = video_id_list[i]\n",
    "            translated_comments[\"comment\"][i] = new_comment\n",
    "            pbar.update(1)\n",
    "\n",
    "translated_df = pd.DataFrame.from_dict(translated_comments)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>This covid will be a never-ending fuckery as l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>A new variant is inevitable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>The man that should resign from his office is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>Is that the people who got been vaccinated.,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>The toxic of comments section 😄 \\r\\n During th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                            comment\n",
       "0     aLZ85hb4wjE                     Loved the calmness of Manilla.\n",
       "1     aLZ85hb4wjE  After this pandemic I think every country shou...\n",
       "2     aLZ85hb4wjE           manila looks beautifull with less people\n",
       "3     aLZ85hb4wjE  The lockdown makes the city look like a place ...\n",
       "4     aLZ85hb4wjE                                    India also same\n",
       "...           ...                                                ...\n",
       "1211  5DvMPgoKZmM  This covid will be a never-ending fuckery as l...\n",
       "1212  5DvMPgoKZmM                       A new variant is inevitable.\n",
       "1213  5DvMPgoKZmM  The man that should resign from his office is ...\n",
       "1214  5DvMPgoKZmM       Is that the people who got been vaccinated.,\n",
       "1215  5DvMPgoKZmM  The toxic of comments section 😄 \\r\\n During th...\n",
       "\n",
       "[1216 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(video_id_list, comments_list):\n",
    "    translated_comments = {}\n",
    "    translated_comments[\"video_id\"] = {}\n",
    "    translated_comments[\"comment\"] = {}\n",
    "    \n",
    "    pbar = tqdm(total=len(video_id_list))\n",
    "    pbar.set_description(\"Translating...\")\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        if comments_list[i] != None:\n",
    "            new_comment = comments_list[i]\n",
    "            try:\n",
    "                lang = detect(comments_list[i]) #added langdetect since it errors if there are many entries to translate, so now it will ontly tranlate if comment not english\n",
    "                if lang != 'en':\n",
    "                    new_comment = ts.translate_text(comments_list[i], 'google', to_language = 'en')\n",
    "\n",
    "            except:\n",
    "                # No change; get same comment from list\n",
    "                pass\n",
    "\n",
    "            finally:\n",
    "                translated_comments[\"video_id\"][i] = video_id_list[i]\n",
    "                translated_comments[\"comment\"][i] = new_comment\n",
    "                pbar.update(1)\n",
    "\n",
    "    translated_df = pd.DataFrame.from_dict(translated_comments)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETECT SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0:Not Spam\n",
    "- 1:Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    1508\n",
       "AUTHOR        1508\n",
       "DATE          1508\n",
       "CONTENT       1508\n",
       "CLASS         1508\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset source: https://archive.ics.uci.edu/dataset/380/youtube+spam+collection\n",
    "\n",
    "psy_model_df = pd.read_csv(\"../datasets/model_train/Youtube01-Psy.csv\")\n",
    "lmfao_model_df = pd.read_csv(\"../datasets/model_train/Youtube03-LMFAO.csv\")\n",
    "kp_model_df = pd.read_csv(\"../datasets/model_train/Youtube02-KatyPerry.csv\")\n",
    "shakira_df = pd.read_csv(\"../datasets/model_train/Youtube05-Shakira.csv\")\n",
    "model_df = pd.concat([psy_model_df,lmfao_model_df,kp_model_df,shakira_df])\n",
    "model_df.reset_index(inplace=True, drop=True) \n",
    "model_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>_2viQ_Qnc6_1Hq9MGlefkBIszt9rYD3S_CozADvMhQ4</td>\n",
       "      <td>Dinova Sharon</td>\n",
       "      <td>2013-07-13T14:44:00.700000</td>\n",
       "      <td>well done shakira</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>_2viQ_Qnc6-bMSjqyL1NKj57ROicCSJV5SwTrw-RFFA</td>\n",
       "      <td>Katie Mettam</td>\n",
       "      <td>2013-07-13T13:27:39.441000</td>\n",
       "      <td>I love this song because we sing it at Camp al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>_2viQ_Qnc6-pY-1yR6K2FhmC5i48-WuNx5CumlHLDAI</td>\n",
       "      <td>Sabina Pearson-Smith</td>\n",
       "      <td>2013-07-13T13:14:30.021000</td>\n",
       "      <td>I love this song for two reasons: 1.it is abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>_2viQ_Qnc6_yBt8UGMWyg3vh0PulTqcqyQtdE7d4Fl0</td>\n",
       "      <td>Aishlin Maciel</td>\n",
       "      <td>2013-07-13T11:17:52.308000</td>\n",
       "      <td>Shakira u are so wiredo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>_2viQ_Qnc685RPw1aSa1tfrIuHXRvAQ2rPT9R06KTqA</td>\n",
       "      <td>Latin Bosch</td>\n",
       "      <td>2013-07-12T22:33:27.916000</td>\n",
       "      <td>Shakira is the best dancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1362 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       COMMENT_ID                AUTHOR  \\\n",
       "0     LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU             Julius NM   \n",
       "1     LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A           adam riyati   \n",
       "2     LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8      Evgeny Murashkin   \n",
       "3             z13jhp0bxqncu512g22wvzkasxmvvzjaz04       ElNino Melendez   \n",
       "4             z13fwbwp1oujthgqj04chlngpvzmtt3r3dw                GsMega   \n",
       "...                                           ...                   ...   \n",
       "1502  _2viQ_Qnc6_1Hq9MGlefkBIszt9rYD3S_CozADvMhQ4         Dinova Sharon   \n",
       "1503  _2viQ_Qnc6-bMSjqyL1NKj57ROicCSJV5SwTrw-RFFA          Katie Mettam   \n",
       "1504  _2viQ_Qnc6-pY-1yR6K2FhmC5i48-WuNx5CumlHLDAI  Sabina Pearson-Smith   \n",
       "1506  _2viQ_Qnc6_yBt8UGMWyg3vh0PulTqcqyQtdE7d4Fl0        Aishlin Maciel   \n",
       "1507  _2viQ_Qnc685RPw1aSa1tfrIuHXRvAQ2rPT9R06KTqA           Latin Bosch   \n",
       "\n",
       "                            DATE  \\\n",
       "0            2013-11-07T06:20:48   \n",
       "1            2013-11-07T12:37:15   \n",
       "2            2013-11-08T17:34:21   \n",
       "3            2013-11-09T08:28:43   \n",
       "4            2013-11-10T16:05:38   \n",
       "...                          ...   \n",
       "1502  2013-07-13T14:44:00.700000   \n",
       "1503  2013-07-13T13:27:39.441000   \n",
       "1504  2013-07-13T13:14:30.021000   \n",
       "1506  2013-07-13T11:17:52.308000   \n",
       "1507  2013-07-12T22:33:27.916000   \n",
       "\n",
       "                                                CONTENT  CLASS  \n",
       "0     Huh, anyway check out this you[tube] channel: ...      1  \n",
       "1     Hey guys check out my new channel and our firs...      1  \n",
       "2                just for test I have to say murdev.com      1  \n",
       "3      me shaking my sexy ass on my channel enjoy ^_^ ﻿      1  \n",
       "4               watch?v=vtaRGgvGtWQ   Check this out .﻿      1  \n",
       "...                                                 ...    ...  \n",
       "1502                                  well done shakira      0  \n",
       "1503  I love this song because we sing it at Camp al...      0  \n",
       "1504  I love this song for two reasons: 1.it is abou...      0  \n",
       "1506                            Shakira u are so wiredo      0  \n",
       "1507                         Shakira is the best dancer      0  \n",
       "\n",
       "[1362 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.drop_duplicates(subset=\"CONTENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMENT_ID    1508\n",
       "AUTHOR        1508\n",
       "DATE          1508\n",
       "CONTENT       1508\n",
       "CLASS         1508\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Melanie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "stop_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['CONTENT'] = model_df['CONTENT'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "\n",
    "ps = PorterStemmer() \n",
    "for w in model_df[\"CONTENT\"]: \n",
    "    #convert to lowercase\n",
    "    model_df['CONTENT'] = model_df[\"CONTENT\"].str.lower()\n",
    "    #Stem\n",
    "    model_df['CONTENT'] = model_df[\"CONTENT\"].apply(ps.stem) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model_df[\"CONTENT\"]\n",
    "y  =model_df[\"CLASS\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test  = train_test_split(x,y,random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9717064544650752\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       544\n",
      "           1       0.97      0.97      0.97       587\n",
      "\n",
      "    accuracy                           0.97      1131\n",
      "   macro avg       0.97      0.97      0.97      1131\n",
      "weighted avg       0.97      0.97      0.97      1131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_nb = MultinomialNB()\n",
    "spam_nb.fit(x_train,y_train)\n",
    "\n",
    "predictions=spam_nb.predict(x_train)\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(f\"Train Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_train, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9177718832891246\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       204\n",
      "           1       0.92      0.90      0.91       173\n",
      "\n",
      "    accuracy                           0.92       377\n",
      "   macro avg       0.92      0.92      0.92       377\n",
      "weighted avg       0.92      0.92      0.92       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=spam_nb.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with another dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z12rwfnyyrbsefonb232i5ehdxzkjzjs2</td>\n",
       "      <td>Lisa Wellas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+447935454150 lovely girl talk to me xxx﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z130wpnwwnyuetxcn23xf5k5ynmkdpjrj04</td>\n",
       "      <td>jason graham</td>\n",
       "      <td>2015-05-29T02:26:10.652000</td>\n",
       "      <td>I always end up coming back to this song&lt;br /&gt;﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z13vsfqirtavjvu0t22ezrgzyorwxhpf3</td>\n",
       "      <td>Ajkal Khan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my sister just received over 6,500 new &lt;a rel=...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z12wjzc4eprnvja4304cgbbizuved35wxcs</td>\n",
       "      <td>Dakota Taylor</td>\n",
       "      <td>2015-05-29T02:13:07.810000</td>\n",
       "      <td>Cool﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13xjfr42z3uxdz2223gx5rrzs3dt5hna</td>\n",
       "      <td>Jihad Naser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello I&amp;#39;am from Palastine﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            COMMENT_ID         AUTHOR  \\\n",
       "0    z12rwfnyyrbsefonb232i5ehdxzkjzjs2    Lisa Wellas   \n",
       "1  z130wpnwwnyuetxcn23xf5k5ynmkdpjrj04   jason graham   \n",
       "2    z13vsfqirtavjvu0t22ezrgzyorwxhpf3     Ajkal Khan   \n",
       "3  z12wjzc4eprnvja4304cgbbizuved35wxcs  Dakota Taylor   \n",
       "4    z13xjfr42z3uxdz2223gx5rrzs3dt5hna    Jihad Naser   \n",
       "\n",
       "                         DATE  \\\n",
       "0                         NaN   \n",
       "1  2015-05-29T02:26:10.652000   \n",
       "2                         NaN   \n",
       "3  2015-05-29T02:13:07.810000   \n",
       "4                         NaN   \n",
       "\n",
       "                                             CONTENT  CLASS  \n",
       "0          +447935454150 lovely girl talk to me xxx﻿      1  \n",
       "1    I always end up coming back to this song<br />﻿      0  \n",
       "2  my sister just received over 6,500 new <a rel=...      1  \n",
       "3                                              Cool﻿      0  \n",
       "4                     Hello I&#39;am from Palastine﻿      1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset source: https://archive.ics.uci.edu/dataset/380/youtube+spam+collection\n",
    "\n",
    "em_model_df = pd.read_csv(\"../datasets/model_train/Youtube04-Eminem.csv\")\n",
    "em_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_model_df['CONTENT'] = em_model_df['CONTENT'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "\n",
    "ps = PorterStemmer() \n",
    "for w in em_model_df[\"CONTENT\"]: \n",
    "    #convert to lowercase\n",
    "    em_model_df['CONTENT'] = em_model_df[\"CONTENT\"].str.lower()\n",
    "    #Stem\n",
    "    em_model_df['CONTENT'] = em_model_df[\"CONTENT\"].apply(ps.stem) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_x=em_model_df[\"CONTENT\"]\n",
    "em_y=em_model_df[\"CLASS\"]\n",
    "\n",
    "em_x=vectorizer.transform(em_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8526785714285714\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82       203\n",
      "           1       0.82      0.94      0.87       245\n",
      "\n",
      "    accuracy                           0.85       448\n",
      "   macro avg       0.86      0.84      0.85       448\n",
      "weighted avg       0.86      0.85      0.85       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=spam_nb.predict(em_x)\n",
    "accuracy = accuracy_score(em_y, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(em_y, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypertuning MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0, 10.0,2,0.2 ],\n",
    "    'fit_prior': [True, False],\n",
    "    'class_prior': [None, [0.1,]* len(model_df[\"CLASS\"]), ]\n",
    "         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 28 is smaller than n_iter=500. Running 28 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "140 fits failed out of a total of 280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "140 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 775, in fit\n",
      "    self._update_class_log_prior(class_prior=class_prior)\n",
      "  File \"d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 590, in _update_class_log_prior\n",
      "    raise ValueError(\"Number of priors must match number of classes.\")\n",
      "ValueError: Number of priors must match number of classes.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.89670261 0.90238994        nan        nan 0.9108805  0.91751123\n",
      "        nan        nan 0.92132075 0.9269991         nan        nan\n",
      " 0.91754717 0.92701707        nan        nan 0.87111411 0.88439353\n",
      "        nan        nan 0.9184726  0.92701707        nan        nan\n",
      " 0.91468104 0.91941599        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#multinomial_nb_grid = GridSearchCV(MultinomialNB(), param_grid=hyperparameters, n_jobs=-1, cv=5, verbose=5).fi t(x_train,y_train)\n",
    "#https://coderzcolumn.com/tutorials/machine-learning/scikit-learn-sklearn-naive-bayes#6\n",
    "multinomial_nb_random = RandomizedSearchCV(MultinomialNB(),param_distributions=hyperparameters,n_iter=500,cv=10,random_state=42).fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_prior': False, 'class_prior': None, 'alpha': 1.0}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_nb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9161147902869757\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       244\n",
      "           1       0.92      0.90      0.91       209\n",
      "\n",
      "    accuracy                           0.92       453\n",
      "   macro avg       0.92      0.91      0.92       453\n",
      "weighted avg       0.92      0.92      0.92       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = multinomial_nb_random.best_estimator_.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8928571428571429\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88       203\n",
      "           1       0.87      0.94      0.91       245\n",
      "\n",
      "    accuracy                           0.89       448\n",
      "   macro avg       0.90      0.89      0.89       448\n",
      "weighted avg       0.89      0.89      0.89       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = multinomial_nb_random.best_estimator_.predict(em_x)\n",
    "accuracy = accuracy_score(em_y, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(em_y, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=model_df[\"CONTENT\"]\n",
    "y=model_df[\"CLASS\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x=vectorizer.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test  = train_test_split(x,y,test_size=0.30,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8265402843601896\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       504\n",
      "           1       0.84      0.83      0.83       551\n",
      "\n",
      "    accuracy                           0.83      1055\n",
      "   macro avg       0.83      0.83      0.83      1055\n",
      "weighted avg       0.83      0.83      0.83      1055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel = 'sigmoid', gamma = 1.0)\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "predictions = svm_model.predict(x_train)\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(f\"Train Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_train, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8432671081677704\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       244\n",
      "           1       0.81      0.86      0.83       209\n",
      "\n",
      "    accuracy                           0.84       453\n",
      "   macro avg       0.84      0.84      0.84       453\n",
      "weighted avg       0.84      0.84      0.84       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = svm_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8058035714285714\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       203\n",
      "           1       0.83      0.80      0.82       245\n",
      "\n",
      "    accuracy                           0.81       448\n",
      "   macro avg       0.80      0.81      0.80       448\n",
      "weighted avg       0.81      0.81      0.81       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "em_x=em_model_df[\"CONTENT\"]\n",
    "em_y=em_model_df[\"CLASS\"]\n",
    "\n",
    "em_x=vectorizer.transform(em_x)\n",
    "\n",
    "predictions = svm_model.predict(em_x)\n",
    "accuracy = accuracy_score(em_y, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(em_y, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters= [\n",
    "    {\n",
    "        \"C\":[0.0001, 0.001, 0.01 , 0.1, 1.0, 5, 30, 50],\n",
    "        \"kernel\": [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n",
    "        \"degree\" :[1, 3, 5, 10, 25, 50,100],\n",
    "        \"gamma\" :[\"scale\", \"auto\",1000, 10, 5, 2.5, 1.5, 1.0]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "111 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "111 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in fit\n",
      "    raise ValueError(\n",
      "ValueError: The dual coefficients or intercepts are not finite. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.86920934 0.52228212 0.50994609 0.52228212 0.9460018  0.8303504\n",
      " 0.55545373 0.93367475 0.82566038 0.9460018  0.62070979 0.70049416\n",
      " 0.9460018  0.9460018  0.9460018  0.57537287 0.52228212        nan\n",
      " 0.57537287 0.65229111 0.8303504  0.80781671 0.52228212 0.9478796\n",
      " 0.68056604 0.52228212        nan 0.52228212 0.56018868        nan\n",
      " 0.84363881 0.52228212 0.52228212 0.52228212 0.83221923 0.50617251\n",
      " 0.9460018  0.86920934 0.50044924 0.51942498 0.9460018  0.94980234\n",
      " 0.52228212 0.86161725 0.84646002 0.52228212 0.9460018  0.52228212\n",
      " 0.87398922        nan 0.52228212 0.90713387 0.94694519 0.62070979\n",
      " 0.52228212 0.82563342 0.52228212 0.90713387 0.86920934 0.52228212\n",
      " 0.82663073 0.5592363  0.93367475 0.52228212 0.57537287 0.9460018\n",
      " 0.95075472 0.9460018  0.9460018  0.82663073 0.52228212 0.8312938\n",
      " 0.90333333 0.52228212 0.86920934 0.8303504  0.62070979 0.86920934\n",
      " 0.90333333 0.9460018  0.52228212 0.94693621 0.57537287 0.52228212\n",
      " 0.52228212 0.86920934 0.8303504  0.52228212 0.52228212        nan\n",
      " 0.52228212 0.52228212 0.9460018  0.52228212        nan 0.52228212\n",
      " 0.9460018  0.95075472 0.52228212 0.94694519 0.52228212        nan\n",
      " 0.52228212        nan 0.52228212        nan 0.84459119 0.93367475\n",
      " 0.52228212        nan 0.89384546 0.70712489 0.90333333 0.52228212\n",
      " 0.90333333 0.5592363  0.52228212 0.93367475 0.52132974 0.52228212\n",
      " 0.52228212 0.9460018  0.86920934 0.52228212 0.9460018  0.57537287\n",
      " 0.9460018  0.52228212 0.52228212 0.8303504         nan 0.68056604\n",
      " 0.85598383 0.90713387 0.93367475 0.52228212 0.52228212 0.52228212\n",
      " 0.93176999 0.89198562 0.83790656 0.9460018  0.70712489 0.94694519\n",
      " 0.52228212        nan 0.86161725 0.62070979 0.93176999 0.52228212\n",
      " 0.52037736        nan 0.52228212 0.52228212 0.52228212 0.52228212\n",
      " 0.93367475 0.8312938  0.93367475 0.52228212 0.52228212 0.89384546\n",
      " 0.89010782 0.52228212 0.94693621 0.57537287 0.70712489 0.52228212\n",
      " 0.52228212 0.52228212 0.89010782 0.52228212 0.70712489 0.52228212\n",
      " 0.52228212 0.52228212 0.93367475 0.95075472 0.5592363  0.94694519\n",
      " 0.62070979 0.52228212 0.87493261 0.52228212 0.9460018  0.84078167\n",
      " 0.68056604        nan 0.52228212 0.8303504  0.9460018  0.8910602\n",
      " 0.52228212        nan 0.93367475 0.52228212 0.9460018  0.86920934\n",
      " 0.62070979 0.52228212]\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rssvc = RandomizedSearchCV(estimator = svc, param_distributions = hyperparameters, n_iter =200, cv=10, random_state=42).fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(degree=5, gamma=1000, kernel=&#x27;linear&#x27;, max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(degree=5, gamma=1000, kernel=&#x27;linear&#x27;, max_iter=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(degree=5, gamma=1000, kernel='linear', max_iter=500)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rssvc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9580573951434879\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       244\n",
      "           1       0.97      0.94      0.95       209\n",
      "\n",
      "    accuracy                           0.96       453\n",
      "   macro avg       0.96      0.96      0.96       453\n",
      "weighted avg       0.96      0.96      0.96       453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=rssvc.best_estimator_.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (EMINEM DF): 0.96875\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       203\n",
      "           1       1.00      0.95      0.97       245\n",
      "\n",
      "    accuracy                           0.97       448\n",
      "   macro avg       0.97      0.97      0.97       448\n",
      "weighted avg       0.97      0.97      0.97       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=rssvc.best_estimator_.predict(em_x)\n",
    "accuracy = accuracy_score(em_y, predictions)\n",
    "print(f\"Test Accuracy (EMINEM DF): {accuracy}\")\n",
    "\n",
    "class_report = classification_report(em_y, predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "better performance with eminem dataset using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_svc=rssvc.best_estimator_\n",
    "spam_nb=multinomial_nb_random.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Models Wih Translated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try models on translated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_spam_filtered = translated_df.copy()\n",
    "#svm_spam_filtered = translated_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_spam_filtered[\"comment_cleaned\"] = nb_spam_filtered[\"comment\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "\n",
    "ps = PorterStemmer() \n",
    "for w in nb_spam_filtered[\"comment\"]: \n",
    "    nb_spam_filtered[\"comment_cleaned\"] = nb_spam_filtered[\"comment\"].apply(ps.stem) \n",
    "    nb_spam_filtered[\"comment_cleaned\"] = nb_spam_filtered[\"comment\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_spam_filtered = nb_spam_filtered.copy() #so no need to go through same cleaning/preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "      <td>loved the calmness of manilla.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "      <td>after this pandemic i think every country shou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "      <td>the lockdown makes the city look like a place ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "      <td>india also same</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  aLZ85hb4wjE                     Loved the calmness of Manilla.   \n",
       "1  aLZ85hb4wjE  After this pandemic I think every country shou...   \n",
       "2  aLZ85hb4wjE           manila looks beautifull with less people   \n",
       "3  aLZ85hb4wjE  The lockdown makes the city look like a place ...   \n",
       "4  aLZ85hb4wjE                                    India also same   \n",
       "\n",
       "                                     comment_cleaned  spam  \n",
       "0                     loved the calmness of manilla.     0  \n",
       "1  after this pandemic i think every country shou...     0  \n",
       "2           manila looks beautifull with less people     0  \n",
       "3  the lockdown makes the city look like a place ...     0  \n",
       "4                                    india also same     1  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = vectorizer.transform(nb_spam_filtered[\"comment_cleaned\"])\n",
    "\n",
    "nb_spam_filtered[\"spam\"]=spam_nb.predict(transformed)\n",
    "nb_spam_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           470\n",
       "comment            470\n",
       "comment_cleaned    470\n",
       "spam               470\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_spam_filtered[nb_spam_filtered[\"spam\"]==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           746\n",
       "comment            746\n",
       "comment_cleaned    746\n",
       "spam               746\n",
       "dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_spam_filtered[nb_spam_filtered[\"spam\"]==0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "      <td>loved the calmness of manilla.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "      <td>after this pandemic i think every country shou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "      <td>the lockdown makes the city look like a place ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "      <td>india also same</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  aLZ85hb4wjE                     Loved the calmness of Manilla.   \n",
       "1  aLZ85hb4wjE  After this pandemic I think every country shou...   \n",
       "2  aLZ85hb4wjE           manila looks beautifull with less people   \n",
       "3  aLZ85hb4wjE  The lockdown makes the city look like a place ...   \n",
       "4  aLZ85hb4wjE                                    India also same   \n",
       "\n",
       "                                     comment_cleaned  spam  \n",
       "0                     loved the calmness of manilla.     0  \n",
       "1  after this pandemic i think every country shou...     0  \n",
       "2           manila looks beautifull with less people     0  \n",
       "3  the lockdown makes the city look like a place ...     0  \n",
       "4                                    india also same     0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = vectorizer.transform(svm_spam_filtered[\"comment_cleaned\"])\n",
    "\n",
    "svm_spam_filtered[\"spam\"]=spam_svc.predict(transformed)\n",
    "svm_spam_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           155\n",
       "comment            155\n",
       "comment_cleaned    155\n",
       "spam               155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_spam_filtered[svm_spam_filtered[\"spam\"]==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id           1061\n",
       "comment            1061\n",
       "comment_cleaned    1061\n",
       "spam               1061\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_spam_filtered[svm_spam_filtered[\"spam\"]==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3YFpjgIQqEo</td>\n",
       "      <td>This is how cold it is to just make it worse f...</td>\n",
       "      <td>this is how cold it is to just make it worse f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dIsaz_XlmTw</td>\n",
       "      <td>To those who say 18 cases are only detected. T...</td>\n",
       "      <td>to those who say 18 cases are only detected. t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dIsaz_XlmTw</td>\n",
       "      <td>Are we back when you hit tooth ache just covid...</td>\n",
       "      <td>are we back when you hit tooth ache just covid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>nTUWK8vufOk</td>\n",
       "      <td>I'm here out of curiosity if they include how ...</td>\n",
       "      <td>i'm here out of curiosity if they include how ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>cPVE7QGS7As</td>\n",
       "      <td>Deaths have been low compared to other countri...</td>\n",
       "      <td>deaths have been low compared to other countri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>sEjN7muHOLc</td>\n",
       "      <td>Revelation 13: 15-17 \\r\\n Are there scientific...</td>\n",
       "      <td>revelation 13: 15-17 \\r\\n are there scientific...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>Y-xQtgvNuvA</td>\n",
       "      <td>In the Philippines, mandatory faceshields and ...</td>\n",
       "      <td>in the philippines, mandatory faceshields and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>W7n2FoRinVk</td>\n",
       "      <td>Find out in your LGU first if you can. It's a ...</td>\n",
       "      <td>find out in your lgu first if you can. it's a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>It's been almost 2 years of this, and how many...</td>\n",
       "      <td>it's been almost 2 years of this, and how many...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>The toxic of comments section 😄 \\r\\n During th...</td>\n",
       "      <td>the toxic of comments section 😄 \\r\\n during th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                            comment  \\\n",
       "12    3YFpjgIQqEo  This is how cold it is to just make it worse f...   \n",
       "24    dIsaz_XlmTw  To those who say 18 cases are only detected. T...   \n",
       "28    dIsaz_XlmTw  Are we back when you hit tooth ache just covid...   \n",
       "49    nTUWK8vufOk  I'm here out of curiosity if they include how ...   \n",
       "58    cPVE7QGS7As  Deaths have been low compared to other countri...   \n",
       "...           ...                                                ...   \n",
       "1170  sEjN7muHOLc  Revelation 13: 15-17 \\r\\n Are there scientific...   \n",
       "1187  Y-xQtgvNuvA  In the Philippines, mandatory faceshields and ...   \n",
       "1191  W7n2FoRinVk  Find out in your LGU first if you can. It's a ...   \n",
       "1207  5DvMPgoKZmM  It's been almost 2 years of this, and how many...   \n",
       "1215  5DvMPgoKZmM  The toxic of comments section 😄 \\r\\n During th...   \n",
       "\n",
       "                                        comment_cleaned  spam  \n",
       "12    this is how cold it is to just make it worse f...     1  \n",
       "24    to those who say 18 cases are only detected. t...     1  \n",
       "28    are we back when you hit tooth ache just covid...     1  \n",
       "49    i'm here out of curiosity if they include how ...     1  \n",
       "58    deaths have been low compared to other countri...     1  \n",
       "...                                                 ...   ...  \n",
       "1170  revelation 13: 15-17 \\r\\n are there scientific...     1  \n",
       "1187  in the philippines, mandatory faceshields and ...     1  \n",
       "1191  find out in your lgu first if you can. it's a ...     1  \n",
       "1207  it's been almost 2 years of this, and how many...     1  \n",
       "1215  the toxic of comments section 😄 \\r\\n during th...     1  \n",
       "\n",
       "[155 rows x 4 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_spam_filtered[svm_spam_filtered[\"spam\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "      <td>loved the calmness of manilla.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "      <td>after this pandemic i think every country shou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "      <td>the lockdown makes the city look like a place ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "      <td>india also same</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>Please, if you have an option to get vaccinate...</td>\n",
       "      <td>please, if you have an option to get vaccinate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>This covid will be a never-ending fuckery as l...</td>\n",
       "      <td>this covid will be a never-ending fuckery as l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>A new variant is inevitable.</td>\n",
       "      <td>a new variant is inevitable.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>The man that should resign from his office is ...</td>\n",
       "      <td>the man that should resign from his office is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>5DvMPgoKZmM</td>\n",
       "      <td>Is that the people who got been vaccinated.,</td>\n",
       "      <td>is that the people who got been vaccinated.,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1061 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                            comment  \\\n",
       "0     aLZ85hb4wjE                     Loved the calmness of Manilla.   \n",
       "1     aLZ85hb4wjE  After this pandemic I think every country shou...   \n",
       "2     aLZ85hb4wjE           manila looks beautifull with less people   \n",
       "3     aLZ85hb4wjE  The lockdown makes the city look like a place ...   \n",
       "4     aLZ85hb4wjE                                    India also same   \n",
       "...           ...                                                ...   \n",
       "1210  5DvMPgoKZmM  Please, if you have an option to get vaccinate...   \n",
       "1211  5DvMPgoKZmM  This covid will be a never-ending fuckery as l...   \n",
       "1212  5DvMPgoKZmM                       A new variant is inevitable.   \n",
       "1213  5DvMPgoKZmM  The man that should resign from his office is ...   \n",
       "1214  5DvMPgoKZmM       Is that the people who got been vaccinated.,   \n",
       "\n",
       "                                        comment_cleaned  spam  \n",
       "0                        loved the calmness of manilla.     0  \n",
       "1     after this pandemic i think every country shou...     0  \n",
       "2              manila looks beautifull with less people     0  \n",
       "3     the lockdown makes the city look like a place ...     0  \n",
       "4                                       india also same     0  \n",
       "...                                                 ...   ...  \n",
       "1210  please, if you have an option to get vaccinate...     0  \n",
       "1211  this covid will be a never-ending fuckery as l...     0  \n",
       "1212                       a new variant is inevitable.     0  \n",
       "1213  the man that should resign from his office is ...     0  \n",
       "1214       is that the people who got been vaccinated.,     0  \n",
       "\n",
       "[1061 rows x 4 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_spam_filtered[svm_spam_filtered[\"spam\"]==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Israel-Palestine comments check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>No matter how many times these information get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>*To learn who RULES over you, simply find out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Say that part again: Jewish , Christian’s and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>So sad. They were living in peace and now suff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>Why start at 1946?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment\n",
       "0  R0ftmf_Uv9A  No matter how many times these information get...\n",
       "1  R0ftmf_Uv9A  *To learn who RULES over you, simply find out ...\n",
       "2  R0ftmf_Uv9A  Say that part again: Jewish , Christian’s and ...\n",
       "3  R0ftmf_Uv9A  So sad. They were living in peace and now suff...\n",
       "4  R0ftmf_Uv9A                                 Why start at 1946?"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_df = pd.read_csv(\"../datasets/israel-palestine_conflict_history/comments.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "is_pal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pal_df[\"comment\"] = is_pal_df[\"comment\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "\n",
    "ps = PorterStemmer() \n",
    "for w in is_pal_df[\"comment\"]: \n",
    "    is_pal_df[\"comment\"] = is_pal_df[\"comment\"].apply(ps.stem) \n",
    "    is_pal_df[\"comment\"] = is_pal_df[\"comment\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>no matter many times information gets thrown e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>*to learn rules you, simply find not allowed c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>say part again: jewish , christian’s muslims l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>so sad. they living peace suffering 7 decades 😢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>why start 1946?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  spam\n",
       "0  R0ftmf_Uv9A  no matter many times information gets thrown e...     0\n",
       "1  R0ftmf_Uv9A  *to learn rules you, simply find not allowed c...     1\n",
       "2  R0ftmf_Uv9A  say part again: jewish , christian’s muslims l...     1\n",
       "3  R0ftmf_Uv9A    so sad. they living peace suffering 7 decades 😢     0\n",
       "4  R0ftmf_Uv9A                                    why start 1946?     0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = vectorizer.transform(is_pal_df[\"comment\"])\n",
    "\n",
    "is_pal_df[\"spam\"]=spam_nb.predict(transformed)\n",
    "is_pal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id    583\n",
       "comment     583\n",
       "spam        583\n",
       "dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_df[is_pal_df[\"spam\"]==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id    1288\n",
       "comment     1288\n",
       "spam        1288\n",
       "dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_df[is_pal_df[\"spam\"]==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>*to learn rules you, simply find not allowed c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>say part again: jewish , christian’s muslims l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>thank's ireland, consistent n vocal supporting...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bno1m1zhIWs</td>\n",
       "      <td>finally. an objective concise summary religiou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bno1m1zhIWs</td>\n",
       "      <td>this first video actually explained things tho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>SsKpy2ftuF4</td>\n",
       "      <td>they gave fair warning time evacuation. that t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>JuU7pSDs8f4</td>\n",
       "      <td>angel one demat account(free) - https://tinyur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>JuU7pSDs8f4</td>\n",
       "      <td>nobody explain clear do. pl. keep videos.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>JuU7pSDs8f4</td>\n",
       "      <td>in telugu best channel facts best content rema...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>JuU7pSDs8f4</td>\n",
       "      <td>i'm upsc aspirant ....i seen many videos regar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                            comment  spam\n",
       "1     R0ftmf_Uv9A  *to learn rules you, simply find not allowed c...     1\n",
       "2     R0ftmf_Uv9A  say part again: jewish , christian’s muslims l...     1\n",
       "5     R0ftmf_Uv9A  thank's ireland, consistent n vocal supporting...     1\n",
       "12    Bno1m1zhIWs  finally. an objective concise summary religiou...     1\n",
       "13    Bno1m1zhIWs  this first video actually explained things tho...     1\n",
       "...           ...                                                ...   ...\n",
       "1859  SsKpy2ftuF4  they gave fair warning time evacuation. that t...     1\n",
       "1861  JuU7pSDs8f4  angel one demat account(free) - https://tinyur...     1\n",
       "1863  JuU7pSDs8f4          nobody explain clear do. pl. keep videos.     1\n",
       "1864  JuU7pSDs8f4  in telugu best channel facts best content rema...     1\n",
       "1867  JuU7pSDs8f4  i'm upsc aspirant ....i seen many videos regar...     1\n",
       "\n",
       "[583 rows x 3 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_df[is_pal_df[\"spam\"]==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>no matter many times information gets thrown e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>*to learn rules you, simply find not allowed c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>say part again: jewish , christian’s muslims l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>so sad. they living peace suffering 7 decades 😢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R0ftmf_Uv9A</td>\n",
       "      <td>why start 1946?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  spam\n",
       "0  R0ftmf_Uv9A  no matter many times information gets thrown e...     0\n",
       "1  R0ftmf_Uv9A  *to learn rules you, simply find not allowed c...     0\n",
       "2  R0ftmf_Uv9A  say part again: jewish , christian’s muslims l...     1\n",
       "3  R0ftmf_Uv9A    so sad. they living peace suffering 7 decades 😢     0\n",
       "4  R0ftmf_Uv9A                                    why start 1946?     0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = vectorizer.transform(is_pal_df[\"comment\"])\n",
    "\n",
    "is_pal_df[\"spam\"]=spam_svc.predict(transformed)\n",
    "is_pal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id    182\n",
       "comment     182\n",
       "spam        182\n",
       "dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_df[is_pal_df[\"spam\"]==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id    1689\n",
       "comment     1689\n",
       "spam        1689\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_df[is_pal_df[\"spam\"]==0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like SVM works better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "      <td>loved the calmness of manilla.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "      <td>after this pandemic i think every country shou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "      <td>the lockdown makes the city look like a place ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "      <td>india also same</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  aLZ85hb4wjE                     Loved the calmness of Manilla.   \n",
       "1  aLZ85hb4wjE  After this pandemic I think every country shou...   \n",
       "2  aLZ85hb4wjE           manila looks beautifull with less people   \n",
       "3  aLZ85hb4wjE  The lockdown makes the city look like a place ...   \n",
       "4  aLZ85hb4wjE                                    India also same   \n",
       "\n",
       "                                     comment_cleaned  spam  \n",
       "0                     loved the calmness of manilla.     0  \n",
       "1  after this pandemic i think every country shou...     0  \n",
       "2           manila looks beautifull with less people     0  \n",
       "3  the lockdown makes the city look like a place ...     0  \n",
       "4                                    india also same     0  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_filtered_out_df = svm_spam_filtered[svm_spam_filtered[\"spam\"]==0]\n",
    "covid_filtered_out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>Loved the calmness of Manilla.</td>\n",
       "      <td>loved the calmness of manilla.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>After this pandemic I think every country shou...</td>\n",
       "      <td>after this pandemic i think every country shou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>manila looks beautifull with less people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>The lockdown makes the city look like a place ...</td>\n",
       "      <td>the lockdown makes the city look like a place ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aLZ85hb4wjE</td>\n",
       "      <td>India also same</td>\n",
       "      <td>india also same</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                            comment  \\\n",
       "0  aLZ85hb4wjE                     Loved the calmness of Manilla.   \n",
       "1  aLZ85hb4wjE  After this pandemic I think every country shou...   \n",
       "2  aLZ85hb4wjE           manila looks beautifull with less people   \n",
       "3  aLZ85hb4wjE  The lockdown makes the city look like a place ...   \n",
       "4  aLZ85hb4wjE                                    India also same   \n",
       "\n",
       "                                     comment_cleaned  spam  \n",
       "0                     loved the calmness of manilla.     0  \n",
       "1  after this pandemic i think every country shou...     0  \n",
       "2           manila looks beautifull with less people     0  \n",
       "3  the lockdown makes the city look like a place ...     0  \n",
       "4                                    india also same     0  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pal_filtered_df = svm_spam_filtered[svm_spam_filtered[\"spam\"]==0]\n",
    "is_pal_filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import re\n",
    "from scipy.special import softmax\n",
    "\n",
    "def roberta_sentiment_scores(list_comments):\n",
    "    roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "    labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "\n",
    "    for comments in list_comments:\n",
    "        comment_words = []\n",
    "        comments = comments.replace(\"\\n\", \" \")\n",
    "        comments = comments.replace(\"\\xa0\", \" \")\n",
    "        comments = comments.replace(\"?\", \" \")\n",
    "        comments = comments.replace(\":\", \" \")\n",
    "        comments = comments.replace(\";\", \" \")\n",
    "        comments = comments.replace(\";\", \" \")\n",
    "        comments = re.sub(r\"\\s+\", ' ', comments) \n",
    "        print(comments)\n",
    "        for word in comments.split(' '):\n",
    "            if word.startswith('@') and len(word) > 1:\n",
    "               word = '@user'\n",
    "        \n",
    "            elif word.startswith('http'):\n",
    "                word = \"http\"\n",
    "            comment_words.append(word)\n",
    "\n",
    "        comment_procs = \" \".join(comment_words)\n",
    "\n",
    "        encoded = tokenizer(comment_procs, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "        print(encoded)\n",
    "        output = model(**encoded)\n",
    "\n",
    "        scores = output[0][0].detach().numpy()\n",
    "\n",
    "        scores = softmax(scores)\n",
    "\n",
    "        for i in range(len(scores)):\n",
    "\n",
    "            l = labels[i]\n",
    "            s = scores[i]\n",
    "            print(l, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\miniconda3\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved the calmness of Manilla.\n",
      "{'input_ids': tensor([[    0,   574, 12677,     5,  6327,  1825,     9,  1554,  4699,     4,\n",
      "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.0026419058\n",
      "Neutral 0.031785045\n",
      "Positive 0.9655731\n",
      "After this pandemic I think every country should have a lockdown every month to give mother nature a time to heal, with all the pollution that the earth is experiencing.\n",
      "{'input_ids': tensor([[    0,  4993,    42, 23387, 14414,    38,   206,   358,   247,   197,\n",
      "            33,    10, 23076,   358,   353,     7,   492,   985,  2574,    10,\n",
      "            86,     7, 14384,     6,    19,    70,     5,  6631,    14,     5,\n",
      "          6872,    16,  7242,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.72357625\n",
      "Neutral 0.25514364\n",
      "Positive 0.021280115\n",
      "manila looks beautifull with less people\n",
      "{'input_ids': tensor([[    0,   397,  4882,  1326, 28651,  1594,  5023,    19,   540,    82,\n",
      "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.023302699\n",
      "Neutral 0.14321633\n",
      "Positive 0.83348095\n",
      "The lockdown makes the city look like a place I want to explore. Before the lockdown, it looked like a crowded mess filled with traffic and pollution.\n",
      "{'input_ids': tensor([[    0,   133, 23076,   817,     5,   343,   356,   101,    10,   317,\n",
      "            38,   236,     7,  5393,     4,  3224,     5, 23076,     6,    24,\n",
      "          1415,   101,    10, 11138,  7319,  3820,    19,  1703,     8,  6631,\n",
      "             4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.41387478\n",
      "Neutral 0.4223302\n",
      "Positive 0.1637951\n",
      "India also same\n",
      "{'input_ids': tensor([[    0, 11015,    67,   276,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
      "Negative 0.081384994\n",
      "Neutral 0.8471448\n",
      "Positive 0.0714702\n",
      "The president promised that he'll do his best to ease the traffic in the metro like 5mins of travel along EDSA. Fortunately it happened but unfortunately it wasn't in the ideal way. Nature's sense of humor tho.\n",
      "{'input_ids': tensor([[    0,   133,   394,  3604,    14,    37,   581,   109,    39,   275,\n",
      "             7,  5136,     5,  1703,    11,     5, 12716,   101,   195, 30658,\n",
      "             9,  1504,   552, 12714,  3603,     4, 14802,    24,  1102,    53,\n",
      "          9574,    24,   938,    75,    11,     5,  5631,   169,     4, 10053,\n",
      "            18,  1472,     9, 12073, 41090,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.20141368\n",
      "Neutral 0.49210703\n",
      "Positive 0.3064793\n",
      "I went up the viewing spot at antipolo, its a very beautiful, almost smog free view of the metro skyline\n",
      "{'input_ids': tensor([[    0,   100,   439,    62,     5,  7603,  1514,    23, 37554,  5675,\n",
      "             6,    63,    10,   182,  2721,     6,   818,  5278,  2154,   481,\n",
      "          1217,     9,     5, 12716, 30728,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Negative 0.0017040264\n",
      "Neutral 0.021389995\n",
      "Positive 0.976906\n",
      "The sad part is people around the world did not intend to heal earth but afraid of death.\n",
      "{'input_ids': tensor([[    0,   133,  5074,   233,    16,    82,   198,     5,   232,   222,\n",
      "            45, 10557,     7, 14384,  6872,    53,  6023,     9,   744,     4,\n",
      "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.9466527\n",
      "Neutral 0.05063883\n",
      "Positive 0.0027084134\n",
      "i hope it stays like this forever its beautiful with no messy people\n",
      "{'input_ids': tensor([[    0,   118,  1034,    24, 10117,   101,    42,  6000,    63,  2721,\n",
      "            19,   117, 18882,    82,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.012420255\n",
      "Neutral 0.09276514\n",
      "Positive 0.8948146\n",
      "2020 is the year when nature fight back and reduce human emission dramatically.\n",
      "{'input_ids': tensor([[    0, 24837,    16,     5,    76,    77,  2574,  1032,   124,     8,\n",
      "          1888,  1050, 22679,  8617,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.03548623\n",
      "Neutral 0.45920116\n",
      "Positive 0.5053126\n",
      "Cough and cold season now because the weather is cold .... now covid again amg impression\n",
      "{'input_ids': tensor([[    0,   347,  4894,     8,  2569,   191,   122,   142,     5,  1650,\n",
      "            16,  2569, 39574,   122, 47268,   808,   456,   524,   571,  8450,\n",
      "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.5715849\n",
      "Neutral 0.38286152\n",
      "Positive 0.0455536\n",
      "Ala n covid tngina\n",
      "{'input_ids': tensor([[    0,  7083,   102,   295, 47268,   808,   326,  2590,  1243,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.20740348\n",
      "Neutral 0.66628414\n",
      "Positive 0.12631242\n",
      "Has it been in Bahrain so the diseases were the same time when it was so old that it was so painful when it came to winter\n",
      "{'input_ids': tensor([[    0, 35634,    24,    57,    11, 13800,    98,     5,  6357,    58,\n",
      "             5,   276,    86,    77,    24,    21,    98,   793,    14,    24,\n",
      "            21,    98,  8661,    77,    24,   376,     7,  2608,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]])}\n",
      "Negative 0.7892667\n",
      "Neutral 0.20188612\n",
      "Positive 0.008847155\n",
      "Season of cough and cold today here in Pinas after our cold day in the morning when it comes to the morning until the night is hot there is no aircon at home after entering work aircon their body temperature has changed before it does not get sick of cough and cold. .atibp\n",
      "{'input_ids': tensor([[    0, 37052,     9, 21768,     8,  2569,   452,   259,    11, 12009,\n",
      "           281,    71,    84,  2569,   183,    11,     5,   662,    77,    24,\n",
      "           606,     7,     5,   662,   454,     5,   363,    16,  2131,    89,\n",
      "            16,   117,   935,  3865,    23,   184,    71,  4201,   173,   935,\n",
      "          3865,    49,   809,  5181,    34,  1714,   137,    24,   473,    45,\n",
      "           120,  4736,     9, 21768,     8,  2569,     4,   479,   415,  1452,\n",
      "           642,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.44137755\n",
      "Neutral 0.46308964\n",
      "Positive 0.09553273\n",
      "It is difficult to cure 2_3wks.This is here in Nueva Ecija.\n",
      "{'input_ids': tensor([[    0,   243,    16,  1202,     7, 13306,   132,  1215,   246,   605,\n",
      "          2258,     4,   713,    16,   259,    11,   234,  1780,  3952,   381,\n",
      "          2520,  1910,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.65835446\n",
      "Neutral 0.3044711\n",
      "Positive 0.037174404\n",
      "Take a ginger drink ..\n",
      "{'input_ids': tensor([[    0, 21031,    10, 19863,  4076, 29942,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.023496099\n",
      "Neutral 0.8185454\n",
      "Positive 0.15795857\n",
      "It's not a joke to say that it's just a cold cold because my brother is the symptom of two hospitals we carry the same covid the outdoors too hard to breathe\n",
      "{'input_ids': tensor([[    0,   243,    18,    45,    10,  8018,     7,   224,    14,    24,\n",
      "            18,    95,    10,  2569,  2569,   142,   127,  2138,    16,     5,\n",
      "         28667,     9,    80,  4815,    52,  2324,     5,   276, 47268,   808,\n",
      "             5, 13384,   350,   543,     7, 14575,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.6197749\n",
      "Neutral 0.3233531\n",
      "Positive 0.056872044\n",
      "😊😊 😊\n",
      "{'input_ids': tensor([[    0, 18636, 27969, 18636, 27969, 17841, 27969,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.0031313696\n",
      "Neutral 0.068584144\n",
      "Positive 0.92828447\n",
      "There are many feverish fever here in the Philippines not just in China.\n",
      "{'input_ids': tensor([[    0,   970,    32,   171, 11696,  1173, 11696,   259,    11,     5,\n",
      "          5639,    45,    95,    11,   436,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.6582311\n",
      "Neutral 0.31710607\n",
      "Positive 0.024662782\n",
      "PRAISE GOD THERE ARE ONLY 18 CASES OUT OF 114 MILLION PEOPLE !! THANK YOU LORD WE ARE ALL HEALTHY ! COVID IS OVER !!\n",
      "{'input_ids': tensor([[    0,   510,  4396, 18819, 41827, 28842, 10616, 35669,   504, 24775,\n",
      "          1723, 14662,  3243, 15900, 34299,  7744, 16789, 43912, 42787, 10540,\n",
      "         45660, 10284, 10616, 12389, 12925, 33086,   975, 27785,  6247, 43814,\n",
      "          3703, 25133, 43912,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.004931455\n",
      "Neutral 0.048431896\n",
      "Positive 0.9466366\n",
      "DOH you have the power to report the height of the cases .. But backlogs of covid allowances of frontliners teach you a teach !!!!!\n",
      "{'input_ids': tensor([[    0,   495, 11979,    47,    33,     5,   476,     7,   266,     5,\n",
      "          6958,     9,     5,  1200, 29942,   125, 14846,    29,     9, 47268,\n",
      "           808, 23885,     9,   760, 18444,  6396,    47,    10,  6396, 43912,\n",
      "         16506,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.5291133\n",
      "Neutral 0.42791548\n",
      "Positive 0.04297118\n",
      "wow ! GOOD NEWS ! glad we are all safe and there is near zero cases of covid ! 🤗\n",
      "{'input_ids': tensor([[    0, 34798, 27785, 31708,  7857, 27785,  7785,    52,    32,    70,\n",
      "          1522,     8,    89,    16,   583,  4276,  1200,     9, 47268,   808,\n",
      "         27785,  8103, 10470,  6800,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]])}\n",
      "Negative 0.004520912\n",
      "Neutral 0.027586922\n",
      "Positive 0.96789217\n",
      "Thanks a Lot/ DOH- Keep all Our Health Well!!!❤😊\n",
      "{'input_ids': tensor([[    0, 22086,    10, 11973,    73, 14010,   725,    12,  7238,    70,\n",
      "          1541,  1309,  2647, 16506, 30151, 10470, 18636, 27969,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.0011429677\n",
      "Neutral 0.027316816\n",
      "Positive 0.9715403\n",
      "Is the covid BS 1 variant still coming\n",
      "{'input_ids': tensor([[    0,  6209,     5, 47268,   808, 26190,   112, 17390,   202,   567,\n",
      "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.041455552\n",
      "Neutral 0.92569965\n",
      "Positive 0.032844733\n",
      "here we go again\n",
      "{'input_ids': tensor([[    0, 10859,    52,   213,   456,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.57551485\n",
      "Neutral 0.3833746\n",
      "Positive 0.04111058\n",
      "Hmmm. this could be the triggering pin for the ....\n",
      "{'input_ids': tensor([[    0,   725, 41311,     4,    42,   115,    28,     5, 16902,  7756,\n",
      "            13,     5, 39574,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.35495794\n",
      "Neutral 0.6257598\n",
      "Positive 0.01928225\n",
      "Others country in south east Asia, people are dying on the complication of the mutate virus COVID. As far as US several cases have been reported on ICU don't be so carefree extreme measures and social distancing is a must\n",
      "{'input_ids': tensor([[    0, 43813,   247,    11,  2077,  3017,  1817,     6,    82,    32,\n",
      "          8180,    15,     5, 36443,     9,     5, 16119,   877,  6793,  6247,\n",
      "         43814,     4,   287,   444,    25,   382,   484,  1200,    33,    57,\n",
      "           431,    15,  8242,   791,   218,    75,    28,    98,   575,  3743,\n",
      "          5004,  1797,     8,   592,  7018,  7710,    16,    10,   531,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Negative 0.86476046\n",
      "Neutral 0.1307641\n",
      "Positive 0.004475479\n",
      "200k excess death sa 💉💉💉💉, explain nyo pls lang.\n",
      "{'input_ids': tensor([[    0,  2619,   330,  7400,   744,  2241,  8103, 10659, 23171,  6569,\n",
      "         10659, 23171,  6569, 10659, 23171,  6569, 10659, 23171,     6,  3922,\n",
      "           295,  9839,  2968,    29, 22682,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "Negative 0.6907134\n",
      "Neutral 0.29440364\n",
      "Positive 0.014882902\n",
      "Take us back to work from home\n",
      "{'input_ids': tensor([[    0, 21031,   201,   124,     7,   173,    31,   184,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.11331079\n",
      "Neutral 0.8166681\n",
      "Positive 0.07002113\n",
      "can we use this po \n",
      "{'input_ids': tensor([[   0, 7424,   52,  304,   42, 4202, 1437,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.030302525\n",
      "Neutral 0.7931191\n",
      "Positive 0.1765784\n",
      "Permission to use this for my video presentation, thank you!\n",
      "{'input_ids': tensor([[    0, 20823, 12478,     7,   304,    42,    13,   127,   569,  5209,\n",
      "             6,  3392,    47,   328,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.0009896423\n",
      "Neutral 0.03443175\n",
      "Positive 0.96457857\n",
      "No comments odd\n",
      "{'input_ids': tensor([[   0, 3084, 1450, 8372,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
      "Negative 0.31256422\n",
      "Neutral 0.6460113\n",
      "Positive 0.041424446\n",
      "SANA MAY PART 2 NA LOCKDOWN THIS 2024\n",
      "{'input_ids': tensor([[    0,   104, 14629, 19105, 19713,   132,  8438,   226, 13181, 39200,\n",
      "         10652, 15294,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.034807835\n",
      "Neutral 0.8932153\n",
      "Positive 0.07197685\n",
      "Daddy Digs is frustrating\n",
      "{'input_ids': tensor([[    0, 36009, 16621,    29,    16, 10314,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.95266706\n",
      "Neutral 0.042314567\n",
      "Positive 0.005018393\n",
      "Let us remember that the reason why we had such high numbers or had COVID AT ALL was because this guy was afraid of hurting China's feelings by imposing a travel ban on them.\n",
      "{'input_ids': tensor([[    0,  7939,   201,  2145,    14,     5,  1219,   596,    52,    56,\n",
      "           215,   239,  1530,    50,    56,  6247, 43814,  3263, 12389,    21,\n",
      "           142,    42,  2173,    21,  6023,     9, 12780,   436,    18,  6453,\n",
      "            30, 13223,    10,  1504,  2020,    15,   106,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.65882885\n",
      "Neutral 0.3244862\n",
      "Positive 0.016684989\n",
      "Sweet un lock down, Daddy's voice is so sweet that people are looking forward to the lockdown. It means, everyone, Dad Digong's decision, is really salute to FPRRD because he is pressed during pandemic.\n",
      "{'input_ids': tensor([[    0, 35942,   542,  7014,   159,     6, 25455,    18,  2236,    16,\n",
      "            98,  4045,    14,    82,    32,   546,   556,     7,     5, 23076,\n",
      "             4,    85,   839,     6,   961,     6, 13404, 16621,  1657,    18,\n",
      "           568,     6,    16,   269, 23824,     7,   274,  4454, 34158,   142,\n",
      "            37,    16, 11224,   148, 23387, 14414,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.014324683\n",
      "Neutral 0.09721928\n",
      "Positive 0.888456\n",
      "Cure.\n",
      "{'input_ids': tensor([[   0,  347, 2407,    4,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
      "Negative 0.31450516\n",
      "Neutral 0.51580006\n",
      "Positive 0.16969474\n",
      "Just ask me so there is a booster avail on covid ngaun po.\n",
      "{'input_ids': tensor([[    0,  6785,  1394,   162,    98,    89,    16,    10, 27028, 22345,\n",
      "            15, 47268,   808,  6094,  7381,  4202,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.045634624\n",
      "Neutral 0.9055104\n",
      "Positive 0.048854902\n",
      "Slightly Rise! But hopefully the face mask is imandatory before it gets worse .. globally because it rises. But it would have taken action immediately rather than to be caught and pushed to the public to wear a face mask again\n",
      "{'input_ids': tensor([[    0,   104, 41720, 20644,   328,   125,  5952,     5,   652, 11445,\n",
      "            16,  4356,   463,  5257,   137,    24,  1516,  3007, 29942,  7197,\n",
      "           142,    24, 10185,     4,   125,    24,    74,    33,   551,   814,\n",
      "          1320,  1195,    87,     7,    28,  2037,     8,  3148,     7,     5,\n",
      "           285,     7,  3568,    10,   652, 11445,   456,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.5221928\n",
      "Neutral 0.40845758\n",
      "Positive 0.06934962\n",
      "As a Filipino student, online class is frustrating because our internet here sucks.\n",
      "{'input_ids': tensor([[    0,  1620,    10, 19890,  1294,     6,   804,  1380,    16, 10314,\n",
      "           142,    84,  2888,   259, 29384,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.9777641\n",
      "Neutral 0.01999423\n",
      "Positive 0.0022416082\n",
      "I hope the family was paid for being interviewed. They need support more than ever.\n",
      "{'input_ids': tensor([[   0,  100, 1034,    5,  284,   21, 1199,   13,  145, 7477,    4,  252,\n",
      "          240,  323,   55,   87,  655,    4,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.11213035\n",
      "Neutral 0.5301997\n",
      "Positive 0.3576699\n",
      "nothing is more heartbreaking than children forced to grow up before there time...\n",
      "{'input_ids': tensor([[    0, 23702,    16,    55, 17052,    87,   408,  1654,     7,  1733,\n",
      "            62,   137,    89,    86,   734,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.96249413\n",
      "Neutral 0.034035742\n",
      "Positive 0.003470091\n",
      "As a teacher in Malaysia I feel for these anak- anak . Be strong and be safe ,only education can change your life and your family , Praying for success from Malaysia .\n",
      "{'input_ids': tensor([[    0,  1620,    10,  3254,    11,  5697,    38,   619,    13,   209,\n",
      "            41,   677,    12,    41,   677,   479,  1456,   670,     8,    28,\n",
      "          1522,  2156,  8338,  1265,    64,   464,   110,   301,     8,   110,\n",
      "           284,  2156,  2869, 11918,    13,  1282,    31,  5697,   479,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.01727385\n",
      "Neutral 0.2490064\n",
      "Positive 0.73371977\n",
      "I was in the Philippines on a mission trip when Covid hit. After I was home in the US with my family, the worry I felt for the kids I'd met there was overwhelming. May God bless the Filipino people💙\n",
      "{'input_ids': tensor([[    0,   100,    21,    11,     5,  5639,    15,    10,  2511,  1805,\n",
      "            77, 19150,   808,   478,     4,   572,    38,    21,   184,    11,\n",
      "             5,   382,    19,   127,   284,     6,     5,  4022,    38,  1299,\n",
      "            13,     5,  1159,    38,  1017,  1145,    89,    21,  8642,     4,\n",
      "           392,  1840, 22212,     5, 19890,    82,  6569, 10659,    27,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Negative 0.13846323\n",
      "Neutral 0.41005006\n",
      "Positive 0.45148668\n",
      "I am so glad that they also tackled the mental health of the youth right now. It is also one of the worst problems that the youth of the Philippines can experience. I know a lot of people in my classmates who suffer from depression, that is why, we must take actions to fight and solve this problem.\n",
      "{'input_ids': tensor([[    0,   100,   524,    98,  7785,    14,    51,    67, 19737,     5,\n",
      "          2536,   474,     9,     5,  2719,   235,   122,     4,    85,    16,\n",
      "            67,    65,     9,     5,  2373,  1272,    14,     5,  2719,     9,\n",
      "             5,  5639,    64,   676,     4,    38,   216,    10,   319,     9,\n",
      "            82,    11,   127, 18295,    54,  6297,    31,  6943,     6,    14,\n",
      "            16,   596,     6,    52,   531,   185,  2163,     7,  1032,     8,\n",
      "          6136,    42,   936,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.23760104\n",
      "Neutral 0.4249271\n",
      "Positive 0.33747196\n",
      "The problem in the Philippines is that there are many less privileged, challenged people. The government officials and local government unit can be corrupt and don’t do their assigned jobs properly(not saying all of them but some or maybe most of them). The less privileged people and some teens just makes more babies and say having an accidental baby is a “blessing”. It is only a blessing if it was planned and both couple/parents are ready to have their own family. That is why many people are suffering from poverty because many people do not plan making their family. Then they blame everything to the government and if there are people doing better than them they want to pull others down. #crabmentality 🦀 I feel sorry for the challenged people but some of the people just make their own problems. Didn’t comment here to debate. Just giving my opinion ✌🏻\n",
      "{'input_ids': tensor([[    0,   133,   936,    11,     5,  5639,    16,    14,    89,    32,\n",
      "           171,   540, 18560,     6,  6835,    82,     4,    20,   168,   503,\n",
      "             8,   400,   168,  1933,    64,    28, 10334,     8,   218,    17,\n",
      "            27,    90,   109,    49,  5530,  1315,  5083,  1640,  3654,   584,\n",
      "            70,     9,   106,    53,   103,    50,  2085,   144,     9,   106,\n",
      "           322,    20,   540, 18560,    82,     8,   103,  7475,    95,   817,\n",
      "            55,  7272,     8,   224,   519,    41, 18305,  1928,    16,    10,\n",
      "            44,    48,   428,  1672,   154,    17,    46,     4,    85,    16,\n",
      "           129,    10, 14164,   114,    24,    21,  1904,     8,   258,   891,\n",
      "            73, 34846,    32,  1227,     7,    33,    49,   308,   284,     4,\n",
      "           280,    16,   596,   171,    82,    32,  3606,    31,  5263,   142,\n",
      "           171,    82,   109,    45,   563,   442,    49,   284,     4,  1892,\n",
      "            51,  4887,   960,     7,     5,   168,     8,   114,    89,    32,\n",
      "            82,   608,   357,    87,   106,    51,   236,     7,  2999,   643,\n",
      "           159,     4,   849,  8344,   873,  1757,  6948,  8103, 18164,  7471,\n",
      "            38,   619,  6661,    13,     5,  6835,    82,    53,   103,     9,\n",
      "             5,    82,    95,   146,    49,   308,  1272,     4, 31940,    17,\n",
      "            27,    90,  1129,   259,     7,  2625,     4,  1801,  1311,   127,\n",
      "          2979, 36174, 14285,  6569,  9357,  2023,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.8140413\n",
      "Neutral 0.16427885\n",
      "Positive 0.021679783\n",
      "Ah bless jonathan he is so determined while my niece in the philippines her parents send her to a private school provided everything and now she did not finish school what a spoilt brat. I wish jonathan finish a degree someday he deserve to be help\n",
      "{'input_ids': tensor([[    0, 17986, 22212,  1236,   261, 15322,    37,    16,    98,  3030,\n",
      "           150,   127, 21348,    11,     5,  7843, 33465,  3141,    69,  1041,\n",
      "          2142,    69,     7,    10,   940,   334,  1286,   960,     8,   122,\n",
      "            79,   222,    45,  2073,   334,    99,    10, 25222, 10325,  5378,\n",
      "           415,     4,    38,  2813,  1236,   261, 15322,  2073,    10,  3093,\n",
      "         23090,    37,  6565,     7,    28,   244,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.17547931\n",
      "Neutral 0.3221349\n",
      "Positive 0.50238574\n",
      "I want to sponsor Johnathan and help him finish school.\n",
      "{'input_ids': tensor([[    0,   100,   236,     7,  9242,   610, 15322,     8,   244,   123,\n",
      "          2073,   334,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.0048315045\n",
      "Neutral 0.19115195\n",
      "Positive 0.8040166\n",
      "Just because our neighbour Filipina increase their covid test testing does not mean they are the worst in South East Asia. For me I admire that they try to save their people the best they can and honest with the figure too. Better than countries who have huge problem with covid, denying that they have the problem. Sending our thought and prayer to Filipina people..from Malaysia. Keep fighting spirit alive. May god protect you all.\n",
      "{'input_ids': tensor([[    0,  6785,   142,    84, 14915, 21376,  1243,   712,    49, 47268,\n",
      "           808,  1296,  3044,   473,    45,  1266,    51,    32,     5,  2373,\n",
      "            11,   391,   953,  1817,     4,   286,   162,    38, 15865,    14,\n",
      "            51,   860,     7,  1871,    49,    82,     5,   275,    51,    64,\n",
      "             8,  5322,    19,     5,  1955,   350,     4, 11238,    87,   749,\n",
      "            54,    33,  1307,   936,    19, 47268,   808,     6, 12000,    14,\n",
      "            51,    33,     5,   936,     4, 40940,    84,   802,     8,  9621,\n",
      "             7, 21376,  1243,    82,  7586,  7761,  5697,     4,  7238,  2190,\n",
      "          4780,  4299,     4,   392,  9069,  1744,    47,    70,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.09198586\n",
      "Neutral 0.4020136\n",
      "Positive 0.5060005\n",
      "Stay strong, my Filipino mates, this too shall pass\n",
      "{'input_ids': tensor([[    0, 34112,   670,     6,   127, 19890, 18779,     6,    42,   350,\n",
      "          5658,  1323,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Negative 0.004319039\n",
      "Neutral 0.17137127\n",
      "Positive 0.82430977\n"
     ]
    }
   ],
   "source": [
    "roberta_sentiment_scores(covid_filtered_out_df[\"comment\"][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST TEXTBLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def textblob_sentiment_scores(list_comments):\n",
    "    list_sentiment={}\n",
    "    for comment in list_comments:\n",
    "        testimonial = TextBlob(comment)\n",
    "        if (testimonial.sentiment.polarity > 0):\n",
    "            print(\"positive\", testimonial.sentiment.polarity)\n",
    "        elif (testimonial.sentiment.polarity < 0):\n",
    "            print(\"negative\", testimonial.sentiment.polarity)\n",
    "        else:\n",
    "            print(\"neutral\", testimonial.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive 0.7\n",
      "neutral 0.0\n",
      "negative -0.16666666666666666\n",
      "positive 0.11250000000000002\n",
      "neutral 0.0\n",
      "positive 0.44999999999999996\n",
      "positive 0.7\n",
      "negative -0.55\n",
      "positive 0.475\n",
      "neutral 0.0\n",
      "negative -0.6\n",
      "neutral 0.0\n",
      "negative -0.19999999999999998\n",
      "negative -0.45285714285714285\n",
      "negative -0.5\n",
      "neutral 0.0\n",
      "negative -0.3729166666666667\n",
      "neutral 0.0\n",
      "positive 0.2\n",
      "positive 0.48828125\n",
      "neutral 0.0\n",
      "positive 0.425\n",
      "positive 0.2\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "positive 0.0020833333333333346\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "negative -0.16666666666666666\n",
      "neutral 0.0\n",
      "negative -0.4\n",
      "negative -0.14666666666666664\n",
      "positive 0.18611111111111112\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "negative -0.10166666666666668\n",
      "negative -0.35\n",
      "positive 0.5\n",
      "positive 0.09999999999999998\n",
      "positive 0.30833333333333335\n",
      "positive 0.5\n",
      "negative -0.07857142857142857\n",
      "positive 0.18194444444444446\n",
      "neutral 0.0\n",
      "neutral 0.0\n",
      "positive 0.2508928571428572\n",
      "positive 0.4333333333333333\n"
     ]
    }
   ],
   "source": [
    "textblob_sentiment_scores(covid_filtered_out_df[\"comment\"][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST STANZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "def stanza_sentiment_scores(list_comments):\n",
    "    nlp = stanza.Pipeline('en', processors='tokenize,sentiment', tokenize_no_ssplit=True)\n",
    "\n",
    "    for comment in list_comments:\n",
    "        doc = nlp(comment.replace(\"\\n\", \" \"))\n",
    "        print(comment)\n",
    "    #doc.sentences[0].print_dependencies()\n",
    "        for i, sentence in enumerate(doc.sentences):\n",
    "            print(\"%d -> %d\" % (i, sentence.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 16:15:00 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79737eeffa284005836ae73b363e4370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 16:15:00 WARNING: Language en package default expects mwt, which has been added\n",
      "2024-03-07 16:15:01 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2024-03-07 16:15:01 INFO: Using device: cpu\n",
      "2024-03-07 16:15:01 INFO: Loading: tokenize\n",
      "2024-03-07 16:15:01 INFO: Loading: mwt\n",
      "2024-03-07 16:15:01 INFO: Loading: sentiment\n",
      "2024-03-07 16:15:02 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved the calmness of Manilla.\n",
      "0 -> 2\n",
      "After this pandemic I think every country should have a lockdown every month to give mother nature a time to heal, with all the pollution that the earth is experiencing.\n",
      "0 -> 0\n",
      "manila looks beautifull with less people\n",
      "0 -> 2\n",
      "The lockdown makes the city look like a place I want to explore.\n",
      "\n",
      "Before the lockdown, it looked like a crowded mess filled with traffic and pollution.\n",
      "0 -> 0\n",
      "India also same\n",
      "0 -> 1\n",
      "The president promised that he'll do his best to ease the traffic in the metro like 5mins of travel along EDSA. Fortunately it happened but unfortunately it wasn't in the ideal way. Nature's sense of humor tho.\n",
      "0 -> 0\n",
      "I went up the viewing spot at antipolo, its a very beautiful, almost smog free view of the metro skyline\n",
      "0 -> 2\n",
      "The sad part is people around the world did not intend to heal earth but afraid of death.\n",
      "0 -> 1\n",
      "i hope it stays like this forever its beautiful with no messy people\n",
      "0 -> 2\n",
      "2020 is the year when nature fight back and reduce human emission dramatically.\n",
      "0 -> 1\n",
      "Cough and cold season now because the weather is cold .... now covid again amg impression\n",
      "0 -> 0\n",
      "Ala n covid tngina\n",
      "0 -> 1\n",
      "Has it been in Bahrain so the diseases were the same time when it was so old that it was so painful when it came to winter\n",
      "0 -> 0\n",
      "Season of cough and cold today here in Pinas after our cold day in the morning when it comes to the morning until the night is hot there is no aircon at home after entering work aircon their body temperature has changed before it does not get sick of cough and cold. .atibp\n",
      "0 -> 0\n",
      "It is difficult to cure 2_3wks.This is here in Nueva Ecija.\n",
      "0 -> 0\n",
      "Take a ginger drink ..\n",
      "0 -> 1\n",
      "It's not a joke to say that it's just a cold cold because my brother is the symptom of two hospitals we carry the same covid the outdoors too hard to breathe\n",
      "0 -> 0\n",
      "😊😊\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "😊\n",
      "0 -> 1\n",
      "There are many feverish fever here in the Philippines not just in China.\n",
      "0 -> 1\n",
      "PRAISE GOD THERE ARE ONLY 18 CASES OUT OF 114 MILLION PEOPLE !!\n",
      " THANK YOU LORD WE ARE ALL HEALTHY !\n",
      " COVID IS OVER !!\n",
      "0 -> 2\n",
      "DOH you have the power to report the height of the cases .. But backlogs of covid allowances of frontliners teach you a teach !!!!!\n",
      "0 -> 1\n",
      "wow ! GOOD NEWS ! glad we are all safe and there is near zero cases of covid ! 🤗\n",
      "0 -> 2\n",
      "Thanks a Lot/ DOH- Keep all Our Health Well!!!❤😊\n",
      "0 -> 2\n",
      "Is the covid BS 1 variant still coming\n",
      "0 -> 1\n",
      "here we go again\n",
      "0 -> 1\n",
      "Hmmm. this could be the triggering pin for the ....\n",
      "0 -> 1\n",
      "Others country in south east Asia, people are dying on the complication of the mutate virus COVID. As far as US several cases have been reported on ICU don't be so carefree extreme measures and social distancing is a must\n",
      "0 -> 0\n",
      "200k excess death sa 💉💉💉💉, explain nyo pls lang.\n",
      "0 -> 1\n",
      "Take us back to work from home\n",
      "0 -> 1\n",
      "can we use this po?\n",
      "0 -> 1\n",
      "Permission to use this for my video presentation, thank you!\n",
      "0 -> 2\n",
      "No comments odd\n",
      "0 -> 1\n",
      "SANA MAY PART 2 NA LOCKDOWN THIS 2024\n",
      "0 -> 1\n",
      "Daddy Digs is frustrating\n",
      "0 -> 0\n",
      "Let us remember that the reason why we had such high numbers or had COVID AT ALL was because this guy was afraid of hurting China's feelings by imposing a travel ban on them.\n",
      "0 -> 0\n",
      "Sweet un lock down, Daddy's voice is so sweet that people are looking forward to the lockdown. It means, everyone, Dad Digong's decision, is really salute to FPRRD because he is pressed during pandemic.\n",
      "0 -> 2\n",
      "Cure.\n",
      "0 -> 1\n",
      "Just ask me so there is a booster avail on covid ngaun po.\n",
      "0 -> 1\n",
      "Slightly Rise! But hopefully the face mask is imandatory before it gets worse .. globally because it rises. But it would have taken action immediately rather than to be caught and pushed to the public to wear a face mask again\n",
      "0 -> 0\n",
      "As a Filipino student, online class is frustrating because our internet here sucks.\n",
      "0 -> 0\n",
      "I hope the family was paid for being interviewed. They need support more than ever.\n",
      "0 -> 0\n",
      "nothing is more heartbreaking than children forced to grow up before there time...\n",
      "0 -> 2\n",
      "As a teacher in Malaysia I feel for these anak- anak . Be strong and be safe ,only education can change your life and your family , Praying for success from Malaysia .\n",
      "0 -> 1\n",
      "I was in the Philippines on a mission trip when Covid hit. After I was home in the US with my family, the worry I felt for the kids I'd met there was overwhelming. May God bless the Filipino people💙\n",
      "0 -> 1\n",
      "I am so glad that they also tackled the mental health of the youth right now. It is also one of the worst problems that the youth of the Philippines can experience. I know a lot of people in my classmates who suffer from depression, that is why, we must take actions to fight and solve this problem.\n",
      "0 -> 0\n",
      "The problem in the Philippines is that there are many less privileged, challenged people. The government officials and local government unit can be corrupt and don’t do their assigned jobs properly(not saying all of them but some or maybe most of them). The less privileged people and some teens just makes more babies and say having an accidental baby is a “blessing”. It is only a blessing if it was planned and both couple/parents are ready to have their own family. That is why many people are suffering from poverty because many people do not plan making their family. Then they blame everything to the government and if there are people doing better than them they want to pull others down. #crabmentality 🦀 I feel sorry for the challenged people but some of the people just make their own problems.\n",
      "\n",
      "Didn’t comment here to debate. Just giving my opinion ✌🏻\n",
      "0 -> 0\n",
      "Ah bless jonathan he is so determined while my niece in the philippines her parents send her to a private school provided everything and now she did not finish school what a spoilt brat. I wish jonathan finish a degree someday he deserve to be help\n",
      "0 -> 0\n",
      "I want to sponsor Johnathan and help him finish school.\n",
      "0 -> 1\n",
      "Just because our neighbour Filipina increase their covid test testing does not mean they are the worst in South East Asia. For me I admire that they try to save their people the best they can and honest with the figure too. Better than countries who have huge problem with covid, denying that they have the problem. Sending our thought and prayer to Filipina people..from Malaysia. Keep fighting spirit alive. May god protect you all.\n",
      "0 -> 0\n",
      "Stay strong, my Filipino mates, this too shall pass\n",
      "0 -> 1\n"
     ]
    }
   ],
   "source": [
    "stanza_sentiment_scores(covid_filtered_out_df[\"comment\"][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def vader_sentiment_scores (list_comments):\n",
    "    for sentence in list_comments:\n",
    "        sid_obj = SentimentIntensityAnalyzer()\n",
    "        sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "        print(sentence)\n",
    "        print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
    "        print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
    "        print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
    "        print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
    " \n",
    "        print(\"Sentence Overall Rated As\", end = \" \")\n",
    " \n",
    "        # decide sentiment as positive, negative and neutral\n",
    "        if sentiment_dict['compound'] >= 0.05 :\n",
    "            print(\"Positive\")\n",
    " \n",
    "        elif sentiment_dict['compound'] <= - 0.05 :\n",
    "            print(\"Negative\")\n",
    " \n",
    "        else :\n",
    "            print(\"Neutral\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved the calmness of Manilla.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.312, 'pos': 0.688, 'compound': 0.765}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  31.2 % Neutral\n",
      "sentence was rated as  68.8 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "After this pandemic I think every country should have a lockdown every month to give mother nature a time to heal, with all the pollution that the earth is experiencing.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "manila looks beautifull with less people\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "The lockdown makes the city look like a place I want to explore.\n",
      "\n",
      "Before the lockdown, it looked like a crowded mess filled with traffic and pollution.\n",
      "Overall sentiment dictionary is :  {'neg': 0.079, 'neu': 0.723, 'pos': 0.198, 'compound': 0.4215}\n",
      "sentence was rated as  7.9 % Negative\n",
      "sentence was rated as  72.3 % Neutral\n",
      "sentence was rated as  19.8 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "India also same\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "The president promised that he'll do his best to ease the traffic in the metro like 5mins of travel along EDSA. Fortunately it happened but unfortunately it wasn't in the ideal way. Nature's sense of humor tho.\n",
      "Overall sentiment dictionary is :  {'neg': 0.143, 'neu': 0.635, 'pos': 0.222, 'compound': 0.1867}\n",
      "sentence was rated as  14.299999999999999 % Negative\n",
      "sentence was rated as  63.5 % Neutral\n",
      "sentence was rated as  22.2 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "I went up the viewing spot at antipolo, its a very beautiful, almost smog free view of the metro skyline\n",
      "Overall sentiment dictionary is :  {'neg': 0.082, 'neu': 0.644, 'pos': 0.273, 'compound': 0.7222}\n",
      "sentence was rated as  8.200000000000001 % Negative\n",
      "sentence was rated as  64.4 % Neutral\n",
      "sentence was rated as  27.3 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "The sad part is people around the world did not intend to heal earth but afraid of death.\n",
      "Overall sentiment dictionary is :  {'neg': 0.316, 'neu': 0.684, 'pos': 0.0, 'compound': -0.8126}\n",
      "sentence was rated as  31.6 % Negative\n",
      "sentence was rated as  68.4 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "i hope it stays like this forever its beautiful with no messy people\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.441, 'pos': 0.559, 'compound': 0.8862}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  44.1 % Neutral\n",
      "sentence was rated as  55.900000000000006 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "2020 is the year when nature fight back and reduce human emission dramatically.\n",
      "Overall sentiment dictionary is :  {'neg': 0.178, 'neu': 0.822, 'pos': 0.0, 'compound': -0.3818}\n",
      "sentence was rated as  17.8 % Negative\n",
      "sentence was rated as  82.19999999999999 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Cough and cold season now because the weather is cold .... now covid again amg impression\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.888, 'pos': 0.112, 'compound': 0.2263}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  88.8 % Neutral\n",
      "sentence was rated as  11.200000000000001 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Ala n covid tngina\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Has it been in Bahrain so the diseases were the same time when it was so old that it was so painful when it came to winter\n",
      "Overall sentiment dictionary is :  {'neg': 0.126, 'neu': 0.874, 'pos': 0.0, 'compound': -0.5777}\n",
      "sentence was rated as  12.6 % Negative\n",
      "sentence was rated as  87.4 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Season of cough and cold today here in Pinas after our cold day in the morning when it comes to the morning until the night is hot there is no aircon at home after entering work aircon their body temperature has changed before it does not get sick of cough and cold. .atibp\n",
      "Overall sentiment dictionary is :  {'neg': 0.039, 'neu': 0.912, 'pos': 0.048, 'compound': 0.1285}\n",
      "sentence was rated as  3.9 % Negative\n",
      "sentence was rated as  91.2 % Neutral\n",
      "sentence was rated as  4.8 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "It is difficult to cure 2_3wks.This is here in Nueva Ecija.\n",
      "Overall sentiment dictionary is :  {'neg': 0.2, 'neu': 0.8, 'pos': 0.0, 'compound': -0.3612}\n",
      "sentence was rated as  20.0 % Negative\n",
      "sentence was rated as  80.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Take a ginger drink ..\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "It's not a joke to say that it's just a cold cold because my brother is the symptom of two hospitals we carry the same covid the outdoors too hard to breathe\n",
      "Overall sentiment dictionary is :  {'neg': 0.099, 'neu': 0.901, 'pos': 0.0, 'compound': -0.3156}\n",
      "sentence was rated as  9.9 % Negative\n",
      "sentence was rated as  90.10000000000001 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "😊😊\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "😊\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.333, 'pos': 0.667, 'compound': 0.9517}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  33.300000000000004 % Neutral\n",
      "sentence was rated as  66.7 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "There are many feverish fever here in the Philippines not just in China.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "PRAISE GOD THERE ARE ONLY 18 CASES OUT OF 114 MILLION PEOPLE !!\n",
      " THANK YOU LORD WE ARE ALL HEALTHY !\n",
      " COVID IS OVER !!\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.583, 'pos': 0.417, 'compound': 0.9432}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  58.3 % Neutral\n",
      "sentence was rated as  41.699999999999996 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "DOH you have the power to report the height of the cases .. But backlogs of covid allowances of frontliners teach you a teach !!!!!\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "wow ! GOOD NEWS ! glad we are all safe and there is near zero cases of covid ! 🤗\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.485, 'pos': 0.515, 'compound': 0.9517}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  48.5 % Neutral\n",
      "sentence was rated as  51.5 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Thanks a Lot/ DOH- Keep all Our Health Well!!!❤😊\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'compound': 0.944}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  40.6 % Neutral\n",
      "sentence was rated as  59.4 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Is the covid BS 1 variant still coming\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "here we go again\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Hmmm. this could be the triggering pin for the ....\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Others country in south east Asia, people are dying on the complication of the mutate virus COVID. As far as US several cases have been reported on ICU don't be so carefree extreme measures and social distancing is a must\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.918, 'pos': 0.082, 'compound': 0.541}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  91.8 % Neutral\n",
      "sentence was rated as  8.200000000000001 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "200k excess death sa 💉💉💉💉, explain nyo pls lang.\n",
      "Overall sentiment dictionary is :  {'neg': 0.257, 'neu': 0.658, 'pos': 0.086, 'compound': -0.5574}\n",
      "sentence was rated as  25.7 % Negative\n",
      "sentence was rated as  65.8 % Neutral\n",
      "sentence was rated as  8.6 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Take us back to work from home\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "can we use this po?\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Permission to use this for my video presentation, thank you!\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'compound': 0.4199}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  76.3 % Neutral\n",
      "sentence was rated as  23.7 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "No comments odd\n",
      "Overall sentiment dictionary is :  {'neg': 0.426, 'neu': 0.194, 'pos': 0.38, 'compound': -0.0613}\n",
      "sentence was rated as  42.6 % Negative\n",
      "sentence was rated as  19.400000000000002 % Neutral\n",
      "sentence was rated as  38.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "SANA MAY PART 2 NA LOCKDOWN THIS 2024\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Daddy Digs is frustrating\n",
      "Overall sentiment dictionary is :  {'neg': 0.492, 'neu': 0.508, 'pos': 0.0, 'compound': -0.4404}\n",
      "sentence was rated as  49.2 % Negative\n",
      "sentence was rated as  50.8 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Let us remember that the reason why we had such high numbers or had COVID AT ALL was because this guy was afraid of hurting China's feelings by imposing a travel ban on them.\n",
      "Overall sentiment dictionary is :  {'neg': 0.199, 'neu': 0.801, 'pos': 0.0, 'compound': -0.7717}\n",
      "sentence was rated as  19.900000000000002 % Negative\n",
      "sentence was rated as  80.10000000000001 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "Sweet un lock down, Daddy's voice is so sweet that people are looking forward to the lockdown. It means, everyone, Dad Digong's decision, is really salute to FPRRD because he is pressed during pandemic.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.823, 'pos': 0.177, 'compound': 0.7824}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  82.3 % Neutral\n",
      "sentence was rated as  17.7 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Cure.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Just ask me so there is a booster avail on covid ngaun po.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  100.0 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Neutral\n",
      "Slightly Rise! But hopefully the face mask is imandatory before it gets worse .. globally because it rises. But it would have taken action immediately rather than to be caught and pushed to the public to wear a face mask again\n",
      "Overall sentiment dictionary is :  {'neg': 0.095, 'neu': 0.837, 'pos': 0.068, 'compound': -0.3155}\n",
      "sentence was rated as  9.5 % Negative\n",
      "sentence was rated as  83.7 % Neutral\n",
      "sentence was rated as  6.800000000000001 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "As a Filipino student, online class is frustrating because our internet here sucks.\n",
      "Overall sentiment dictionary is :  {'neg': 0.329, 'neu': 0.671, 'pos': 0.0, 'compound': -0.6597}\n",
      "sentence was rated as  32.9 % Negative\n",
      "sentence was rated as  67.10000000000001 % Neutral\n",
      "sentence was rated as  0.0 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "I hope the family was paid for being interviewed. They need support more than ever.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.699, 'pos': 0.301, 'compound': 0.6808}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  69.89999999999999 % Neutral\n",
      "sentence was rated as  30.099999999999998 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "nothing is more heartbreaking than children forced to grow up before there time...\n",
      "Overall sentiment dictionary is :  {'neg': 0.18, 'neu': 0.659, 'pos': 0.162, 'compound': -0.078}\n",
      "sentence was rated as  18.0 % Negative\n",
      "sentence was rated as  65.9 % Neutral\n",
      "sentence was rated as  16.2 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "As a teacher in Malaysia I feel for these anak- anak . Be strong and be safe ,only education can change your life and your family , Praying for success from Malaysia .\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.7, 'pos': 0.3, 'compound': 0.9081}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  70.0 % Neutral\n",
      "sentence was rated as  30.0 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "I was in the Philippines on a mission trip when Covid hit. After I was home in the US with my family, the worry I felt for the kids I'd met there was overwhelming. May God bless the Filipino people💙\n",
      "Overall sentiment dictionary is :  {'neg': 0.058, 'neu': 0.76, 'pos': 0.182, 'compound': 0.7351}\n",
      "sentence was rated as  5.800000000000001 % Negative\n",
      "sentence was rated as  76.0 % Neutral\n",
      "sentence was rated as  18.2 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "I am so glad that they also tackled the mental health of the youth right now. It is also one of the worst problems that the youth of the Philippines can experience. I know a lot of people in my classmates who suffer from depression, that is why, we must take actions to fight and solve this problem.\n",
      "Overall sentiment dictionary is :  {'neg': 0.262, 'neu': 0.663, 'pos': 0.075, 'compound': -0.9332}\n",
      "sentence was rated as  26.200000000000003 % Negative\n",
      "sentence was rated as  66.3 % Neutral\n",
      "sentence was rated as  7.5 % Positive\n",
      "Sentence Overall Rated As Negative\n",
      "The problem in the Philippines is that there are many less privileged, challenged people. The government officials and local government unit can be corrupt and don’t do their assigned jobs properly(not saying all of them but some or maybe most of them). The less privileged people and some teens just makes more babies and say having an accidental baby is a “blessing”. It is only a blessing if it was planned and both couple/parents are ready to have their own family. That is why many people are suffering from poverty because many people do not plan making their family. Then they blame everything to the government and if there are people doing better than them they want to pull others down. #crabmentality 🦀 I feel sorry for the challenged people but some of the people just make their own problems.\n",
      "\n",
      "Didn’t comment here to debate. Just giving my opinion ✌🏻\n",
      "Overall sentiment dictionary is :  {'neg': 0.122, 'neu': 0.74, 'pos': 0.138, 'compound': 0.7006}\n",
      "sentence was rated as  12.2 % Negative\n",
      "sentence was rated as  74.0 % Neutral\n",
      "sentence was rated as  13.8 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Ah bless jonathan he is so determined while my niece in the philippines her parents send her to a private school provided everything and now she did not finish school what a spoilt brat. I wish jonathan finish a degree someday he deserve to be help\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.788, 'pos': 0.212, 'compound': 0.8838}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  78.8 % Neutral\n",
      "sentence was rated as  21.2 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "I want to sponsor Johnathan and help him finish school.\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.4588}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  66.7 % Neutral\n",
      "sentence was rated as  33.300000000000004 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Just because our neighbour Filipina increase their covid test testing does not mean they are the worst in South East Asia. For me I admire that they try to save their people the best they can and honest with the figure too. Better than countries who have huge problem with covid, denying that they have the problem. Sending our thought and prayer to Filipina people..from Malaysia. Keep fighting spirit alive. May god protect you all.\n",
      "Overall sentiment dictionary is :  {'neg': 0.139, 'neu': 0.569, 'pos': 0.292, 'compound': 0.9313}\n",
      "sentence was rated as  13.900000000000002 % Negative\n",
      "sentence was rated as  56.89999999999999 % Neutral\n",
      "sentence was rated as  29.2 % Positive\n",
      "Sentence Overall Rated As Positive\n",
      "Stay strong, my Filipino mates, this too shall pass\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.708, 'pos': 0.292, 'compound': 0.5106}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  70.8 % Neutral\n",
      "sentence was rated as  29.2 % Positive\n",
      "Sentence Overall Rated As Positive\n"
     ]
    }
   ],
   "source": [
    "vader_sentiment_scores (covid_filtered_out_df[\"comment\"][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sentiment sentiment for each video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEXTBLOB APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob_sentiment_scores(list_comments):\n",
    "    list_sentiment={}\n",
    "    for comment in list_comments:\n",
    "        testimonial = TextBlob(comment)\n",
    "        if (testimonial.sentiment.polarity > 0):\n",
    "            print(\"positive\", testimonial.sentiment.polarity)\n",
    "        elif (testimonial.sentiment.polarity < 0):\n",
    "            print(\"negative\", testimonial.sentiment.polarity)\n",
    "        else:\n",
    "            print(\"neutral\", testimonial.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aLZ85hb4wjE', 'sYI97jv-pZg', '3YFpjgIQqEo', 'dIsaz_XlmTw',\n",
       "       'DWxIvQlpJK8', 'pMUumjHY3tw', 'nTUWK8vufOk', 'cPVE7QGS7As',\n",
       "       'CEIrzjA8euQ', 'lw16DeB6zns', '8dTelszbObM', 'Mxf8uGFcqSE',\n",
       "       'MQ5aYS4YFlQ', 'iOE6rAY8l-k', '_a-rQYfsCck', 'jEINZXA_ujo',\n",
       "       '587N9bJ5J5k', 'E5F3xA_zkFc', '05JLyd58R-w', '2fRQ8OsqOLs',\n",
       "       'E56W-5xVOss', 'c1oU8U05puY', 'SEHcakm-fAc', '1psSvU1km0I',\n",
       "       'PP3Yu-ro1tA', 'NQeI1CRCqeo', 'RhDHGgo4yZg', 'sdsz-t540WI',\n",
       "       '7SKGXkZKjV8', 'oy0wHScCPds', 'o1kPskxFkQ8', 'aoNQUUQno00',\n",
       "       'liEUC1_l8e8', '-b0EuuMvvy8', 'MmyIvf7bEGc', 'Fd3HcncV6Zk',\n",
       "       '-n9Ks3VTub4', 'LzymJ2xZhho', '-qFcO_onBdA', 'fp9uRsmTWqg',\n",
       "       '3ZXR2eARmuQ', '57wz3HuIVLA', 'lbK7UjoLr8o', 'xV1oR-RbOGU',\n",
       "       'kn6DKdInYXk', '2T3yZ6lNRDg', 'HLYSlKY6Ww4', 'sH_YoV-NA6s',\n",
       "       'ZLT6L3PHz78', 'lczwrm68u6I', 'zhBdbLj5y6A', 'ibWFsmcnefk',\n",
       "       'e0fN7HxkIUc', 'Ji47WRv2tQE', 'dj5ov38ihZI', 'j3E3NF9nk44',\n",
       "       'BomdsEJjb0E', 'T7c6GvrF82k', '6DBFwIlT4fg', '2FgFNBIJTIA',\n",
       "       '254GdlKEz5I', 'y4qaoHc2ezk', '2VRGUm_wQ0w', 'HK5rfm4X2G0',\n",
       "       '_DM5L8uu1Do', 'pK6y1h0YgSU', 'a3-AiHSyTIU', 'SLrKdYsNbSo',\n",
       "       '8w61tigk0ag', 'Mwpqgw9gMfo', 'FJEMcVK0MWI', 'gRKL_FUQUpY',\n",
       "       'LLFcBFAuauk', 'EsW0ye2wjUQ', 'R0i7i80ToUM', '6zkba0hNiE8',\n",
       "       'T48EuGS36Zk', 'KzCjAetb3_I', 'N9OQbW0YOLU', 'I4WXmX_6Zds',\n",
       "       'WTD3l2xovQI', 'LtW0cTMWdbY', 'iVM-azf1Akk', 'xWV_GI9hq5U',\n",
       "       '-LFGaCkPzzY', 'rFDK10oplxA', '6p_8T_xmnLQ', 'D9-CHldoZ74',\n",
       "       'xqz1KueuzAM', 'T2JkwAZ8KY8', 'TQ0QJ4Si7A4', '81Fj00CFmJM',\n",
       "       'C-iuGrZR2pQ', 'JT1R95tG9jg', 'O06AlL8nONo', 'HabzHfgdMNs',\n",
       "       'o96VMbz4Zpk', 'XylXJJp4HpE', 'ZaTPlJ8nd9Q', 'R3E3RlBEIl8',\n",
       "       '5jCZ42fV6sw', 'tq7FyWSGaD4', 'jQusLZgOYac', 'iOnxb9jrY40',\n",
       "       'UWMmesK08TU', '4bub6WOlT-I', 'jIsXjk3TgkU', 'W8WAKyR5pGA',\n",
       "       'ZBO3c3ko0eg', 'FIiz8hqXm24', 'I3mkImSqHA0', 'DTUckJz0RGo',\n",
       "       'JWA5mUrrr_A', 'XqzQanN4Xx8', 'QjJwrWxwLJU', 'D7zMgv16cik',\n",
       "       'bJYGvO6V67A', 'sJ0xpruFAwQ', 'ENk_QRA2XsY', 'OB0qJwk5yA8',\n",
       "       '29LXKUT0eMY', 'Bo24jIb7GA8', '19hkLN7KEqc', '_quGokF8G0o',\n",
       "       'M7qPgEDk2JY', '-PqXVcMtygc', 'GUVKWAEO_hY', '_S_9JRwFmcA',\n",
       "       'LWIgEf_TMVU', 'aw59h2FNMIQ', 'lw0rcwYyiwE', 'sEjN7muHOLc',\n",
       "       'Y-xQtgvNuvA', 'W7n2FoRinVk', 'Wjj__vIdew0', '5DvMPgoKZmM'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_filtered_out_df[\"video_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_vid_textblob_polarity (df):\n",
    "    video_polarity={}\n",
    "    for video in df[\"video_id\"].unique():\n",
    "        sum_polarity=0\n",
    "        for comment in df.loc[df[\"video_id\"]==video][\"comment\"]:\n",
    "            sum_polarity+=(TextBlob(comment)).sentiment.polarity\n",
    "        video_polarity[video] = sum_polarity/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "    ''' if (testimonial.sentiment.polarity > 0):\n",
    "            print(\"positive\", testimonial.sentiment.subjectivity)\n",
    "        elif (testimonial.sentiment.polarity < 0):\n",
    "            print(\"negative\", testimonial.sentiment.subjectivity)\n",
    "        else:\n",
    "            print(\"neutral\", testimonial.sentiment.subjectivity)'''\n",
    "    return video_polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aLZ85hb4wjE': 0.1720833333333333,\n",
       " 'sYI97jv-pZg': -0.3,\n",
       " '3YFpjgIQqEo': -0.09305472883597882,\n",
       " 'dIsaz_XlmTw': 0.07838541666666667,\n",
       " 'DWxIvQlpJK8': -0.06590277777777777,\n",
       " 'pMUumjHY3tw': -0.05083333333333334,\n",
       " 'nTUWK8vufOk': 0.12907848324514992,\n",
       " 'cPVE7QGS7As': 0.38312003968253966,\n",
       " 'CEIrzjA8euQ': -0.25,\n",
       " 'lw16DeB6zns': 0.11604662698412699,\n",
       " '8dTelszbObM': 0.20164552024308124,\n",
       " 'Mxf8uGFcqSE': 0.16666666666666666,\n",
       " 'MQ5aYS4YFlQ': 0.26589898989898986,\n",
       " 'iOE6rAY8l-k': 0.04490740740740742,\n",
       " '_a-rQYfsCck': 0.05265151515151515,\n",
       " 'jEINZXA_ujo': 0.39894179894179893,\n",
       " '587N9bJ5J5k': 0.10679012345679012,\n",
       " 'E5F3xA_zkFc': 0.0866078884078884,\n",
       " '05JLyd58R-w': 0.0,\n",
       " '2fRQ8OsqOLs': 0.02433862433862434,\n",
       " 'E56W-5xVOss': 0.10351587301587302,\n",
       " 'c1oU8U05puY': 0.13055555555555556,\n",
       " 'SEHcakm-fAc': 0.07676204004329004,\n",
       " '1psSvU1km0I': 0.15870664315108762,\n",
       " 'PP3Yu-ro1tA': 0.11888888888888889,\n",
       " 'NQeI1CRCqeo': 0.020672348484848484,\n",
       " 'RhDHGgo4yZg': -0.11822916666666668,\n",
       " 'sdsz-t540WI': 0.09243055555555554,\n",
       " '7SKGXkZKjV8': -0.18030864197530866,\n",
       " 'oy0wHScCPds': -0.009515993265993247,\n",
       " 'o1kPskxFkQ8': 0.1210565476190476,\n",
       " 'aoNQUUQno00': 0.058571428571428566,\n",
       " 'liEUC1_l8e8': 0.11903318903318905,\n",
       " '-b0EuuMvvy8': 0.03419312169312169,\n",
       " 'MmyIvf7bEGc': 0.1328703703703704,\n",
       " 'Fd3HcncV6Zk': 0.1980952380952381,\n",
       " '-n9Ks3VTub4': 0.04938271604938271,\n",
       " 'LzymJ2xZhho': 0.03591269841269842,\n",
       " '-qFcO_onBdA': 0.028180803571428565,\n",
       " 'fp9uRsmTWqg': 0.0010416666666666803,\n",
       " '3ZXR2eARmuQ': 0.5905753968253968,\n",
       " '57wz3HuIVLA': 0.1759375,\n",
       " 'lbK7UjoLr8o': 0.33333333333333337,\n",
       " 'xV1oR-RbOGU': 0.12955614344503236,\n",
       " 'kn6DKdInYXk': -0.1336995496086405,\n",
       " '2T3yZ6lNRDg': 0.1330625,\n",
       " 'HLYSlKY6Ww4': 0.2585565476190476,\n",
       " 'sH_YoV-NA6s': 0.38308035714285715,\n",
       " 'ZLT6L3PHz78': 0.02395382395382395,\n",
       " 'lczwrm68u6I': 0.4138888888888889,\n",
       " 'zhBdbLj5y6A': -0.02916161616161616,\n",
       " 'ibWFsmcnefk': 0.24192857142857147,\n",
       " 'e0fN7HxkIUc': -0.07113756613756614,\n",
       " 'Ji47WRv2tQE': -0.016174242424242424,\n",
       " 'dj5ov38ihZI': 0.29276161193847655,\n",
       " 'j3E3NF9nk44': 0.14558441558441557,\n",
       " 'BomdsEJjb0E': 0.12856150793650795,\n",
       " 'T7c6GvrF82k': -0.2796527777777778,\n",
       " '6DBFwIlT4fg': 0.022234848484848496,\n",
       " '2FgFNBIJTIA': 0.12469387755102042,\n",
       " '254GdlKEz5I': 0.0,\n",
       " 'y4qaoHc2ezk': 0.25555555555555554,\n",
       " '2VRGUm_wQ0w': 0.2832993080152171,\n",
       " 'HK5rfm4X2G0': -0.0375,\n",
       " '_DM5L8uu1Do': 0.08037317620650955,\n",
       " 'pK6y1h0YgSU': 0.27027011183261185,\n",
       " 'a3-AiHSyTIU': 0.17899062049062048,\n",
       " 'SLrKdYsNbSo': -0.013243978243978239,\n",
       " '8w61tigk0ag': -0.0013392857142857095,\n",
       " 'Mwpqgw9gMfo': 0.2375,\n",
       " 'FJEMcVK0MWI': 0.34182539682539687,\n",
       " 'gRKL_FUQUpY': 0.2294642857142857,\n",
       " 'LLFcBFAuauk': 0.10376602564102563,\n",
       " 'EsW0ye2wjUQ': 0.0,\n",
       " 'R0i7i80ToUM': 0.3154938271604938,\n",
       " '6zkba0hNiE8': 0.04542181069958848,\n",
       " 'T48EuGS36Zk': 0.14982323232323233,\n",
       " 'KzCjAetb3_I': 0.31357142857142856,\n",
       " 'N9OQbW0YOLU': 0.029761904761904767,\n",
       " 'I4WXmX_6Zds': 0.06537037037037037,\n",
       " 'WTD3l2xovQI': 0.38161616161616163,\n",
       " 'LtW0cTMWdbY': 0.20272727272727273,\n",
       " 'iVM-azf1Akk': -0.052546296296296285,\n",
       " 'xWV_GI9hq5U': 0.243,\n",
       " '-LFGaCkPzzY': -0.19999999999999998,\n",
       " 'rFDK10oplxA': 0.09147025813692479,\n",
       " '6p_8T_xmnLQ': 0.12577380952380954,\n",
       " 'D9-CHldoZ74': 0.11785714285714285,\n",
       " 'xqz1KueuzAM': 0.06447368421052632,\n",
       " 'T2JkwAZ8KY8': 0.03606060606060604,\n",
       " 'TQ0QJ4Si7A4': 0.14166666666666666,\n",
       " '81Fj00CFmJM': 0.016406249999999997,\n",
       " 'C-iuGrZR2pQ': 0.02880681818181819,\n",
       " 'JT1R95tG9jg': 0.04928571428571428,\n",
       " 'O06AlL8nONo': 0.08066468253968255,\n",
       " 'HabzHfgdMNs': 0.215,\n",
       " 'o96VMbz4Zpk': -0.05,\n",
       " 'XylXJJp4HpE': 0.22633101851851853,\n",
       " 'ZaTPlJ8nd9Q': 0.2991784511784512,\n",
       " 'R3E3RlBEIl8': 0.20535714285714285,\n",
       " '5jCZ42fV6sw': 0.35694444444444445,\n",
       " 'tq7FyWSGaD4': 0.11550446428571431,\n",
       " 'jQusLZgOYac': 0.51,\n",
       " 'iOnxb9jrY40': 3.469446951953614e-18,\n",
       " 'UWMmesK08TU': 0.25030864197530867,\n",
       " '4bub6WOlT-I': 0.03230419272085938,\n",
       " 'jIsXjk3TgkU': 0.10416666666666666,\n",
       " 'W8WAKyR5pGA': 0.0,\n",
       " 'ZBO3c3ko0eg': -0.049999999999999996,\n",
       " 'FIiz8hqXm24': 0.10555555555555556,\n",
       " 'I3mkImSqHA0': 0.045959595959595964,\n",
       " 'DTUckJz0RGo': 0.03125000000000001,\n",
       " 'JWA5mUrrr_A': 0.0234375,\n",
       " 'XqzQanN4Xx8': 0.265,\n",
       " 'QjJwrWxwLJU': 0.12295918367346936,\n",
       " 'D7zMgv16cik': 0.1684090909090909,\n",
       " 'bJYGvO6V67A': 0.0,\n",
       " 'sJ0xpruFAwQ': 0.15030864197530863,\n",
       " 'ENk_QRA2XsY': 0.18665223665223665,\n",
       " 'OB0qJwk5yA8': 0.058186958874458884,\n",
       " '29LXKUT0eMY': 0.010858585858585854,\n",
       " 'Bo24jIb7GA8': 0.06065315856982523,\n",
       " '19hkLN7KEqc': 0.002312008978675648,\n",
       " '_quGokF8G0o': 0.12566666666666665,\n",
       " 'M7qPgEDk2JY': 0.034393939393939386,\n",
       " '-PqXVcMtygc': 0.26666666666666666,\n",
       " 'GUVKWAEO_hY': 0.11889898989898988,\n",
       " '_S_9JRwFmcA': 0.875,\n",
       " 'LWIgEf_TMVU': 0.07415945165945168,\n",
       " 'aw59h2FNMIQ': 0.13472222222222222,\n",
       " 'lw0rcwYyiwE': 0.08783670033670034,\n",
       " 'sEjN7muHOLc': 0.0019360269360269146,\n",
       " 'Y-xQtgvNuvA': 0.25647306397306396,\n",
       " 'W7n2FoRinVk': 0.22315724206349205,\n",
       " 'Wjj__vIdew0': 0.06395833333333334,\n",
       " '5DvMPgoKZmM': 0.06242897727272727}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_vid_textblob_polarity(covid_filtered_out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VADER APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_vid_vader_polarity (df):\n",
    "    polarity_scores={}\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for video in df[\"video_id\"].unique():\n",
    "        sum_neg =0\n",
    "        sum_pos = 0\n",
    "        sum_neu =0\n",
    "        sum_compound= 0\n",
    "        scores={}\n",
    "        for sentence in df.loc[df[\"video_id\"]==video][\"comment\"]:\n",
    "\n",
    "            sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "            sum_neg += sentiment_dict['neg']\n",
    "            sum_pos += sentiment_dict['pos']\n",
    "            sum_neu += sentiment_dict['neu']\n",
    "            sum_compound += sentiment_dict['compound']\n",
    "            \n",
    "        scores[\"Neg\"] = sum_neg/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        scores[\"Pos\"] = sum_pos/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        scores[\"Neu\"] = sum_neu/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        scores[\"Overall\"] = sum_compound/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        \n",
    "        polarity_scores[video]=scores\n",
    "        '''# decide sentiment as positive, negative and neutral\n",
    "        if sentiment_dict['compound'] >= 0.05 :\n",
    "            print(\"Positive\")\n",
    " \n",
    "        elif sentiment_dict['compound'] <= - 0.05 :\n",
    "            print(\"Negative\")\n",
    " \n",
    "        else :\n",
    "            print(\"Neutral\")'''\n",
    "    return polarity_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aLZ85hb4wjE': {'Neg': 0.07980000000000001,\n",
       "  'Pos': 0.194,\n",
       "  'Neu': 0.7261,\n",
       "  'Overall': 0.17872000000000002},\n",
       " 'sYI97jv-pZg': {'Neg': 0.0, 'Pos': 0.056, 'Neu': 0.944, 'Overall': 0.11315},\n",
       " '3YFpjgIQqEo': {'Neg': 0.05155555555555555,\n",
       "  'Pos': 0.1257777777777778,\n",
       "  'Neu': 0.8225555555555556,\n",
       "  'Overall': 0.08543333333333335},\n",
       " 'dIsaz_XlmTw': {'Neg': 0.032125,\n",
       "  'Pos': 0.15962500000000002,\n",
       "  'Neu': 0.8083750000000001,\n",
       "  'Overall': 0.23491250000000002},\n",
       " 'DWxIvQlpJK8': {'Neg': 0.139625,\n",
       "  'Pos': 0.09925,\n",
       "  'Neu': 0.761125,\n",
       "  'Overall': -0.00888750000000002},\n",
       " 'pMUumjHY3tw': {'Neg': 0.0475,\n",
       "  'Pos': 0.034,\n",
       "  'Neu': 0.9185,\n",
       "  'Overall': -0.15775},\n",
       " 'nTUWK8vufOk': {'Neg': 0.10566666666666667,\n",
       "  'Pos': 0.1892222222222222,\n",
       "  'Neu': 0.7052222222222223,\n",
       "  'Overall': 0.2995888888888889},\n",
       " 'cPVE7QGS7As': {'Neg': 0.0758888888888889,\n",
       "  'Pos': 0.262,\n",
       "  'Neu': 0.6621111111111111,\n",
       "  'Overall': 0.3731222222222222},\n",
       " 'CEIrzjA8euQ': {'Neg': 0.196, 'Pos': 0.0, 'Neu': 0.804, 'Overall': -0.296},\n",
       " 'lw16DeB6zns': {'Neg': 0.04175,\n",
       "  'Pos': 0.148875,\n",
       "  'Neu': 0.809375,\n",
       "  'Overall': 0.27},\n",
       " '8dTelszbObM': {'Neg': 0.12455555555555556,\n",
       "  'Pos': 0.19866666666666666,\n",
       "  'Neu': 0.6766666666666667,\n",
       "  'Overall': 0.0400111111111111},\n",
       " 'Mxf8uGFcqSE': {'Neg': 0.049999999999999996,\n",
       "  'Pos': 0.14933333333333332,\n",
       "  'Neu': 0.8006666666666667,\n",
       "  'Overall': 0.23786666666666667},\n",
       " 'MQ5aYS4YFlQ': {'Neg': 0.10700000000000001,\n",
       "  'Pos': 0.1456,\n",
       "  'Neu': 0.7472,\n",
       "  'Overall': 0.25376000000000004},\n",
       " 'iOE6rAY8l-k': {'Neg': 0.03766666666666666,\n",
       "  'Pos': 0.1135,\n",
       "  'Neu': 0.8488333333333333,\n",
       "  'Overall': 0.08221666666666669},\n",
       " '_a-rQYfsCck': {'Neg': 0.064,\n",
       "  'Pos': 0.14344444444444443,\n",
       "  'Neu': 0.7925555555555556,\n",
       "  'Overall': 0.15585555555555555},\n",
       " 'jEINZXA_ujo': {'Neg': 0.05455555555555556,\n",
       "  'Pos': 0.3403333333333334,\n",
       "  'Neu': 0.605,\n",
       "  'Overall': 0.41407777777777777},\n",
       " '587N9bJ5J5k': {'Neg': 0.04033333333333333,\n",
       "  'Pos': 0.3967777777777777,\n",
       "  'Neu': 0.5630000000000001,\n",
       "  'Overall': 0.43336666666666673},\n",
       " 'E5F3xA_zkFc': {'Neg': 0.12620000000000003,\n",
       "  'Pos': 0.1485,\n",
       "  'Neu': 0.7254,\n",
       "  'Overall': -0.03336000000000003},\n",
       " '05JLyd58R-w': {'Neg': 0.0, 'Pos': 0.0, 'Neu': 1.0, 'Overall': 0.0},\n",
       " '2fRQ8OsqOLs': {'Neg': 0.06333333333333334,\n",
       "  'Pos': 0.09888888888888887,\n",
       "  'Neu': 0.8377777777777777,\n",
       "  'Overall': 0.08503333333333335},\n",
       " 'E56W-5xVOss': {'Neg': 0.0448,\n",
       "  'Pos': 0.3275,\n",
       "  'Neu': 0.6278,\n",
       "  'Overall': 0.5922000000000001},\n",
       " 'c1oU8U05puY': {'Neg': 0.20299999999999999,\n",
       "  'Pos': 0.028777777777777777,\n",
       "  'Neu': 0.7682222222222221,\n",
       "  'Overall': -0.2014888888888889},\n",
       " 'SEHcakm-fAc': {'Neg': 0.037125,\n",
       "  'Pos': 0.168125,\n",
       "  'Neu': 0.7944999999999999,\n",
       "  'Overall': 0.3123},\n",
       " '1psSvU1km0I': {'Neg': 0.15755555555555553,\n",
       "  'Pos': 0.083,\n",
       "  'Neu': 0.7594444444444445,\n",
       "  'Overall': -0.1991},\n",
       " 'PP3Yu-ro1tA': {'Neg': 0.11466666666666667,\n",
       "  'Pos': 0.11444444444444445,\n",
       "  'Neu': 0.770888888888889,\n",
       "  'Overall': 0.04813333333333334},\n",
       " 'NQeI1CRCqeo': {'Neg': 0.1836,\n",
       "  'Pos': 0.1698,\n",
       "  'Neu': 0.6467,\n",
       "  'Overall': 0.12021000000000001},\n",
       " 'RhDHGgo4yZg': {'Neg': 0.16187500000000002,\n",
       "  'Pos': 0.20400000000000001,\n",
       "  'Neu': 0.6341249999999999,\n",
       "  'Overall': -0.0593625},\n",
       " 'sdsz-t540WI': {'Neg': 0.0437,\n",
       "  'Pos': 0.17920000000000003,\n",
       "  'Neu': 0.7771999999999999,\n",
       "  'Overall': 0.46030999999999994},\n",
       " '7SKGXkZKjV8': {'Neg': 0.2641111111111111,\n",
       "  'Pos': 0.20855555555555558,\n",
       "  'Neu': 0.5273333333333333,\n",
       "  'Overall': 0.030255555555555542},\n",
       " 'oy0wHScCPds': {'Neg': 0.03833333333333334,\n",
       "  'Pos': 0.1101111111111111,\n",
       "  'Neu': 0.8515555555555555,\n",
       "  'Overall': 0.21537777777777778},\n",
       " 'o1kPskxFkQ8': {'Neg': 0.04883333333333333,\n",
       "  'Pos': 0.22383333333333333,\n",
       "  'Neu': 0.7273333333333333,\n",
       "  'Overall': -0.03314999999999999},\n",
       " 'aoNQUUQno00': {'Neg': 0.06314285714285714,\n",
       "  'Pos': 0.18999999999999997,\n",
       "  'Neu': 0.7469999999999999,\n",
       "  'Overall': 0.31827142857142865},\n",
       " 'liEUC1_l8e8': {'Neg': 0.11588888888888887,\n",
       "  'Pos': 0.09855555555555556,\n",
       "  'Neu': 0.7856666666666666,\n",
       "  'Overall': -0.03845555555555555},\n",
       " '-b0EuuMvvy8': {'Neg': 0.07577777777777778,\n",
       "  'Pos': 0.16977777777777778,\n",
       "  'Neu': 0.7545555555555556,\n",
       "  'Overall': 0.1167},\n",
       " 'MmyIvf7bEGc': {'Neg': 0.06188888888888888,\n",
       "  'Pos': 0.19155555555555556,\n",
       "  'Neu': 0.7465555555555556,\n",
       "  'Overall': 0.12915555555555558},\n",
       " 'Fd3HcncV6Zk': {'Neg': 0.0945,\n",
       "  'Pos': 0.1855,\n",
       "  'Neu': 0.7199,\n",
       "  'Overall': 0.060639999999999986},\n",
       " '-n9Ks3VTub4': {'Neg': 0.052,\n",
       "  'Pos': 0.08633333333333333,\n",
       "  'Neu': 0.862,\n",
       "  'Overall': 0.33569999999999994},\n",
       " 'LzymJ2xZhho': {'Neg': 0.06033333333333333,\n",
       "  'Pos': 0.057333333333333326,\n",
       "  'Neu': 0.8821666666666667,\n",
       "  'Overall': 0.013866666666666675},\n",
       " '-qFcO_onBdA': {'Neg': 0.1711,\n",
       "  'Pos': 0.0771,\n",
       "  'Neu': 0.7518999999999999,\n",
       "  'Overall': 0.014460000000000006},\n",
       " 'fp9uRsmTWqg': {'Neg': 0.171125,\n",
       "  'Pos': 0.08900000000000001,\n",
       "  'Neu': 0.739875,\n",
       "  'Overall': -0.10038749999999999},\n",
       " '3ZXR2eARmuQ': {'Neg': 0.03066666666666667,\n",
       "  'Pos': 0.26366666666666666,\n",
       "  'Neu': 0.7056666666666667,\n",
       "  'Overall': 0.6039555555555556},\n",
       " '57wz3HuIVLA': {'Neg': 0.01275,\n",
       "  'Pos': 0.26349999999999996,\n",
       "  'Neu': 0.72375,\n",
       "  'Overall': 0.6025750000000001},\n",
       " 'lbK7UjoLr8o': {'Neg': 0.0,\n",
       "  'Pos': 0.26849999999999996,\n",
       "  'Neu': 0.7315,\n",
       "  'Overall': 0.29390000000000005},\n",
       " 'xV1oR-RbOGU': {'Neg': 0.026000000000000002,\n",
       "  'Pos': 0.221,\n",
       "  'Neu': 0.7528888888888888,\n",
       "  'Overall': 0.6098},\n",
       " 'kn6DKdInYXk': {'Neg': 0.12933333333333333,\n",
       "  'Pos': 0.1942222222222222,\n",
       "  'Neu': 0.6764444444444444,\n",
       "  'Overall': -0.14544444444444443},\n",
       " '2T3yZ6lNRDg': {'Neg': 0.0188,\n",
       "  'Pos': 0.19290000000000002,\n",
       "  'Neu': 0.7884,\n",
       "  'Overall': 0.20521000000000003},\n",
       " 'HLYSlKY6Ww4': {'Neg': 0.10928571428571428,\n",
       "  'Pos': 0.36528571428571427,\n",
       "  'Neu': 0.5254285714285715,\n",
       "  'Overall': 0.5552142857142857},\n",
       " 'sH_YoV-NA6s': {'Neg': 0.0,\n",
       "  'Pos': 0.27442857142857147,\n",
       "  'Neu': 0.7255714285714284,\n",
       "  'Overall': 0.5895},\n",
       " 'ZLT6L3PHz78': {'Neg': 0.10533333333333333,\n",
       "  'Pos': 0.23783333333333334,\n",
       "  'Neu': 0.6568333333333334,\n",
       "  'Overall': 0.08168333333333332},\n",
       " 'lczwrm68u6I': {'Neg': 0.023600000000000003,\n",
       "  'Pos': 0.3898,\n",
       "  'Neu': 0.5865,\n",
       "  'Overall': 0.6887199999999999},\n",
       " 'zhBdbLj5y6A': {'Neg': 0.1592,\n",
       "  'Pos': 0.14909999999999998,\n",
       "  'Neu': 0.6917,\n",
       "  'Overall': 0.06791},\n",
       " 'ibWFsmcnefk': {'Neg': 0.03344444444444445,\n",
       "  'Pos': 0.23011111111111113,\n",
       "  'Neu': 0.7363333333333333,\n",
       "  'Overall': 0.40044444444444444},\n",
       " 'e0fN7HxkIUc': {'Neg': 0.14555555555555555,\n",
       "  'Pos': 0.2416666666666667,\n",
       "  'Neu': 0.6127777777777778,\n",
       "  'Overall': 0.07914444444444443},\n",
       " 'Ji47WRv2tQE': {'Neg': 0.1625,\n",
       "  'Pos': 0.146,\n",
       "  'Neu': 0.6915,\n",
       "  'Overall': -0.16921},\n",
       " 'dj5ov38ihZI': {'Neg': 0.3215,\n",
       "  'Pos': 0.2365,\n",
       "  'Neu': 0.44200000000000006,\n",
       "  'Overall': 0.22475},\n",
       " 'j3E3NF9nk44': {'Neg': 0.011,\n",
       "  'Pos': 0.19328571428571428,\n",
       "  'Neu': 0.7957142857142857,\n",
       "  'Overall': 0.16338571428571427},\n",
       " 'BomdsEJjb0E': {'Neg': 0.1326,\n",
       "  'Pos': 0.1105,\n",
       "  'Neu': 0.7569,\n",
       "  'Overall': -0.22974999999999998},\n",
       " 'T7c6GvrF82k': {'Neg': 0.32112500000000005,\n",
       "  'Pos': 0.172375,\n",
       "  'Neu': 0.5065,\n",
       "  'Overall': -0.21575},\n",
       " '6DBFwIlT4fg': {'Neg': 0.0638,\n",
       "  'Pos': 0.0927,\n",
       "  'Neu': 0.8435,\n",
       "  'Overall': 0.05889000000000001},\n",
       " '2FgFNBIJTIA': {'Neg': 0.13599999999999998,\n",
       "  'Pos': 0.017285714285714286,\n",
       "  'Neu': 0.8467142857142856,\n",
       "  'Overall': -0.3609428571428572},\n",
       " '254GdlKEz5I': {'Neg': 0.0,\n",
       "  'Pos': 0.08233333333333333,\n",
       "  'Neu': 0.9176666666666667,\n",
       "  'Overall': 0.10606666666666666},\n",
       " 'y4qaoHc2ezk': {'Neg': 0.09244444444444445,\n",
       "  'Pos': 0.23266666666666666,\n",
       "  'Neu': 0.6747777777777778,\n",
       "  'Overall': 0.18007777777777778},\n",
       " '2VRGUm_wQ0w': {'Neg': 0.103,\n",
       "  'Pos': 0.2745555555555556,\n",
       "  'Neu': 0.6224444444444444,\n",
       "  'Overall': 0.20161111111111113},\n",
       " 'HK5rfm4X2G0': {'Neg': 0.0691,\n",
       "  'Pos': 0.1046,\n",
       "  'Neu': 0.8261,\n",
       "  'Overall': 0.06345},\n",
       " '_DM5L8uu1Do': {'Neg': 0.14388888888888887,\n",
       "  'Pos': 0.2031111111111111,\n",
       "  'Neu': 0.6531111111111111,\n",
       "  'Overall': 0.14923333333333336},\n",
       " 'pK6y1h0YgSU': {'Neg': 0.042124999999999996,\n",
       "  'Pos': 0.26887500000000003,\n",
       "  'Neu': 0.6889999999999998,\n",
       "  'Overall': 0.47506250000000005},\n",
       " 'a3-AiHSyTIU': {'Neg': 0.09955555555555556,\n",
       "  'Pos': 0.18455555555555553,\n",
       "  'Neu': 0.716111111111111,\n",
       "  'Overall': 0.34498888888888884},\n",
       " 'SLrKdYsNbSo': {'Neg': 0.13599999999999998,\n",
       "  'Pos': 0.07239999999999999,\n",
       "  'Neu': 0.7918000000000001,\n",
       "  'Overall': 0.016459999999999995},\n",
       " '8w61tigk0ag': {'Neg': 0.1733,\n",
       "  'Pos': 0.0759,\n",
       "  'Neu': 0.7508999999999999,\n",
       "  'Overall': -0.22881999999999988},\n",
       " 'Mwpqgw9gMfo': {'Neg': 0.1465,\n",
       "  'Pos': 0.6910000000000001,\n",
       "  'Neu': 0.1625,\n",
       "  'Overall': 0.22995},\n",
       " 'FJEMcVK0MWI': {'Neg': 0.0,\n",
       "  'Pos': 0.3315,\n",
       "  'Neu': 0.6684999999999999,\n",
       "  'Overall': 0.5858},\n",
       " 'gRKL_FUQUpY': {'Neg': 0.086,\n",
       "  'Pos': 0.17875,\n",
       "  'Neu': 0.73525,\n",
       "  'Overall': 0.082925},\n",
       " 'LLFcBFAuauk': {'Neg': 0.11037499999999999,\n",
       "  'Pos': 0.20949999999999996,\n",
       "  'Neu': 0.68,\n",
       "  'Overall': 0.24870000000000003},\n",
       " 'EsW0ye2wjUQ': {'Neg': 0.0, 'Pos': 0.75, 'Neu': 0.25, 'Overall': 0.4588},\n",
       " 'R0i7i80ToUM': {'Neg': 0.025333333333333333,\n",
       "  'Pos': 0.28522222222222227,\n",
       "  'Neu': 0.6894444444444444,\n",
       "  'Overall': 0.4903111111111112},\n",
       " '6zkba0hNiE8': {'Neg': 0.02266666666666667,\n",
       "  'Pos': 0.04733333333333333,\n",
       "  'Neu': 0.9300000000000002,\n",
       "  'Overall': 0.08673333333333334},\n",
       " 'T48EuGS36Zk': {'Neg': 0.06066666666666667,\n",
       "  'Pos': 0.30183333333333334,\n",
       "  'Neu': 0.6375000000000001,\n",
       "  'Overall': 0.5301166666666667},\n",
       " 'KzCjAetb3_I': {'Neg': 0.0813,\n",
       "  'Pos': 0.2623,\n",
       "  'Neu': 0.6564,\n",
       "  'Overall': 0.22349999999999998},\n",
       " 'N9OQbW0YOLU': {'Neg': 0.138,\n",
       "  'Pos': 0.1615,\n",
       "  'Neu': 0.7005,\n",
       "  'Overall': -0.10526666666666669},\n",
       " 'I4WXmX_6Zds': {'Neg': 0.062333333333333324,\n",
       "  'Pos': 0.07311111111111111,\n",
       "  'Neu': 0.8645555555555555,\n",
       "  'Overall': 0.06298888888888889},\n",
       " 'WTD3l2xovQI': {'Neg': 0.02277777777777778,\n",
       "  'Pos': 0.2731111111111111,\n",
       "  'Neu': 0.7043333333333334,\n",
       "  'Overall': 0.5665},\n",
       " 'LtW0cTMWdbY': {'Neg': 0.0455,\n",
       "  'Pos': 0.0607,\n",
       "  'Neu': 0.8936999999999999,\n",
       "  'Overall': 0.009170000000000001},\n",
       " 'iVM-azf1Akk': {'Neg': 0.1507777777777778,\n",
       "  'Pos': 0.042222222222222223,\n",
       "  'Neu': 0.8069999999999999,\n",
       "  'Overall': -0.11801111111111112},\n",
       " 'xWV_GI9hq5U': {'Neg': 0.12688888888888888,\n",
       "  'Pos': 0.23088888888888887,\n",
       "  'Neu': 0.6422222222222222,\n",
       "  'Overall': 0.1106},\n",
       " '-LFGaCkPzzY': {'Neg': 0.06799999999999999,\n",
       "  'Pos': 0.19833333333333333,\n",
       "  'Neu': 0.7336666666666667,\n",
       "  'Overall': 0.16363333333333335},\n",
       " 'rFDK10oplxA': {'Neg': 0.01611111111111111,\n",
       "  'Pos': 0.17655555555555555,\n",
       "  'Neu': 0.8073333333333333,\n",
       "  'Overall': 0.2899555555555555},\n",
       " '6p_8T_xmnLQ': {'Neg': 0.12266666666666667,\n",
       "  'Pos': 0.19411111111111112,\n",
       "  'Neu': 0.6833333333333333,\n",
       "  'Overall': 0.1625777777777778},\n",
       " 'D9-CHldoZ74': {'Neg': 0.15988888888888889,\n",
       "  'Pos': 0.22366666666666665,\n",
       "  'Neu': 0.6164444444444445,\n",
       "  'Overall': -0.12791111111111111},\n",
       " 'xqz1KueuzAM': {'Neg': 0.2413157894736842,\n",
       "  'Pos': 0.12278947368421053,\n",
       "  'Neu': 0.6358947368421053,\n",
       "  'Overall': -0.21106315789473684},\n",
       " 'T2JkwAZ8KY8': {'Neg': 0.22920000000000001,\n",
       "  'Pos': 0.10169999999999998,\n",
       "  'Neu': 0.669,\n",
       "  'Overall': -0.27592},\n",
       " 'TQ0QJ4Si7A4': {'Neg': 0.07875,\n",
       "  'Pos': 0.1325,\n",
       "  'Neu': 0.7887500000000001,\n",
       "  'Overall': 0.19025},\n",
       " '81Fj00CFmJM': {'Neg': 0.022375,\n",
       "  'Pos': 0.01375,\n",
       "  'Neu': 0.9638749999999999,\n",
       "  'Overall': 0.010575000000000008},\n",
       " 'C-iuGrZR2pQ': {'Neg': 0.0805,\n",
       "  'Pos': 0.1464,\n",
       "  'Neu': 0.773,\n",
       "  'Overall': 0.09995000000000001},\n",
       " 'JT1R95tG9jg': {'Neg': 0.12714285714285717,\n",
       "  'Pos': 0.12999999999999998,\n",
       "  'Neu': 0.7428571428571428,\n",
       "  'Overall': -0.06155714285714286},\n",
       " 'O06AlL8nONo': {'Neg': 0.10855555555555557,\n",
       "  'Pos': 0.037333333333333336,\n",
       "  'Neu': 0.8542222222222223,\n",
       "  'Overall': -0.20228888888888888},\n",
       " 'HabzHfgdMNs': {'Neg': 0.023799999999999998,\n",
       "  'Pos': 0.30979999999999996,\n",
       "  'Neu': 0.6664,\n",
       "  'Overall': 0.40113000000000004},\n",
       " 'o96VMbz4Zpk': {'Neg': 0.1665, 'Pos': 0.0, 'Neu': 0.8335, 'Overall': -0.125},\n",
       " 'XylXJJp4HpE': {'Neg': 0.03166666666666666,\n",
       "  'Pos': 0.22966666666666663,\n",
       "  'Neu': 0.7384444444444445,\n",
       "  'Overall': 0.4071777777777778},\n",
       " 'ZaTPlJ8nd9Q': {'Neg': 0.04544444444444444,\n",
       "  'Pos': 0.2541111111111111,\n",
       "  'Neu': 0.7004444444444444,\n",
       "  'Overall': 0.27423333333333333},\n",
       " 'R3E3RlBEIl8': {'Neg': 0.0, 'Pos': 0.4085, 'Neu': 0.5915, 'Overall': 0.61815},\n",
       " '5jCZ42fV6sw': {'Neg': 0.238,\n",
       "  'Pos': 0.07433333333333333,\n",
       "  'Neu': 0.6876666666666665,\n",
       "  'Overall': -0.40563333333333335},\n",
       " 'tq7FyWSGaD4': {'Neg': 0.047625,\n",
       "  'Pos': 0.13675,\n",
       "  'Neu': 0.8157500000000001,\n",
       "  'Overall': 0.26514999999999994},\n",
       " 'jQusLZgOYac': {'Neg': 0.0,\n",
       "  'Pos': 0.3344,\n",
       "  'Neu': 0.6656000000000001,\n",
       "  'Overall': 0.618},\n",
       " 'iOnxb9jrY40': {'Neg': 0.09137499999999998,\n",
       "  'Pos': 0.10825,\n",
       "  'Neu': 0.8003750000000001,\n",
       "  'Overall': 0.06644999999999998},\n",
       " 'UWMmesK08TU': {'Neg': 0.10166666666666667,\n",
       "  'Pos': 0.13577777777777778,\n",
       "  'Neu': 0.7625555555555555,\n",
       "  'Overall': 0.13556666666666667},\n",
       " '4bub6WOlT-I': {'Neg': 0.06433333333333333,\n",
       "  'Pos': 0.2028888888888889,\n",
       "  'Neu': 0.7327777777777779,\n",
       "  'Overall': 0.2764444444444444},\n",
       " 'jIsXjk3TgkU': {'Neg': 0.054200000000000005,\n",
       "  'Pos': 0.1776,\n",
       "  'Neu': 0.7682,\n",
       "  'Overall': 0.31197},\n",
       " 'W8WAKyR5pGA': {'Neg': 0.0, 'Pos': 0.315, 'Neu': 0.685, 'Overall': 0.3182},\n",
       " 'ZBO3c3ko0eg': {'Neg': 0.189,\n",
       "  'Pos': 0.15785714285714286,\n",
       "  'Neu': 0.6532857142857144,\n",
       "  'Overall': -0.015128571428571411},\n",
       " 'FIiz8hqXm24': {'Neg': 0.0,\n",
       "  'Pos': 0.07522222222222223,\n",
       "  'Neu': 0.9247777777777778,\n",
       "  'Overall': 0.14596666666666666},\n",
       " 'I3mkImSqHA0': {'Neg': 0.12733333333333333,\n",
       "  'Pos': 0.09433333333333332,\n",
       "  'Neu': 0.7782222222222224,\n",
       "  'Overall': -0.1276},\n",
       " 'DTUckJz0RGo': {'Neg': 0.15712500000000001,\n",
       "  'Pos': 0.05225,\n",
       "  'Neu': 0.790625,\n",
       "  'Overall': -0.10548750000000001},\n",
       " 'JWA5mUrrr_A': {'Neg': 0.23375,\n",
       "  'Pos': 0.04925,\n",
       "  'Neu': 0.717,\n",
       "  'Overall': -0.1225625},\n",
       " 'XqzQanN4Xx8': {'Neg': 0.0114,\n",
       "  'Pos': 0.5027,\n",
       "  'Neu': 0.4859,\n",
       "  'Overall': 0.37498},\n",
       " 'QjJwrWxwLJU': {'Neg': 0.03242857142857143,\n",
       "  'Pos': 0.11757142857142856,\n",
       "  'Neu': 0.849857142857143,\n",
       "  'Overall': 0.15564285714285717},\n",
       " 'D7zMgv16cik': {'Neg': 0.06525,\n",
       "  'Pos': 0.1835,\n",
       "  'Neu': 0.75125,\n",
       "  'Overall': -0.0024874999999999897},\n",
       " 'bJYGvO6V67A': {'Neg': 0.0, 'Pos': 0.659, 'Neu': 0.341, 'Overall': 0.7003},\n",
       " 'sJ0xpruFAwQ': {'Neg': 0.046,\n",
       "  'Pos': 0.2241111111111111,\n",
       "  'Neu': 0.73,\n",
       "  'Overall': 0.37444444444444447},\n",
       " 'ENk_QRA2XsY': {'Neg': 0.029285714285714286,\n",
       "  'Pos': 0.15614285714285714,\n",
       "  'Neu': 0.8144285714285714,\n",
       "  'Overall': 0.27147142857142853},\n",
       " 'OB0qJwk5yA8': {'Neg': 0.056100000000000004,\n",
       "  'Pos': 0.06860000000000001,\n",
       "  'Neu': 0.8754,\n",
       "  'Overall': -0.056600000000000004},\n",
       " '29LXKUT0eMY': {'Neg': 0.06833333333333333,\n",
       "  'Pos': 0.06933333333333333,\n",
       "  'Neu': 0.8623333333333333,\n",
       "  'Overall': -0.01906666666666666},\n",
       " 'Bo24jIb7GA8': {'Neg': 0.0621111111111111,\n",
       "  'Pos': 0.09111111111111111,\n",
       "  'Neu': 0.8466666666666667,\n",
       "  'Overall': 0.2718888888888889},\n",
       " '19hkLN7KEqc': {'Neg': 0.12611111111111112,\n",
       "  'Pos': 0.15344444444444444,\n",
       "  'Neu': 0.7204444444444444,\n",
       "  'Overall': 0.005099999999999993},\n",
       " '_quGokF8G0o': {'Neg': 0.1234,\n",
       "  'Pos': 0.129,\n",
       "  'Neu': 0.7476,\n",
       "  'Overall': 0.047220000000000005},\n",
       " 'M7qPgEDk2JY': {'Neg': 0.091,\n",
       "  'Pos': 0.22999999999999998,\n",
       "  'Neu': 0.679,\n",
       "  'Overall': 0.11255},\n",
       " '-PqXVcMtygc': {'Neg': 0.222,\n",
       "  'Pos': 0.17433333333333334,\n",
       "  'Neu': 0.6036666666666667,\n",
       "  'Overall': -0.14193333333333333},\n",
       " 'GUVKWAEO_hY': {'Neg': 0.02,\n",
       "  'Pos': 0.14040000000000002,\n",
       "  'Neu': 0.8394,\n",
       "  'Overall': 0.28042},\n",
       " '_S_9JRwFmcA': {'Neg': 0.0, 'Pos': 0.761, 'Neu': 0.239, 'Overall': 0.4926},\n",
       " 'LWIgEf_TMVU': {'Neg': 0.0727,\n",
       "  'Pos': 0.23259999999999997,\n",
       "  'Neu': 0.6947,\n",
       "  'Overall': 0.12046000000000001},\n",
       " 'aw59h2FNMIQ': {'Neg': 0.059111111111111114,\n",
       "  'Pos': 0.21166666666666667,\n",
       "  'Neu': 0.729111111111111,\n",
       "  'Overall': 0.06736666666666664},\n",
       " 'lw0rcwYyiwE': {'Neg': 0.11344444444444443,\n",
       "  'Pos': 0.09200000000000001,\n",
       "  'Neu': 0.7944444444444445,\n",
       "  'Overall': -0.005522222222222224},\n",
       " 'sEjN7muHOLc': {'Neg': 0.12844444444444447,\n",
       "  'Pos': 0.18100000000000002,\n",
       "  'Neu': 0.6904444444444444,\n",
       "  'Overall': 0.07881111111111114},\n",
       " 'Y-xQtgvNuvA': {'Neg': 0.10144444444444445,\n",
       "  'Pos': 0.17622222222222222,\n",
       "  'Neu': 0.7225555555555556,\n",
       "  'Overall': 0.1534333333333334},\n",
       " 'W7n2FoRinVk': {'Neg': 0.020499999999999997,\n",
       "  'Pos': 0.08650000000000001,\n",
       "  'Neu': 0.893,\n",
       "  'Overall': 0.1047375},\n",
       " 'Wjj__vIdew0': {'Neg': 0.03825,\n",
       "  'Pos': 0.09237500000000001,\n",
       "  'Neu': 0.869375,\n",
       "  'Overall': -0.014812500000000004},\n",
       " '5DvMPgoKZmM': {'Neg': 0.03025,\n",
       "  'Pos': 0.1,\n",
       "  'Neu': 0.86975,\n",
       "  'Overall': 0.195475}}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_vid_vader_polarity(covid_filtered_out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "#import re\n",
    "#from scipy.special import softmax\n",
    "\n",
    "def roberta_per_vid_scores(df):\n",
    "    polarity_scores={}\n",
    "\n",
    "    roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "    labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "    for video in df[\"video_id\"].unique():\n",
    "        sum_neg =0\n",
    "        sum_pos = 0\n",
    "        sum_neu =0 \n",
    "        scores={}\n",
    "        for comments in df.loc[df[\"video_id\"]==video][\"comment\"]:\n",
    "            comment_words = []\n",
    "            comments = comments.replace(\"\\n\", \" \")\n",
    "            comments = comments.replace(\"\\xa0\", \" \")\n",
    "            comments = comments.replace(\"?\", \" \")\n",
    "            comments = comments.replace(\":\", \" \")\n",
    "            comments = comments.replace(\";\", \" \")\n",
    "            comments = comments.replace(\";\", \" \")\n",
    "            comments = re.sub(r\"\\s+\", ' ', comments) \n",
    "     #   print(comments)\n",
    "            for word in comments.split(' '):\n",
    "                if word.startswith('@') and len(word) > 1:\n",
    "                    word = '@user'\n",
    "        \n",
    "                elif word.startswith('http'):\n",
    "                    word = \"http\"\n",
    "                comment_words.append(word)\n",
    "\n",
    "            comment_procs = \" \".join(comment_words)\n",
    "\n",
    "            encoded = tokenizer(comment_procs, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "           # print(encoded)\n",
    "            output = model(**encoded)\n",
    "\n",
    "            scores = output[0][0].detach().numpy()\n",
    "\n",
    "            scores = softmax(scores)\n",
    "\n",
    "            for i in range(len(scores)):\n",
    "\n",
    "                l = labels[i]\n",
    "                s = scores[i]\n",
    "                #    labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "                if l==\"Negative\":\n",
    "                    sum_neg+= s\n",
    "                elif l == \"Neutral\":\n",
    "                    sum_neu+=s\n",
    "                else : \n",
    "                    sum_pos+=s\n",
    "       # scores[\"Neg\"] = sum_neg/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        scores =dict([(\"Neg\", sum_neg/df.loc[df[\"video_id\"]==video][\"comment\"].count()),(\"Pos\",sum_pos/df.loc[df[\"video_id\"]==video][\"comment\"].count()),(\"Neu\",sum_neu/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    ")])\n",
    "        #scores[\"Pos\"] = sum_pos/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "        #scores[\"Neu\"] = sum_neu/df.loc[df[\"video_id\"]==video][\"comment\"].count()\n",
    "\n",
    "        polarity_scores[video] = scores\n",
    "    return polarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aLZ85hb4wjE': {'Neg': 0.24424575177254154,\n",
       "  'Pos': 0.4741820393828675,\n",
       "  'Neu': 0.28157221488654616},\n",
       " 'sYI97jv-pZg': {'Neg': 0.3894941806793213,\n",
       "  'Pos': 0.0859330091625452,\n",
       "  'Neu': 0.5245728343725204},\n",
       " '3YFpjgIQqEo': {'Neg': 0.4141863211989403,\n",
       "  'Pos': 0.25543777147928876,\n",
       "  'Neu': 0.33037588579787147},\n",
       " 'dIsaz_XlmTw': {'Neg': 0.33079710984020494,\n",
       "  'Pos': 0.2652561893919483,\n",
       "  'Neu': 0.4039467005059123},\n",
       " 'DWxIvQlpJK8': {'Neg': 0.289873747547972,\n",
       "  'Pos': 0.29180154629284516,\n",
       "  'Neu': 0.41832468984648585},\n",
       " 'pMUumjHY3tw': {'Neg': 0.28391369991004467,\n",
       "  'Pos': 0.05910225957632065,\n",
       "  'Neu': 0.6569840013980865},\n",
       " 'nTUWK8vufOk': {'Neg': 0.38223098513359827,\n",
       "  'Pos': 0.3571269003312207,\n",
       "  'Neu': 0.2606421046786838},\n",
       " 'cPVE7QGS7As': {'Neg': 0.16431427941036722,\n",
       "  'Pos': 0.5078818136826158,\n",
       "  'Neu': 0.32780391226212185},\n",
       " 'CEIrzjA8euQ': {'Neg': 0.15780450403690338,\n",
       "  'Pos': 0.1664552390575409,\n",
       "  'Neu': 0.6757402420043945},\n",
       " 'lw16DeB6zns': {'Neg': 0.18314840432140045,\n",
       "  'Pos': 0.3392289634793997,\n",
       "  'Neu': 0.4776226216927171},\n",
       " '8dTelszbObM': {'Neg': 0.3829619338115056,\n",
       "  'Pos': 0.23020292735762066,\n",
       "  'Neu': 0.38683512227402794},\n",
       " 'Mxf8uGFcqSE': {'Neg': 0.3286059144884348,\n",
       "  'Pos': 0.23150264006108046,\n",
       "  'Neu': 0.43989147742589313},\n",
       " 'MQ5aYS4YFlQ': {'Neg': 0.3910105600953102,\n",
       "  'Pos': 0.3012618159875274,\n",
       "  'Neu': 0.307727637887001},\n",
       " 'iOE6rAY8l-k': {'Neg': 0.3188534736012419,\n",
       "  'Pos': 0.26144224327678484,\n",
       "  'Neu': 0.41970429693659145},\n",
       " '_a-rQYfsCck': {'Neg': 0.2134859820879582,\n",
       "  'Pos': 0.32815349960906637,\n",
       "  'Neu': 0.458360498978032},\n",
       " 'jEINZXA_ujo': {'Neg': 0.10915406863205135,\n",
       "  'Pos': 0.6057261071271367,\n",
       "  'Neu': 0.28511982452538276},\n",
       " '587N9bJ5J5k': {'Neg': 0.17312934953305456,\n",
       "  'Pos': 0.5903791793518596,\n",
       "  'Neu': 0.23649148808585274},\n",
       " 'E5F3xA_zkFc': {'Neg': 0.5447165288962423,\n",
       "  'Pos': 0.20625192711595447,\n",
       "  'Neu': 0.2490315232425928},\n",
       " '05JLyd58R-w': {'Neg': 0.4840949047356844,\n",
       "  'Pos': 0.06720608472824097,\n",
       "  'Neu': 0.4486990049481392},\n",
       " '2fRQ8OsqOLs': {'Neg': 0.2568833854747936,\n",
       "  'Pos': 0.22534770828982195,\n",
       "  'Neu': 0.5177689099477397},\n",
       " 'E56W-5xVOss': {'Neg': 0.06495306607102976,\n",
       "  'Pos': 0.6396113216876984,\n",
       "  'Neu': 0.29543561283499004},\n",
       " 'c1oU8U05puY': {'Neg': 0.29776944364938474,\n",
       "  'Pos': 0.11613088954860966,\n",
       "  'Neu': 0.5860996453298463},\n",
       " 'SEHcakm-fAc': {'Neg': 0.21779667303781025,\n",
       "  'Pos': 0.4252193943830207,\n",
       "  'Neu': 0.35698396479710937},\n",
       " '1psSvU1km0I': {'Neg': 0.5429471060116258,\n",
       "  'Pos': 0.2723351027816534,\n",
       "  'Neu': 0.1847177983986007},\n",
       " 'PP3Yu-ro1tA': {'Neg': 0.3924799071262694,\n",
       "  'Pos': 0.21331373881548643,\n",
       "  'Neu': 0.39420634135603905},\n",
       " 'NQeI1CRCqeo': {'Neg': 0.26817576005123556,\n",
       "  'Pos': 0.3413007685914636,\n",
       "  'Neu': 0.3905234567821026},\n",
       " 'RhDHGgo4yZg': {'Neg': 0.3804928094468778,\n",
       "  'Pos': 0.39923470048233867,\n",
       "  'Neu': 0.2202725107781589},\n",
       " 'sdsz-t540WI': {'Neg': 0.20617095045745373,\n",
       "  'Pos': 0.456254156306386,\n",
       "  'Neu': 0.3375748723745346},\n",
       " '7SKGXkZKjV8': {'Neg': 0.4638265831421854,\n",
       "  'Pos': 0.22973601271708807,\n",
       "  'Neu': 0.3064374220040109},\n",
       " 'oy0wHScCPds': {'Neg': 0.18616034168129167,\n",
       "  'Pos': 0.32002748052279156,\n",
       "  'Neu': 0.4938121711214383},\n",
       " 'o1kPskxFkQ8': {'Neg': 0.42847522064888227,\n",
       "  'Pos': 0.402721689393123,\n",
       "  'Neu': 0.16880312686165175},\n",
       " 'aoNQUUQno00': {'Neg': 0.3395658060243087,\n",
       "  'Pos': 0.30344815405883957,\n",
       "  'Neu': 0.3569860559489046},\n",
       " 'liEUC1_l8e8': {'Neg': 0.6806901064183977,\n",
       "  'Pos': 0.05708840996440914,\n",
       "  'Neu': 0.2622214862042003},\n",
       " '-b0EuuMvvy8': {'Neg': 0.24769592212720049,\n",
       "  'Pos': 0.10662825840214889,\n",
       "  'Neu': 0.6456758379936218},\n",
       " 'MmyIvf7bEGc': {'Neg': 0.08503153202279161,\n",
       "  'Pos': 0.42467138005627525,\n",
       "  'Neu': 0.490297091503938},\n",
       " 'Fd3HcncV6Zk': {'Neg': 0.28265681746415794,\n",
       "  'Pos': 0.3828651793766767,\n",
       "  'Neu': 0.3344780135899782},\n",
       " '-n9Ks3VTub4': {'Neg': 0.0663933443526427,\n",
       "  'Pos': 0.16013591488202414,\n",
       "  'Neu': 0.7734707196553549},\n",
       " 'LzymJ2xZhho': {'Neg': 0.16437132218076536,\n",
       "  'Pos': 0.39386866039906937,\n",
       "  'Neu': 0.4417600426822901},\n",
       " '-qFcO_onBdA': {'Neg': 0.3970037639141083,\n",
       "  'Pos': 0.07284530559554696,\n",
       "  'Neu': 0.5301509484648704},\n",
       " 'fp9uRsmTWqg': {'Neg': 0.5589991104789078,\n",
       "  'Pos': 0.1531059091212228,\n",
       "  'Neu': 0.28789499681442976},\n",
       " '3ZXR2eARmuQ': {'Neg': 0.05235973492057787,\n",
       "  'Pos': 0.5947885182168748,\n",
       "  'Neu': 0.3528517244590653},\n",
       " '57wz3HuIVLA': {'Neg': 0.07949328393442556,\n",
       "  'Pos': 0.6818483136594296,\n",
       "  'Neu': 0.23865838581696153},\n",
       " 'lbK7UjoLr8o': {'Neg': 0.26297249644994736,\n",
       "  'Pos': 0.32898617163300514,\n",
       "  'Neu': 0.4080413281917572},\n",
       " 'xV1oR-RbOGU': {'Neg': 0.24810375268053678,\n",
       "  'Pos': 0.3728819667465157,\n",
       "  'Neu': 0.379014253616333},\n",
       " 'kn6DKdInYXk': {'Neg': 0.4406607082217104,\n",
       "  'Pos': 0.2764090742501948,\n",
       "  'Neu': 0.28293023258447647},\n",
       " '2T3yZ6lNRDg': {'Neg': 0.19512141330633312,\n",
       "  'Pos': 0.3508006255142391,\n",
       "  'Neu': 0.4540779642760754},\n",
       " 'HLYSlKY6Ww4': {'Neg': 0.004295782535336912,\n",
       "  'Pos': 0.9514003310884748,\n",
       "  'Neu': 0.04430389031767845},\n",
       " 'sH_YoV-NA6s': {'Neg': 0.013506762916222215,\n",
       "  'Pos': 0.8071821512920516,\n",
       "  'Neu': 0.17931108602455684},\n",
       " 'ZLT6L3PHz78': {'Neg': 0.21193703838313618,\n",
       "  'Pos': 0.2863163718332847,\n",
       "  'Neu': 0.5017465899387995},\n",
       " 'lczwrm68u6I': {'Neg': 0.012433728890027852,\n",
       "  'Pos': 0.8680140405893326,\n",
       "  'Neu': 0.11955223185941577},\n",
       " 'zhBdbLj5y6A': {'Neg': 0.3512038664892316,\n",
       "  'Pos': 0.24891177341341972,\n",
       "  'Neu': 0.3998843662440777},\n",
       " 'ibWFsmcnefk': {'Neg': 0.36659233048299533,\n",
       "  'Pos': 0.3429683435501324,\n",
       "  'Neu': 0.2904393227977885},\n",
       " 'e0fN7HxkIUc': {'Neg': 0.6518301344994042,\n",
       "  'Pos': 0.12846990560905802,\n",
       "  'Neu': 0.21969997055000728},\n",
       " 'Ji47WRv2tQE': {'Neg': 0.48088988242670894,\n",
       "  'Pos': 0.2609048563055694,\n",
       "  'Neu': 0.25820527598261833},\n",
       " 'dj5ov38ihZI': {'Neg': 0.33171851307270117,\n",
       "  'Pos': 0.44357716385275126,\n",
       "  'Neu': 0.22470431122928858},\n",
       " 'j3E3NF9nk44': {'Neg': 0.2566880557153906,\n",
       "  'Pos': 0.2854774237743446,\n",
       "  'Neu': 0.45783452476773945},\n",
       " 'BomdsEJjb0E': {'Neg': 0.5481204116251319,\n",
       "  'Pos': 0.13265389325097204,\n",
       "  'Neu': 0.3192256987094879},\n",
       " 'T7c6GvrF82k': {'Neg': 0.7010493613779545,\n",
       "  'Pos': 0.07868788746418431,\n",
       "  'Neu': 0.22026275843381882},\n",
       " '6DBFwIlT4fg': {'Neg': 0.3545808039023541,\n",
       "  'Pos': 0.3060166474664584,\n",
       "  'Neu': 0.3394025292247534},\n",
       " '2FgFNBIJTIA': {'Neg': 0.6192690644945417,\n",
       "  'Pos': 0.018921205308288336,\n",
       "  'Neu': 0.3618097166929926},\n",
       " '254GdlKEz5I': {'Neg': 0.5694599201281866,\n",
       "  'Pos': 0.022785108846922714,\n",
       "  'Neu': 0.40775499244530994},\n",
       " 'y4qaoHc2ezk': {'Neg': 0.1353207137953076,\n",
       "  'Pos': 0.38133611902594566,\n",
       "  'Neu': 0.4833431910309527},\n",
       " '2VRGUm_wQ0w': {'Neg': 0.4144594016640137,\n",
       "  'Pos': 0.33025603542207843,\n",
       "  'Neu': 0.255284553186761},\n",
       " 'HK5rfm4X2G0': {'Neg': 0.21503179722931237,\n",
       "  'Pos': 0.32239614622667434,\n",
       "  'Neu': 0.4625720638781786},\n",
       " '_DM5L8uu1Do': {'Neg': 0.15243459190241992,\n",
       "  'Pos': 0.4692927388888266,\n",
       "  'Neu': 0.3782726948459943},\n",
       " 'pK6y1h0YgSU': {'Neg': 0.11696977718384005,\n",
       "  'Pos': 0.757594421505928,\n",
       "  'Neu': 0.1254357792204246},\n",
       " 'a3-AiHSyTIU': {'Neg': 0.570676461690002,\n",
       "  'Pos': 0.09767850064155129,\n",
       "  'Neu': 0.33164503673712414},\n",
       " 'SLrKdYsNbSo': {'Neg': 0.38607031404972075,\n",
       "  'Pos': 0.08350183865986764,\n",
       "  'Neu': 0.5304278835654259},\n",
       " '8w61tigk0ag': {'Neg': 0.7055422127246856,\n",
       "  'Pos': 0.03963112242054194,\n",
       "  'Neu': 0.25482666939496995},\n",
       " 'Mwpqgw9gMfo': {'Neg': 0.01277605228824541,\n",
       "  'Pos': 0.8125654757022858,\n",
       "  'Neu': 0.1746584251523018},\n",
       " 'FJEMcVK0MWI': {'Neg': 0.003786157671129331,\n",
       "  'Pos': 0.9009599089622498,\n",
       "  'Neu': 0.09525394843270381},\n",
       " 'gRKL_FUQUpY': {'Neg': 0.3087087750900537,\n",
       "  'Pos': 0.28076451551169157,\n",
       "  'Neu': 0.4105266882106662},\n",
       " 'LLFcBFAuauk': {'Neg': 0.32109121009125374,\n",
       "  'Pos': 0.4738640346331522,\n",
       "  'Neu': 0.20504474034532905},\n",
       " 'EsW0ye2wjUQ': {'Neg': 0.4900619387626648,\n",
       "  'Pos': 0.0339045524597168,\n",
       "  'Neu': 0.4760335087776184},\n",
       " 'R0i7i80ToUM': {'Neg': 0.07969931496255514,\n",
       "  'Pos': 0.7658483135617442,\n",
       "  'Neu': 0.1544523692379395},\n",
       " '6zkba0hNiE8': {'Neg': 0.13684329907927248,\n",
       "  'Pos': 0.2713681277301576,\n",
       "  'Neu': 0.591788575053215},\n",
       " 'T48EuGS36Zk': {'Neg': 0.17334434118432304,\n",
       "  'Pos': 0.6555072765331715,\n",
       "  'Neu': 0.17114838942264518},\n",
       " 'KzCjAetb3_I': {'Neg': 0.0829349166015163,\n",
       "  'Pos': 0.5904765650629997,\n",
       "  'Neu': 0.3265885107219219},\n",
       " 'N9OQbW0YOLU': {'Neg': 0.5585400482717281,\n",
       "  'Pos': 0.2050911634384344,\n",
       "  'Neu': 0.23636879120022058},\n",
       " 'I4WXmX_6Zds': {'Neg': 0.39300101110711694,\n",
       "  'Pos': 0.1911837358234657,\n",
       "  'Neu': 0.41581525115503204},\n",
       " 'WTD3l2xovQI': {'Neg': 0.129245215587111,\n",
       "  'Pos': 0.7134303668927815,\n",
       "  'Neu': 0.1573244504009684},\n",
       " 'LtW0cTMWdbY': {'Neg': 0.3060472868382931,\n",
       "  'Pos': 0.12382551711052656,\n",
       "  'Neu': 0.5701272189617157},\n",
       " 'iVM-azf1Akk': {'Neg': 0.7144119135207601,\n",
       "  'Pos': 0.08795132992478709,\n",
       "  'Neu': 0.19763677567243576},\n",
       " 'xWV_GI9hq5U': {'Neg': 0.21092048787977546,\n",
       "  'Pos': 0.4369771329479085,\n",
       "  'Neu': 0.35210239664754933},\n",
       " '-LFGaCkPzzY': {'Neg': 0.2800370619321863,\n",
       "  'Pos': 0.15166502942641577,\n",
       "  'Neu': 0.5682978928089142},\n",
       " 'rFDK10oplxA': {'Neg': 0.2359990517789912,\n",
       "  'Pos': 0.37986251096137696,\n",
       "  'Neu': 0.38413841981026864},\n",
       " '6p_8T_xmnLQ': {'Neg': 0.2809895885746098,\n",
       "  'Pos': 0.5842237650520272,\n",
       "  'Neu': 0.13478665322893196},\n",
       " 'D9-CHldoZ74': {'Neg': 0.5276445322152641,\n",
       "  'Pos': 0.19544632960524824,\n",
       "  'Neu': 0.27690914438830483},\n",
       " 'xqz1KueuzAM': {'Neg': 0.3048714911075015,\n",
       "  'Pos': 0.18617466297980986,\n",
       "  'Neu': 0.5089538685585323},\n",
       " 'T2JkwAZ8KY8': {'Neg': 0.5626414960250259,\n",
       "  'Pos': 0.15999665269628166,\n",
       "  'Neu': 0.27736185044050216},\n",
       " 'TQ0QJ4Si7A4': {'Neg': 0.29102530144155025,\n",
       "  'Pos': 0.09057668270543218,\n",
       "  'Neu': 0.6183980032801628},\n",
       " '81Fj00CFmJM': {'Neg': 0.2366065070964396,\n",
       "  'Pos': 0.12942732288502157,\n",
       "  'Neu': 0.6339661665260792},\n",
       " 'C-iuGrZR2pQ': {'Neg': 0.31937441835179925,\n",
       "  'Pos': 0.2616432972252369,\n",
       "  'Neu': 0.41898230724036695},\n",
       " 'JT1R95tG9jg': {'Neg': 0.3607409709532346,\n",
       "  'Pos': 0.26544852927327156,\n",
       "  'Neu': 0.37381051055022646},\n",
       " 'O06AlL8nONo': {'Neg': 0.3162025638545553,\n",
       "  'Pos': 0.0681554368800587,\n",
       "  'Neu': 0.6156419780519273},\n",
       " 'HabzHfgdMNs': {'Neg': 0.22908939953194932,\n",
       "  'Pos': 0.5894168902188539,\n",
       "  'Neu': 0.18149370718747376},\n",
       " 'o96VMbz4Zpk': {'Neg': 0.6827418506145477,\n",
       "  'Pos': 0.01484176586382091,\n",
       "  'Neu': 0.3024163469672203},\n",
       " 'XylXJJp4HpE': {'Neg': 0.14342491639157137,\n",
       "  'Pos': 0.4279274278216892,\n",
       "  'Neu': 0.4286476737923092},\n",
       " 'ZaTPlJ8nd9Q': {'Neg': 0.13120037869602028,\n",
       "  'Pos': 0.6347056235083275,\n",
       "  'Neu': 0.2340939815880524},\n",
       " 'R3E3RlBEIl8': {'Neg': 0.03488782932981849,\n",
       "  'Pos': 0.41126159206032753,\n",
       "  'Neu': 0.5538505762815475},\n",
       " '5jCZ42fV6sw': {'Neg': 0.3153246094783147,\n",
       "  'Pos': 0.16697349896033606,\n",
       "  'Neu': 0.5177018642425537},\n",
       " 'tq7FyWSGaD4': {'Neg': 0.2885483303107321,\n",
       "  'Pos': 0.28801144153112546,\n",
       "  'Neu': 0.4234402356669307},\n",
       " 'jQusLZgOYac': {'Neg': 0.010115941893309355,\n",
       "  'Pos': 0.7884901225566864,\n",
       "  'Neu': 0.2013939032331109},\n",
       " 'iOnxb9jrY40': {'Neg': 0.3310296356212348,\n",
       "  'Pos': 0.14972288015997037,\n",
       "  'Neu': 0.5192474834620953},\n",
       " 'UWMmesK08TU': {'Neg': 0.3453912420405282,\n",
       "  'Pos': 0.13239342512355912,\n",
       "  'Neu': 0.5222153266270956},\n",
       " '4bub6WOlT-I': {'Neg': 0.23292949080415484,\n",
       "  'Pos': 0.4203595860550801,\n",
       "  'Neu': 0.3467108971542782},\n",
       " 'jIsXjk3TgkU': {'Neg': 0.10518657099455594,\n",
       "  'Pos': 0.46090862452983855,\n",
       "  'Neu': 0.4339048116467893},\n",
       " 'W8WAKyR5pGA': {'Neg': 0.02103787288069725,\n",
       "  'Pos': 0.25927117466926575,\n",
       "  'Neu': 0.7196909785270691},\n",
       " 'ZBO3c3ko0eg': {'Neg': 0.3334475136362016,\n",
       "  'Pos': 0.25479026285133194,\n",
       "  'Neu': 0.41176221306834904},\n",
       " 'FIiz8hqXm24': {'Neg': 0.31086225735230577,\n",
       "  'Pos': 0.138207846838567,\n",
       "  'Neu': 0.5509298791488012},\n",
       " 'I3mkImSqHA0': {'Neg': 0.48593970470958286,\n",
       "  'Pos': 0.09399411061571704,\n",
       "  'Neu': 0.42006618943479324},\n",
       " 'DTUckJz0RGo': {'Neg': 0.5348175091203302,\n",
       "  'Pos': 0.059034387581050396,\n",
       "  'Neu': 0.4061480797827244},\n",
       " 'JWA5mUrrr_A': {'Neg': 0.5321237113239476,\n",
       "  'Pos': 0.18056309316307306,\n",
       "  'Neu': 0.28731317532947287},\n",
       " 'XqzQanN4Xx8': {'Neg': 0.15934443611185997,\n",
       "  'Pos': 0.5685877189040184,\n",
       "  'Neu': 0.27206783536821605},\n",
       " 'QjJwrWxwLJU': {'Neg': 0.1710097630109106,\n",
       "  'Pos': 0.30674830451607704,\n",
       "  'Neu': 0.5222419181040355},\n",
       " 'D7zMgv16cik': {'Neg': 0.345475681591779,\n",
       "  'Pos': 0.19781014695763588,\n",
       "  'Neu': 0.45671416725963354},\n",
       " 'bJYGvO6V67A': {'Neg': 0.002704152837395668,\n",
       "  'Pos': 0.9547702670097351,\n",
       "  'Neu': 0.042525514960289},\n",
       " 'sJ0xpruFAwQ': {'Neg': 0.26731621702331015,\n",
       "  'Pos': 0.49249360700034434,\n",
       "  'Neu': 0.2401901731888453},\n",
       " 'ENk_QRA2XsY': {'Neg': 0.05226527339047087,\n",
       "  'Pos': 0.5421562641859055,\n",
       "  'Neu': 0.4055784727845873},\n",
       " 'OB0qJwk5yA8': {'Neg': 0.16235541123896838,\n",
       "  'Pos': 0.437119210511446,\n",
       "  'Neu': 0.40052539184689523},\n",
       " '29LXKUT0eMY': {'Neg': 0.563924511273702,\n",
       "  'Pos': 0.037749984146406255,\n",
       "  'Neu': 0.39832553019126254},\n",
       " 'Bo24jIb7GA8': {'Neg': 0.31903466064896846,\n",
       "  'Pos': 0.2186909123427338,\n",
       "  'Neu': 0.4622744090027279},\n",
       " '19hkLN7KEqc': {'Neg': 0.3469207241303391,\n",
       "  'Pos': 0.16207322845649388,\n",
       "  'Neu': 0.4910060448779},\n",
       " '_quGokF8G0o': {'Neg': 0.2880698014050722,\n",
       "  'Pos': 0.17167669273912906,\n",
       "  'Neu': 0.5402535408735275},\n",
       " 'M7qPgEDk2JY': {'Neg': 0.33231044868007303,\n",
       "  'Pos': 0.20843206187710167,\n",
       "  'Neu': 0.4592574782669544},\n",
       " '-PqXVcMtygc': {'Neg': 0.5558043579415729,\n",
       "  'Pos': 0.3324661096557975,\n",
       "  'Neu': 0.11172952720274527},\n",
       " 'GUVKWAEO_hY': {'Neg': 0.10115284528583288,\n",
       "  'Pos': 0.4951684206724167,\n",
       "  'Neu': 0.4036787424236536},\n",
       " '_S_9JRwFmcA': {'Neg': 0.004872555378824472,\n",
       "  'Pos': 0.9520999789237976,\n",
       "  'Neu': 0.04302745312452316},\n",
       " 'LWIgEf_TMVU': {'Neg': 0.3389627614989877,\n",
       "  'Pos': 0.28782967692241074,\n",
       "  'Neu': 0.37320754677057266},\n",
       " 'aw59h2FNMIQ': {'Neg': 0.35665196138951516,\n",
       "  'Pos': 0.15623003741105398,\n",
       "  'Neu': 0.4871180098917749},\n",
       " 'lw0rcwYyiwE': {'Neg': 0.28031310563286144,\n",
       "  'Pos': 0.17310082912445068,\n",
       "  'Neu': 0.5465860598617129},\n",
       " 'sEjN7muHOLc': {'Neg': 0.4808350652585634,\n",
       "  'Pos': 0.2585287659635974,\n",
       "  'Neu': 0.26063616677290863},\n",
       " 'Y-xQtgvNuvA': {'Neg': 0.2755630847791003,\n",
       "  'Pos': 0.3815554017201066,\n",
       "  'Neu': 0.3428815371460385},\n",
       " 'W7n2FoRinVk': {'Neg': 0.4284924220992252,\n",
       "  'Pos': 0.17506254627369344,\n",
       "  'Neu': 0.39644502382725477},\n",
       " 'Wjj__vIdew0': {'Neg': 0.3920016430929536,\n",
       "  'Pos': 0.2223463038681075,\n",
       "  'Neu': 0.38565206760540605},\n",
       " '5DvMPgoKZmM': {'Neg': 0.3999850859399885,\n",
       "  'Pos': 0.2714006745663937,\n",
       "  'Neu': 0.3286142200231552}}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_per_vid_scores(covid_filtered_out_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
