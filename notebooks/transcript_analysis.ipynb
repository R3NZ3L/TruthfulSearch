{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de359323-94c7-42b4-b6e0-e6261bdca096",
   "metadata": {},
   "source": [
    "Guide for training this model was a video by Srinivasan, S. (2020)<br>\n",
    "Link: https://www.youtube.com/watch?v=25JOEnrz40c&list=PL0rtpP-8GFfR2orPIzBttl15_NfDhkujw&index=4&t=518s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b0562c-9fd6-4749-b321-7f73a3243780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "\n",
    "from time import time\n",
    "from time import strftime\n",
    "from time import gmtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9073169d-b518-4b58-ab96-d276599b510a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition\n",
    "from stop_words import get_stop_words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ecc2a7e-8dd6-4beb-ab34-b8296704d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"covid_vaccine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10132217-08dd-4802-8995-3fd807429f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im3otpqYAiQ</td>\n",
       "      <td>Covid Vaccine Study Finds Links to Health Cond...</td>\n",
       "      <td>[CC may contain inaccuracies] In terms of how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SkcAZfrYYXM</td>\n",
       "      <td>Two very rare COVID vaccine side effects detec...</td>\n",
       "      <td>okay we're going to finish with the guardian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7MAlEYqWUTk</td>\n",
       "      <td>Being Nice to Anti-Vaxxers</td>\n",
       "      <td>so you're against the covert vaccine oh here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uiwjAj0zfKQ</td>\n",
       "      <td>If You Get All 5 COVID Vaccines</td>\n",
       "      <td>and all right we're done now if you're feelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jPs4_MeuX7U</td>\n",
       "      <td>New Covid vaccine study links jab to heart and...</td>\n",
       "      <td>a latest covid-19 study is providing answers ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                        video_title  \\\n",
       "0  im3otpqYAiQ  Covid Vaccine Study Finds Links to Health Cond...   \n",
       "1  SkcAZfrYYXM  Two very rare COVID vaccine side effects detec...   \n",
       "2  7MAlEYqWUTk                         Being Nice to Anti-Vaxxers   \n",
       "3  uiwjAj0zfKQ                    If You Get All 5 COVID Vaccines   \n",
       "4  jPs4_MeuX7U  New Covid vaccine study links jab to heart and...   \n",
       "\n",
       "                                    video_transcript  \n",
       "0   [CC may contain inaccuracies] In terms of how...  \n",
       "1   okay we're going to finish with the guardian ...  \n",
       "2   so you're against the covert vaccine oh here ...  \n",
       "3   and all right we're done now if you're feelin...  \n",
       "4   a latest covid-19 study is providing answers ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../datasets/covid_vaccine/covid_vaccine.csv\"\n",
    "df = pd.read_csv(path).drop(\"Unnamed: 0\", axis=1)[[\"video_id\", \"video_title\", \"video_transcript\"]].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ce657b-bf67-4523-adfd-01a66eb69eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = []\n",
    "replacements = []\n",
    "\n",
    "# [0] Removing occurances of \\xa0 and \\n\n",
    "patterns.append('(\\\\xa0|\\\\n)')\n",
    "replacements.append(' ')\n",
    "\n",
    "# [1] Removing text enclosed in brackets\n",
    "patterns.append('\\[(\\w|\\s)+\\]')\n",
    "replacements.append('')\n",
    "\n",
    "# [2] Replacing stray '000's to 'thousand'\n",
    "patterns.append('(?<=\\s)000(?=\\s)')\n",
    "replacements.append('thousand')\n",
    "\n",
    "# [3, 4] Mistranscriptions of the word 'COVID'\n",
    "patterns.append('(?<=\\s)(C|c)o(ve(r)?t|id)(?=\\s)')\n",
    "patterns.append('(C|c)overed(?=\\s(vacc|infe))')\n",
    "replacements.append('COVID')\n",
    "replacements.append('COVID')\n",
    "\n",
    "# [5] Mistranscriptions of the word 'COVID-19'\n",
    "patterns.append('(?<=\\s)(C|c)(oveted|o9|o\\s19)(?=\\s)')\n",
    "replacements.append('COVID19')\n",
    "\n",
    "# [6] Replacing '%' with the word 'percent'\n",
    "patterns.append('(?<=\\d)\\%')\n",
    "replacements.append(' percent')\n",
    "\n",
    "# [7] Removing 'Speaker %d:' occurances\n",
    "patterns.append('Speaker\\s\\d\\:')\n",
    "replacements.append('')\n",
    "\n",
    "# [8] Removing '[\\xa0__\\xa0]'\n",
    "patterns.append('\\[\\\\xa0\\_\\_\\\\xa0\\]')\n",
    "replacements.append('')\n",
    "\n",
    "# [9] Removing >> occurances\n",
    "patterns.append('\\>\\>(\\>+)?')\n",
    "replacements.append('')\n",
    "\n",
    "# [10] Removing 'Reporter:' occurances\n",
    "patterns.append('Reporter\\:')\n",
    "replacements.append('')\n",
    "\n",
    "# [11] Removing weird +@ occurances\n",
    "patterns.append('\\+\\@')\n",
    "replacements.append('')\n",
    "\n",
    "# [12] Removing stray - occurances\n",
    "patterns.append('(?<=\\s)\\-(\\-+)?(?=\\s)')\n",
    "replacements.append('')\n",
    "\n",
    "# [13] Removing text within parentheses\n",
    "patterns.append('\\((\\w|\\s)+\\)')\n",
    "replacements.append('')\n",
    "\n",
    "# [14] Combining stray instances of '19' with the word 'covid' if it exists next to it\n",
    "patterns.append('(covid|COVID)(\\s|-)?19')\n",
    "replacements.append('COVID19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c2c80c-f338-4e0a-b011-1ac39d78185d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts = df[\"video_transcript\"].tolist()\n",
    "cleaned = []\n",
    "len(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200ebe0f-b88a-41bc-ab13-553d8505df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for transcript in transcripts:\n",
    "    result = re.sub(patterns[0], replacements[0], transcript)\n",
    "    \n",
    "    for i in range(1, len(patterns)):\n",
    "        result = re.sub(patterns[i], replacements[i], result)\n",
    "    \n",
    "    cleaned.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9388285-3cb8-461c-a851-8e434533635e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "660dfe0d-5fe6-4765-b9f9-f2355976ff2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im3otpqYAiQ</td>\n",
       "      <td>Covid Vaccine Study Finds Links to Health Cond...</td>\n",
       "      <td>In terms of how widespread the adverse event...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SkcAZfrYYXM</td>\n",
       "      <td>Two very rare COVID vaccine side effects detec...</td>\n",
       "      <td>okay we're going to finish with the guardian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7MAlEYqWUTk</td>\n",
       "      <td>Being Nice to Anti-Vaxxers</td>\n",
       "      <td>so you're against the COVID vaccine oh here w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uiwjAj0zfKQ</td>\n",
       "      <td>If You Get All 5 COVID Vaccines</td>\n",
       "      <td>and all right we're done now if you're feelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jPs4_MeuX7U</td>\n",
       "      <td>New Covid vaccine study links jab to heart and...</td>\n",
       "      <td>a latest COVID19 study is providing answers t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                        video_title  \\\n",
       "0  im3otpqYAiQ  Covid Vaccine Study Finds Links to Health Cond...   \n",
       "1  SkcAZfrYYXM  Two very rare COVID vaccine side effects detec...   \n",
       "2  7MAlEYqWUTk                         Being Nice to Anti-Vaxxers   \n",
       "3  uiwjAj0zfKQ                    If You Get All 5 COVID Vaccines   \n",
       "4  jPs4_MeuX7U  New Covid vaccine study links jab to heart and...   \n",
       "\n",
       "                                    video_transcript  \n",
       "0    In terms of how widespread the adverse event...  \n",
       "1   okay we're going to finish with the guardian ...  \n",
       "2   so you're against the COVID vaccine oh here w...  \n",
       "3   and all right we're done now if you're feelin...  \n",
       "4   a latest COVID19 study is providing answers t...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts_df = pd.DataFrame(\n",
    "    {\n",
    "        'video_id': df[\"video_id\"].tolist(),\n",
    "        'video_title': df[\"video_title\"].tolist(),\n",
    "        'video_transcript': cleaned\n",
    "    }\n",
    ")\n",
    "transcripts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8289125-a285-443d-82be-fcf9057cacad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(transcripts_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86c87ed3-5e8d-47f8-a8da-2da2053301aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (105, 3)\n",
      "Test set size: (45, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66dce008-05d9-4bcf-87b7-1f95117da40a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transcripts = X_train['video_transcript'].tolist()\n",
    "stop_words = get_stop_words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8489923b-66b1-4220-886e-4d64447fd5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_and_lemmatize(transcript):\n",
    "    tokens = [word.lower() for word in word_tokenize(transcript) if len(word) > 3]\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        lemmas.append(wnl.lemmatize(token))\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "654733ce-5c72-46dc-a91c-5c7ad5d433fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    analyzer=\"word\",\n",
    "    tokenizer=tokenize_and_lemmatize,\n",
    "    stop_words=stop_words,\n",
    "    max_df=0.85,\n",
    "    min_df=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f3db3d-1007-48ef-9e2e-b82d8503422f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geloa\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\geloa\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'must'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>actually</th>\n",
       "      <th>already</th>\n",
       "      <th>also</th>\n",
       "      <th>always</th>\n",
       "      <th>american</th>\n",
       "      <th>another</th>\n",
       "      <th>anything</th>\n",
       "      <th>around</th>\n",
       "      <th>available</th>\n",
       "      <th>...</th>\n",
       "      <th>well</th>\n",
       "      <th>whether</th>\n",
       "      <th>whole</th>\n",
       "      <th>will</th>\n",
       "      <th>without</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  actually  already  also  always  american  another  anything  \\\n",
       "0       0         0        0     0       0         0        0         0   \n",
       "1       0         0        1     2       1         0        0         1   \n",
       "2       0         0        0     0       0         3        3         3   \n",
       "3       0         1        0     1       0         0        0         0   \n",
       "4       0         3        0     3       0         2        2         2   \n",
       "..    ...       ...      ...   ...     ...       ...      ...       ...   \n",
       "100     0         0        0     0       0         0        0         0   \n",
       "101     0         0        0     2       0         0        0         0   \n",
       "102     2         0        3     7       0         0        0         0   \n",
       "103     0         0        0     0       0         0        0         0   \n",
       "104     1         2        1     8       0         1        1         2   \n",
       "\n",
       "     around  available  ...  well  whether  whole  will  without  work  \\\n",
       "0         0          0  ...     0        0      0     0        0     0   \n",
       "1         0          0  ...     3        3      0     0        1     0   \n",
       "2         0          0  ...     3        3      6     3        0     3   \n",
       "3         0          0  ...     0        0      0     1        0     0   \n",
       "4         0          0  ...     3        1      2     4        0     2   \n",
       "..      ...        ...  ...   ...      ...    ...   ...      ...   ...   \n",
       "100       0          0  ...     0        0      0     0        0     1   \n",
       "101       0          0  ...     0        0      0     0        0     0   \n",
       "102       0          3  ...     3        1      0     9        3     0   \n",
       "103       2          0  ...     0        0      0     1        0     0   \n",
       "104       1          0  ...     9        6      2     0        0     3   \n",
       "\n",
       "     working  world  yeah  year  \n",
       "0          0      0     0     0  \n",
       "1          0      3     0     1  \n",
       "2          3      3     0     6  \n",
       "3          1      0     0     1  \n",
       "4          1      2    11     2  \n",
       "..       ...    ...   ...   ...  \n",
       "100        0      5     0     0  \n",
       "101        0      1     0     0  \n",
       "102        0      0     1     4  \n",
       "103        0      0     0     4  \n",
       "104        0      0    11     2  \n",
       "\n",
       "[105 rows x 169 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = vectorizer.fit_transform(transcripts)\n",
    "matrix_df = pd.DataFrame(data=matrix.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d119e99e-de1f-4ec7-a504-9f6e9a57a053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['able', 'actually', 'already', 'also', 'always', 'american',\n",
       "       'another', 'anything', 'around', 'available', 'back', 'believe',\n",
       "       'better', 'blood', 'body', 'called', 'came', 'care', 'case',\n",
       "       'cause', 'clear', 'come', 'coming', 'country', 'couple', 'course',\n",
       "       'covid', 'covid19', 'data', 'day', 'death', 'different', 'disease',\n",
       "       'doctor', 'doe', 'done', 'effect', 'enough', 'even', 'every',\n",
       "       'everyone', 'everything', 'fact', 'find', 'first', 'found',\n",
       "       'getting', 'give', 'given', 'going', 'good', 'government', 'group',\n",
       "       'happen', 'happening', 'hard', 'health', 'heart', 'help', 'high',\n",
       "       'higher', 'immune', 'immunity', 'important', 'infection',\n",
       "       'information', 'issue', 'just', 'kind', 'know', 'last', 'le',\n",
       "       'least', 'level', 'life', 'like', 'little', 'long', 'look',\n",
       "       'looking', 'made', 'make', 'making', 'many', 'mean', 'medical',\n",
       "       'might', 'million', 'month', 'mrna', 'much', 'need', 'never',\n",
       "       'news', 'number', 'okay', 'pandemic', 'part', 'patient', 'people',\n",
       "       'percent', 'pfizer', 'point', 'pretty', 'problem', 'protect',\n",
       "       'protein', 'public', 'question', 'really', 'reason', 'report',\n",
       "       'research', 'right', 'risk', 'safe', 'said', 'say', 'saying',\n",
       "       'second', 'seen', 'shot', 'show', 'side', 'since', 'someone',\n",
       "       'something', 'sort', 'start', 'state', 'still', 'story', 'study',\n",
       "       'sure', 'system', 'take', 'talk', 'talking', 'tell', 'term',\n",
       "       'thank', 'thing', 'think', 'thought', 'thousand', 'three', 'time',\n",
       "       'today', 'told', 'trying', 'understand', 'used', 'vaccinated',\n",
       "       'vaccination', 'vaccine', 'video', 'virus', 'want', 'week', 'well',\n",
       "       'whether', 'whole', 'will', 'without', 'work', 'working', 'world',\n",
       "       'yeah', 'year'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = np.array(vectorizer.get_feature_names_out())\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b2f5730-1543-42f9-a522-6f1e961dc305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda = decomposition.LatentDirichletAllocation(n_components=10, max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cd22739-b468-4bf1-a1e8-56c434d65a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_vectors = lda.fit_transform(matrix)\n",
    "h1 = lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07a9993e-42b6-4b2d-97e4-eb31d1688bec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e-01, 1.00000000e-01, 1.00000000e-01, 1.00000000e-01,\n",
       "        1.00000000e-01, 1.00000000e-01, 1.00000000e-01, 1.00000000e-01,\n",
       "        1.00000000e-01, 1.00000000e-01],\n",
       "       [4.29787077e-01, 5.61945390e-04, 1.36888902e-02, 5.52590357e-01,\n",
       "        5.61960443e-04, 5.61948062e-04, 5.61942326e-04, 5.61937476e-04,\n",
       "        5.61982641e-04, 5.61959521e-04],\n",
       "       [9.96750237e-01, 3.61077349e-04, 3.61037889e-04, 3.61120818e-04,\n",
       "        3.61088835e-04, 3.61064687e-04, 3.61070571e-04, 3.61090134e-04,\n",
       "        3.61105631e-04, 3.61106697e-04]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectors[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "953d3b99-75ca-458a-9f85-8734463af16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.49161022e+01, 4.75836589e+01, 2.10824637e+01, 3.44767182e+01,\n",
       "       1.71272088e+01, 8.01524933e+01, 2.21263321e+01, 3.63091243e+01,\n",
       "       1.07318002e+01, 2.81404647e+00, 3.09810702e+01, 4.39417461e+01,\n",
       "       2.72761135e+01, 1.35909673e+00, 1.00016813e-01, 3.18827658e+01,\n",
       "       2.10487951e+01, 3.74377164e+01, 3.25754142e+01, 2.28557921e+01,\n",
       "       2.78856742e+01, 4.08379361e+01, 1.00038858e-01, 9.18625755e+01,\n",
       "       2.49345850e+01, 3.39248714e+01, 5.98077777e+01, 1.49019496e+01,\n",
       "       7.58993501e+01, 3.08325136e+01, 4.99211866e+01, 1.00023219e-01,\n",
       "       1.00024781e-01, 3.29739325e+01, 4.53830199e+01, 2.10110894e+01,\n",
       "       6.93193350e+00, 1.11607083e+01, 8.04634108e+01, 3.68255627e+01,\n",
       "       1.42056184e+01, 2.86769643e+01, 4.28754252e+01, 1.36221024e+01,\n",
       "       4.47863029e+01, 1.00031552e-01, 3.50975221e+01, 3.01596392e+01,\n",
       "       1.54904236e+01, 1.24991125e+02, 3.06841590e+01, 6.70165164e+01,\n",
       "       1.52229211e+01, 2.80128259e+01, 3.21299777e+01, 2.69146088e+01,\n",
       "       2.15669112e+01, 2.33879752e+01, 1.83313612e+01, 1.00029180e-01,\n",
       "       1.00022348e-01, 1.00010665e-01, 1.00015684e-01, 1.00021936e-01,\n",
       "       1.00010827e-01, 4.25623618e+01, 9.72171962e+00, 1.95443305e+02,\n",
       "       1.58858746e+01, 2.18402644e+02, 1.49183616e+01, 6.08339499e+00,\n",
       "       1.00029818e-01, 2.40097080e+01, 5.77396326e+01, 1.31436875e+02,\n",
       "       2.03068405e+01, 1.00011791e-01, 6.63626852e+01, 1.00036640e-01,\n",
       "       3.74139418e+01, 6.98408360e+01, 6.75764222e+00, 2.55242856e+01,\n",
       "       5.25705389e+01, 2.85148757e+01, 2.64782652e+01, 5.22185257e+01,\n",
       "       8.43770416e+00, 1.29767003e+00, 5.63712709e+01, 5.26821758e+01,\n",
       "       4.81482522e+01, 2.75484931e+01, 1.00033055e-01, 3.61413754e+01,\n",
       "       1.44824678e+01, 2.08585556e+01, 1.00020907e-01, 2.73375133e+02,\n",
       "       2.94390826e-01, 1.00015997e-01, 7.08382297e+01, 7.63853457e+00,\n",
       "       2.39653900e+01, 3.62784390e+00, 1.00002336e-01, 4.10388339e+01,\n",
       "       6.59278659e+01, 6.71137348e+01, 2.05318981e+01, 1.33318795e+01,\n",
       "       1.16093458e+01, 9.02154779e+01, 9.04599414e+00, 2.94978258e+01,\n",
       "       8.28502644e+01, 2.81808301e+01, 2.35139217e+01, 8.77710450e+00,\n",
       "       2.26675733e+01, 4.18155417e+01, 6.31579965e+01, 2.40599384e+01,\n",
       "       2.37289840e+01, 2.84621607e+01, 6.48128081e+01, 1.08936359e+01,\n",
       "       3.10083890e+01, 7.04121521e+01, 1.57267196e+01, 6.27980522e+01,\n",
       "       8.32308662e+00, 4.59533108e+01, 1.98268985e+01, 5.74530233e+01,\n",
       "       3.61486621e+01, 1.74711947e+01, 6.50671197e+01, 5.87440747e+00,\n",
       "       6.59997540e+01, 1.25183620e+02, 6.73434037e+01, 3.42880138e+01,\n",
       "       2.43731720e+01, 8.70307016e+00, 7.62368306e+01, 4.29108832e+01,\n",
       "       4.16744353e+01, 3.12520364e+01, 1.00027526e-01, 2.74438823e+01,\n",
       "       1.72418431e+01, 8.21622105e+00, 2.06731866e+02, 3.01985330e+01,\n",
       "       1.00032332e-01, 1.23968439e+02, 1.18109681e+01, 9.20116572e+01,\n",
       "       1.84191205e+01, 3.93724117e+01, 1.36402622e+02, 1.19671089e+01,\n",
       "       4.27692437e+01, 2.22008133e+01, 7.06899668e+01, 4.52224077e+01,\n",
       "       6.79631268e+01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e65b1a37-9100-4228-91a7-2c5296ee837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from the guide\n",
    "num_words = 15\n",
    "top_words = lambda t: [vocabulary[i] for i in np.argsort(t)[:-num_words-1:-1]]\n",
    "topic_words = ([top_words(t) for t in h1])\n",
    "topics = [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9af40592-d1fa-4993-a9d4-3373a93b4f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people know vaccine just will like thing going want well country right said even american',\n",
       " 'health news state vaccine just doctor report part will came give actually also medical right',\n",
       " 'blood vaccination vaccine might doe need three second first week research cause important always number',\n",
       " 'vaccine people risk covid vaccinated study covid19 effect vaccination data death case know million side',\n",
       " 'health question many just care vaccine year country something covid right know american percent public',\n",
       " 'vaccine mrna protein virus body system immune covid19 make pandemic like work around also will',\n",
       " 'long people year think patient going just virus well covid different like many really thing',\n",
       " 'vaccine protein people know covid19 study virus look just thing actually data going time death',\n",
       " 'know like people think yeah just covid kind going getting right really time make still',\n",
       " 'shot might also video second first vaccination data month well information right percent protein reason']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d7d297-7b59-4cae-8a73-d037b0372c6c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c030b-4418-4378-85b4-93b37e63d408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f955847-e5b4-4f5f-b088-3a0a0c2289d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
